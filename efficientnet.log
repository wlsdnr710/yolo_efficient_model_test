/Users/jinwookkim/projects/ml_model/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
  warnings.warn(warn_msg)
Starting EfficientNet training script...

--- Model Initialization (EfficientNet) ---
Using device: mps
Creating EfficientNet model 'timm/efficientnet_b0.ra_in1k' with 101 output classes...

--- Dataset Loading (EfficientNet) ---
Checking for Food-101 dataset...
Image transformations created.
Loading Food-101 dataset using torchvision...
Food-101 dataset loaded. Using a subset of 500 samples for this demo.
Loading checkpoint from ./trained_models/efficientnet_checkpoint.pth
Resuming training from epoch 4
Model, optimizer, and criterion initialized.

--- Training Setup (EfficientNet) ---
DataLoader created with batch size 4 for 125 batches.
Initial Training Accuracy: 9.40%

--- Starting EfficientNet Training ---
Epoch [5/124], Batch [1/125] [--------------------] 0.8%, Loss: 4.0774Epoch [5/124], Batch [2/125] [--------------------] 1.6%, Loss: 4.8847Epoch [5/124], Batch [3/125] [--------------------] 2.4%, Loss: 3.7476Epoch [5/124], Batch [4/125] [--------------------] 3.2%, Loss: 3.5577Epoch [5/124], Batch [5/125] [--------------------] 4.0%, Loss: 3.8353Epoch [5/124], Batch [6/125] [--------------------] 4.8%, Loss: 3.8329Epoch [5/124], Batch [7/125] [#-------------------] 5.6%, Loss: 3.3363Epoch [5/124], Batch [8/125] [#-------------------] 6.4%, Loss: 3.7309Epoch [5/124], Batch [9/125] [#-------------------] 7.2%, Loss: 4.3789Epoch [5/124], Batch [10/125] [#-------------------] 8.0%, Loss: 4.1694Epoch [5/124], Batch [11/125] [#-------------------] 8.8%, Loss: 4.6074Epoch [5/124], Batch [12/125] [#-------------------] 9.6%, Loss: 4.2409Epoch [5/124], Batch [13/125] [##------------------] 10.4%, Loss: 3.8458Epoch [5/124], Batch [14/125] [##------------------] 11.2%, Loss: 3.1282Epoch [5/124], Batch [15/125] [##------------------] 12.0%, Loss: 4.9863Epoch [5/124], Batch [16/125] [##------------------] 12.8%, Loss: 5.8677Epoch [5/124], Batch [17/125] [##------------------] 13.6%, Loss: 3.7231Epoch [5/124], Batch [18/125] [##------------------] 14.4%, Loss: 4.3492Epoch [5/124], Batch [19/125] [###-----------------] 15.2%, Loss: 3.4778Epoch [5/124], Batch [20/125] [###-----------------] 16.0%, Loss: 5.0541Epoch [5/124], Batch [21/125] [###-----------------] 16.8%, Loss: 4.3723Epoch [5/124], Batch [22/125] [###-----------------] 17.6%, Loss: 4.1110Epoch [5/124], Batch [23/125] [###-----------------] 18.4%, Loss: 4.9517Epoch [5/124], Batch [24/125] [###-----------------] 19.2%, Loss: 4.1599Epoch [5/124], Batch [25/125] [####----------------] 20.0%, Loss: 4.9380Epoch [5/124], Batch [26/125] [####----------------] 20.8%, Loss: 4.9494Epoch [5/124], Batch [27/125] [####----------------] 21.6%, Loss: 3.7623Epoch [5/124], Batch [28/125] [####----------------] 22.4%, Loss: 3.7934Epoch [5/124], Batch [29/125] [####----------------] 23.2%, Loss: 4.9140Epoch [5/124], Batch [30/125] [####----------------] 24.0%, Loss: 4.7502Epoch [5/124], Batch [31/125] [####----------------] 24.8%, Loss: 4.0208Epoch [5/124], Batch [32/125] [#####---------------] 25.6%, Loss: 4.5052Epoch [5/124], Batch [33/125] [#####---------------] 26.4%, Loss: 5.8609Epoch [5/124], Batch [34/125] [#####---------------] 27.2%, Loss: 3.3812Epoch [5/124], Batch [35/125] [#####---------------] 28.0%, Loss: 4.9982Epoch [5/124], Batch [36/125] [#####---------------] 28.8%, Loss: 4.0415Epoch [5/124], Batch [37/125] [#####---------------] 29.6%, Loss: 5.5099Epoch [5/124], Batch [38/125] [######--------------] 30.4%, Loss: 5.0688Epoch [5/124], Batch [39/125] [######--------------] 31.2%, Loss: 3.8972Epoch [5/124], Batch [40/125] [######--------------] 32.0%, Loss: 4.6104Epoch [5/124], Batch [41/125] [######--------------] 32.8%, Loss: 5.1495Epoch [5/124], Batch [42/125] [######--------------] 33.6%, Loss: 4.0809Epoch [5/124], Batch [43/125] [######--------------] 34.4%, Loss: 4.4781Epoch [5/124], Batch [44/125] [#######-------------] 35.2%, Loss: 5.3462Epoch [5/124], Batch [45/125] [#######-------------] 36.0%, Loss: 3.8148Epoch [5/124], Batch [46/125] [#######-------------] 36.8%, Loss: 3.7911Epoch [5/124], Batch [47/125] [#######-------------] 37.6%, Loss: 4.2985Epoch [5/124], Batch [48/125] [#######-------------] 38.4%, Loss: 4.2283Epoch [5/124], Batch [49/125] [#######-------------] 39.2%, Loss: 3.7742Epoch [5/124], Batch [50/125] [########------------] 40.0%, Loss: 4.8979Epoch [5/124], Batch [51/125] [########------------] 40.8%, Loss: 4.0539Epoch [5/124], Batch [52/125] [########------------] 41.6%, Loss: 4.1539Epoch [5/124], Batch [53/125] [########------------] 42.4%, Loss: 5.0983Epoch [5/124], Batch [54/125] [########------------] 43.2%, Loss: 4.7847Epoch [5/124], Batch [55/125] [########------------] 44.0%, Loss: 4.5634Epoch [5/124], Batch [56/125] [########------------] 44.8%, Loss: 3.9305Epoch [5/124], Batch [57/125] [#########-----------] 45.6%, Loss: 3.7798Epoch [5/124], Batch [58/125] [#########-----------] 46.4%, Loss: 3.0867Epoch [5/124], Batch [59/125] [#########-----------] 47.2%, Loss: 3.7746Epoch [5/124], Batch [60/125] [#########-----------] 48.0%, Loss: 3.9582Epoch [5/124], Batch [61/125] [#########-----------] 48.8%, Loss: 4.2067Epoch [5/124], Batch [62/125] [#########-----------] 49.6%, Loss: 3.9647Epoch [5/124], Batch [63/125] [##########----------] 50.4%, Loss: 3.8299Epoch [5/124], Batch [64/125] [##########----------] 51.2%, Loss: 4.0890Epoch [5/124], Batch [65/125] [##########----------] 52.0%, Loss: 4.0709Epoch [5/124], Batch [66/125] [##########----------] 52.8%, Loss: 4.6807Epoch [5/124], Batch [67/125] [##########----------] 53.6%, Loss: 4.3866Epoch [5/124], Batch [68/125] [##########----------] 54.4%, Loss: 3.3589Epoch [5/124], Batch [69/125] [###########---------] 55.2%, Loss: 5.2512Epoch [5/124], Batch [70/125] [###########---------] 56.0%, Loss: 4.8248Epoch [5/124], Batch [71/125] [###########---------] 56.8%, Loss: 4.7979Epoch [5/124], Batch [72/125] [###########---------] 57.6%, Loss: 4.1720Epoch [5/124], Batch [73/125] [###########---------] 58.4%, Loss: 4.8201Epoch [5/124], Batch [74/125] [###########---------] 59.2%, Loss: 3.6813Epoch [5/124], Batch [75/125] [############--------] 60.0%, Loss: 4.5893Epoch [5/124], Batch [76/125] [############--------] 60.8%, Loss: 4.4188Epoch [5/124], Batch [77/125] [############--------] 61.6%, Loss: 4.3848Epoch [5/124], Batch [78/125] [############--------] 62.4%, Loss: 3.2599Epoch [5/124], Batch [79/125] [############--------] 63.2%, Loss: 3.8308Epoch [5/124], Batch [80/125] [############--------] 64.0%, Loss: 4.3378Epoch [5/124], Batch [81/125] [############--------] 64.8%, Loss: 3.8570Epoch [5/124], Batch [82/125] [#############-------] 65.6%, Loss: 4.5141Epoch [5/124], Batch [83/125] [#############-------] 66.4%, Loss: 4.1048Epoch [5/124], Batch [84/125] [#############-------] 67.2%, Loss: 4.5359Epoch [5/124], Batch [85/125] [#############-------] 68.0%, Loss: 4.3764Epoch [5/124], Batch [86/125] [#############-------] 68.8%, Loss: 4.5826Epoch [5/124], Batch [87/125] [#############-------] 69.6%, Loss: 4.1406Epoch [5/124], Batch [88/125] [##############------] 70.4%, Loss: 5.3866Epoch [5/124], Batch [89/125] [##############------] 71.2%, Loss: 4.0779Epoch [5/124], Batch [90/125] [##############------] 72.0%, Loss: 3.7108Epoch [5/124], Batch [91/125] [##############------] 72.8%, Loss: 4.9068Epoch [5/124], Batch [92/125] [##############------] 73.6%, Loss: 4.4763Epoch [5/124], Batch [93/125] [##############------] 74.4%, Loss: 4.6050Epoch [5/124], Batch [94/125] [###############-----] 75.2%, Loss: 4.9157Epoch [5/124], Batch [95/125] [###############-----] 76.0%, Loss: 4.8120Epoch [5/124], Batch [96/125] [###############-----] 76.8%, Loss: 4.0593Epoch [5/124], Batch [97/125] [###############-----] 77.6%, Loss: 5.1975Epoch [5/124], Batch [98/125] [###############-----] 78.4%, Loss: 4.9589Epoch [5/124], Batch [99/125] [###############-----] 79.2%, Loss: 4.6899Epoch [5/124], Batch [100/125] [################----] 80.0%, Loss: 4.5977Epoch [5/124], Batch [101/125] [################----] 80.8%, Loss: 4.5703Epoch [5/124], Batch [102/125] [################----] 81.6%, Loss: 4.5140Epoch [5/124], Batch [103/125] [################----] 82.4%, Loss: 4.3868Epoch [5/124], Batch [104/125] [################----] 83.2%, Loss: 4.0470Epoch [5/124], Batch [105/125] [################----] 84.0%, Loss: 4.3232Epoch [5/124], Batch [106/125] [################----] 84.8%, Loss: 3.6375Epoch [5/124], Batch [107/125] [#################---] 85.6%, Loss: 3.9841Epoch [5/124], Batch [108/125] [#################---] 86.4%, Loss: 3.5926Epoch [5/124], Batch [109/125] [#################---] 87.2%, Loss: 4.3781Epoch [5/124], Batch [110/125] [#################---] 88.0%, Loss: 3.1207Epoch [5/124], Batch [111/125] [#################---] 88.8%, Loss: 4.7403Epoch [5/124], Batch [112/125] [#################---] 89.6%, Loss: 4.4855Epoch [5/124], Batch [113/125] [##################--] 90.4%, Loss: 4.6410Epoch [5/124], Batch [114/125] [##################--] 91.2%, Loss: 3.8799Epoch [5/124], Batch [115/125] [##################--] 92.0%, Loss: 3.9607Epoch [5/124], Batch [116/125] [##################--] 92.8%, Loss: 4.4497Epoch [5/124], Batch [117/125] [##################--] 93.6%, Loss: 3.7652Epoch [5/124], Batch [118/125] [##################--] 94.4%, Loss: 3.3944Epoch [5/124], Batch [119/125] [###################-] 95.2%, Loss: 2.4849Epoch [5/124], Batch [120/125] [###################-] 96.0%, Loss: 4.1922Epoch [5/124], Batch [121/125] [###################-] 96.8%, Loss: 4.2716Epoch [5/124], Batch [122/125] [###################-] 97.6%, Loss: 4.8701Epoch [5/124], Batch [123/125] [###################-] 98.4%, Loss: 4.7293Epoch [5/124], Batch [124/125] [###################-] 99.2%, Loss: 4.7391Epoch [5/124], Batch [125/125] [####################] 100.0%, Loss: 3.5441
Epoch [5/124] finished. Average Loss: 4.2931
Training Accuracy: 31.20%
--- Saving checkpoint for epoch 5 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [6/124], Batch [1/125] [--------------------] 0.8%, Loss: 3.1572Epoch [6/124], Batch [2/125] [--------------------] 1.6%, Loss: 3.3106Epoch [6/124], Batch [3/125] [--------------------] 2.4%, Loss: 2.8933Epoch [6/124], Batch [4/125] [--------------------] 3.2%, Loss: 3.2130Epoch [6/124], Batch [5/125] [--------------------] 4.0%, Loss: 3.5891Epoch [6/124], Batch [6/125] [--------------------] 4.8%, Loss: 2.6624Epoch [6/124], Batch [7/125] [#-------------------] 5.6%, Loss: 3.5677Epoch [6/124], Batch [8/125] [#-------------------] 6.4%, Loss: 3.1881Epoch [6/124], Batch [9/125] [#-------------------] 7.2%, Loss: 2.5558Epoch [6/124], Batch [10/125] [#-------------------] 8.0%, Loss: 3.8576Epoch [6/124], Batch [11/125] [#-------------------] 8.8%, Loss: 3.1090Epoch [6/124], Batch [12/125] [#-------------------] 9.6%, Loss: 3.5823Epoch [6/124], Batch [13/125] [##------------------] 10.4%, Loss: 3.3812Epoch [6/124], Batch [14/125] [##------------------] 11.2%, Loss: 3.9136Epoch [6/124], Batch [15/125] [##------------------] 12.0%, Loss: 4.7289Epoch [6/124], Batch [16/125] [##------------------] 12.8%, Loss: 3.4987Epoch [6/124], Batch [17/125] [##------------------] 13.6%, Loss: 3.8136Epoch [6/124], Batch [18/125] [##------------------] 14.4%, Loss: 2.6951Epoch [6/124], Batch [19/125] [###-----------------] 15.2%, Loss: 4.1385Epoch [6/124], Batch [20/125] [###-----------------] 16.0%, Loss: 2.4930Epoch [6/124], Batch [21/125] [###-----------------] 16.8%, Loss: 1.8071Epoch [6/124], Batch [22/125] [###-----------------] 17.6%, Loss: 2.8729Epoch [6/124], Batch [23/125] [###-----------------] 18.4%, Loss: 2.8144Epoch [6/124], Batch [24/125] [###-----------------] 19.2%, Loss: 2.6424Epoch [6/124], Batch [25/125] [####----------------] 20.0%, Loss: 2.0863Epoch [6/124], Batch [26/125] [####----------------] 20.8%, Loss: 2.2830Epoch [6/124], Batch [27/125] [####----------------] 21.6%, Loss: 3.3990Epoch [6/124], Batch [28/125] [####----------------] 22.4%, Loss: 2.8505Epoch [6/124], Batch [29/125] [####----------------] 23.2%, Loss: 2.5345Epoch [6/124], Batch [30/125] [####----------------] 24.0%, Loss: 3.3886Epoch [6/124], Batch [31/125] [####----------------] 24.8%, Loss: 2.7276Epoch [6/124], Batch [32/125] [#####---------------] 25.6%, Loss: 3.2448Epoch [6/124], Batch [33/125] [#####---------------] 26.4%, Loss: 3.8203Epoch [6/124], Batch [34/125] [#####---------------] 27.2%, Loss: 2.3892Epoch [6/124], Batch [35/125] [#####---------------] 28.0%, Loss: 3.0837Epoch [6/124], Batch [36/125] [#####---------------] 28.8%, Loss: 3.0526Epoch [6/124], Batch [37/125] [#####---------------] 29.6%, Loss: 3.1575Epoch [6/124], Batch [38/125] [######--------------] 30.4%, Loss: 3.0704Epoch [6/124], Batch [39/125] [######--------------] 31.2%, Loss: 3.6538Epoch [6/124], Batch [40/125] [######--------------] 32.0%, Loss: 2.9055Epoch [6/124], Batch [41/125] [######--------------] 32.8%, Loss: 2.7409Epoch [6/124], Batch [42/125] [######--------------] 33.6%, Loss: 3.6778Epoch [6/124], Batch [43/125] [######--------------] 34.4%, Loss: 3.1037Epoch [6/124], Batch [44/125] [#######-------------] 35.2%, Loss: 3.8872Epoch [6/124], Batch [45/125] [#######-------------] 36.0%, Loss: 2.9396Epoch [6/124], Batch [46/125] [#######-------------] 36.8%, Loss: 3.1591Epoch [6/124], Batch [47/125] [#######-------------] 37.6%, Loss: 2.8618Epoch [6/124], Batch [48/125] [#######-------------] 38.4%, Loss: 2.7131Epoch [6/124], Batch [49/125] [#######-------------] 39.2%, Loss: 2.6324Epoch [6/124], Batch [50/125] [########------------] 40.0%, Loss: 4.1329Epoch [6/124], Batch [51/125] [########------------] 40.8%, Loss: 2.2704Epoch [6/124], Batch [52/125] [########------------] 41.6%, Loss: 2.4978Epoch [6/124], Batch [53/125] [########------------] 42.4%, Loss: 3.0727Epoch [6/124], Batch [54/125] [########------------] 43.2%, Loss: 2.5903Epoch [6/124], Batch [55/125] [########------------] 44.0%, Loss: 2.3941Epoch [6/124], Batch [56/125] [########------------] 44.8%, Loss: 3.9055Epoch [6/124], Batch [57/125] [#########-----------] 45.6%, Loss: 3.2477Epoch [6/124], Batch [58/125] [#########-----------] 46.4%, Loss: 3.0237Epoch [6/124], Batch [59/125] [#########-----------] 47.2%, Loss: 3.1246Epoch [6/124], Batch [60/125] [#########-----------] 48.0%, Loss: 4.0127Epoch [6/124], Batch [61/125] [#########-----------] 48.8%, Loss: 4.3380Epoch [6/124], Batch [62/125] [#########-----------] 49.6%, Loss: 3.2139Epoch [6/124], Batch [63/125] [##########----------] 50.4%, Loss: 2.6882Epoch [6/124], Batch [64/125] [##########----------] 51.2%, Loss: 3.0965Epoch [6/124], Batch [65/125] [##########----------] 52.0%, Loss: 3.1835Epoch [6/124], Batch [66/125] [##########----------] 52.8%, Loss: 3.5043Epoch [6/124], Batch [67/125] [##########----------] 53.6%, Loss: 2.9283Epoch [6/124], Batch [68/125] [##########----------] 54.4%, Loss: 2.2487Epoch [6/124], Batch [69/125] [###########---------] 55.2%, Loss: 2.7326Epoch [6/124], Batch [70/125] [###########---------] 56.0%, Loss: 2.9817Epoch [6/124], Batch [71/125] [###########---------] 56.8%, Loss: 2.2476Epoch [6/124], Batch [72/125] [###########---------] 57.6%, Loss: 3.8765Epoch [6/124], Batch [73/125] [###########---------] 58.4%, Loss: 2.6863Epoch [6/124], Batch [74/125] [###########---------] 59.2%, Loss: 2.5867Epoch [6/124], Batch [75/125] [############--------] 60.0%, Loss: 2.6544Epoch [6/124], Batch [76/125] [############--------] 60.8%, Loss: 2.6390Epoch [6/124], Batch [77/125] [############--------] 61.6%, Loss: 2.5487Epoch [6/124], Batch [78/125] [############--------] 62.4%, Loss: 2.4216Epoch [6/124], Batch [79/125] [############--------] 63.2%, Loss: 3.3458Epoch [6/124], Batch [80/125] [############--------] 64.0%, Loss: 2.4546Epoch [6/124], Batch [81/125] [############--------] 64.8%, Loss: 2.2524Epoch [6/124], Batch [82/125] [#############-------] 65.6%, Loss: 3.1973Epoch [6/124], Batch [83/125] [#############-------] 66.4%, Loss: 3.4175Epoch [6/124], Batch [84/125] [#############-------] 67.2%, Loss: 2.6967Epoch [6/124], Batch [85/125] [#############-------] 68.0%, Loss: 4.6320Epoch [6/124], Batch [86/125] [#############-------] 68.8%, Loss: 3.5542Epoch [6/124], Batch [87/125] [#############-------] 69.6%, Loss: 2.4206Epoch [6/124], Batch [88/125] [##############------] 70.4%, Loss: 3.2438Epoch [6/124], Batch [89/125] [##############------] 71.2%, Loss: 3.6987Epoch [6/124], Batch [90/125] [##############------] 72.0%, Loss: 3.7954Epoch [6/124], Batch [91/125] [##############------] 72.8%, Loss: 4.2052Epoch [6/124], Batch [92/125] [##############------] 73.6%, Loss: 3.0807Epoch [6/124], Batch [93/125] [##############------] 74.4%, Loss: 2.7402Epoch [6/124], Batch [94/125] [###############-----] 75.2%, Loss: 4.0952Epoch [6/124], Batch [95/125] [###############-----] 76.0%, Loss: 2.5503Epoch [6/124], Batch [96/125] [###############-----] 76.8%, Loss: 3.1109Epoch [6/124], Batch [97/125] [###############-----] 77.6%, Loss: 5.6984Epoch [6/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.8446Epoch [6/124], Batch [99/125] [###############-----] 79.2%, Loss: 2.7546Epoch [6/124], Batch [100/125] [################----] 80.0%, Loss: 3.6248Epoch [6/124], Batch [101/125] [################----] 80.8%, Loss: 2.1010Epoch [6/124], Batch [102/125] [################----] 81.6%, Loss: 3.9666Epoch [6/124], Batch [103/125] [################----] 82.4%, Loss: 3.1897Epoch [6/124], Batch [104/125] [################----] 83.2%, Loss: 1.8548Epoch [6/124], Batch [105/125] [################----] 84.0%, Loss: 4.0484Epoch [6/124], Batch [106/125] [################----] 84.8%, Loss: 3.5240Epoch [6/124], Batch [107/125] [#################---] 85.6%, Loss: 3.0706Epoch [6/124], Batch [108/125] [#################---] 86.4%, Loss: 4.7567Epoch [6/124], Batch [109/125] [#################---] 87.2%, Loss: 2.8263Epoch [6/124], Batch [110/125] [#################---] 88.0%, Loss: 3.5686Epoch [6/124], Batch [111/125] [#################---] 88.8%, Loss: 4.1022Epoch [6/124], Batch [112/125] [#################---] 89.6%, Loss: 3.1734Epoch [6/124], Batch [113/125] [##################--] 90.4%, Loss: 2.4501Epoch [6/124], Batch [114/125] [##################--] 91.2%, Loss: 3.8047Epoch [6/124], Batch [115/125] [##################--] 92.0%, Loss: 2.5966Epoch [6/124], Batch [116/125] [##################--] 92.8%, Loss: 4.0139Epoch [6/124], Batch [117/125] [##################--] 93.6%, Loss: 3.9938Epoch [6/124], Batch [118/125] [##################--] 94.4%, Loss: 4.2919Epoch [6/124], Batch [119/125] [###################-] 95.2%, Loss: 3.6158Epoch [6/124], Batch [120/125] [###################-] 96.0%, Loss: 2.9971Epoch [6/124], Batch [121/125] [###################-] 96.8%, Loss: 4.4902Epoch [6/124], Batch [122/125] [###################-] 97.6%, Loss: 2.5802Epoch [6/124], Batch [123/125] [###################-] 98.4%, Loss: 4.3949Epoch [6/124], Batch [124/125] [###################-] 99.2%, Loss: 3.8573Epoch [6/124], Batch [125/125] [####################] 100.0%, Loss: 4.2086
Epoch [6/124] finished. Average Loss: 3.1887
Training Accuracy: 62.40%
--- Saving checkpoint for epoch 6 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [7/124], Batch [1/125] [--------------------] 0.8%, Loss: 2.6562Epoch [7/124], Batch [2/125] [--------------------] 1.6%, Loss: 2.1613Epoch [7/124], Batch [3/125] [--------------------] 2.4%, Loss: 2.1800Epoch [7/124], Batch [4/125] [--------------------] 3.2%, Loss: 1.3574Epoch [7/124], Batch [5/125] [--------------------] 4.0%, Loss: 1.6464Epoch [7/124], Batch [6/125] [--------------------] 4.8%, Loss: 1.4725Epoch [7/124], Batch [7/125] [#-------------------] 5.6%, Loss: 1.4917Epoch [7/124], Batch [8/125] [#-------------------] 6.4%, Loss: 2.6577Epoch [7/124], Batch [9/125] [#-------------------] 7.2%, Loss: 1.8893Epoch [7/124], Batch [10/125] [#-------------------] 8.0%, Loss: 1.6882Epoch [7/124], Batch [11/125] [#-------------------] 8.8%, Loss: 2.1316Epoch [7/124], Batch [12/125] [#-------------------] 9.6%, Loss: 1.6687Epoch [7/124], Batch [13/125] [##------------------] 10.4%, Loss: 2.5499Epoch [7/124], Batch [14/125] [##------------------] 11.2%, Loss: 2.1309Epoch [7/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.7537Epoch [7/124], Batch [16/125] [##------------------] 12.8%, Loss: 2.1774Epoch [7/124], Batch [17/125] [##------------------] 13.6%, Loss: 2.7113Epoch [7/124], Batch [18/125] [##------------------] 14.4%, Loss: 1.5172Epoch [7/124], Batch [19/125] [###-----------------] 15.2%, Loss: 1.5117Epoch [7/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.8793Epoch [7/124], Batch [21/125] [###-----------------] 16.8%, Loss: 3.5809Epoch [7/124], Batch [22/125] [###-----------------] 17.6%, Loss: 1.6485Epoch [7/124], Batch [23/125] [###-----------------] 18.4%, Loss: 2.8207Epoch [7/124], Batch [24/125] [###-----------------] 19.2%, Loss: 2.1212Epoch [7/124], Batch [25/125] [####----------------] 20.0%, Loss: 2.4590Epoch [7/124], Batch [26/125] [####----------------] 20.8%, Loss: 1.9235Epoch [7/124], Batch [27/125] [####----------------] 21.6%, Loss: 2.3437Epoch [7/124], Batch [28/125] [####----------------] 22.4%, Loss: 1.1647Epoch [7/124], Batch [29/125] [####----------------] 23.2%, Loss: 2.1776Epoch [7/124], Batch [30/125] [####----------------] 24.0%, Loss: 2.4442Epoch [7/124], Batch [31/125] [####----------------] 24.8%, Loss: 1.9910Epoch [7/124], Batch [32/125] [#####---------------] 25.6%, Loss: 1.9448Epoch [7/124], Batch [33/125] [#####---------------] 26.4%, Loss: 2.5342Epoch [7/124], Batch [34/125] [#####---------------] 27.2%, Loss: 2.2224Epoch [7/124], Batch [35/125] [#####---------------] 28.0%, Loss: 1.3399Epoch [7/124], Batch [36/125] [#####---------------] 28.8%, Loss: 2.1040Epoch [7/124], Batch [37/125] [#####---------------] 29.6%, Loss: 1.5751Epoch [7/124], Batch [38/125] [######--------------] 30.4%, Loss: 3.2665Epoch [7/124], Batch [39/125] [######--------------] 31.2%, Loss: 3.8656Epoch [7/124], Batch [40/125] [######--------------] 32.0%, Loss: 3.0334Epoch [7/124], Batch [41/125] [######--------------] 32.8%, Loss: 2.1994Epoch [7/124], Batch [42/125] [######--------------] 33.6%, Loss: 3.1246Epoch [7/124], Batch [43/125] [######--------------] 34.4%, Loss: 2.0109Epoch [7/124], Batch [44/125] [#######-------------] 35.2%, Loss: 3.0871Epoch [7/124], Batch [45/125] [#######-------------] 36.0%, Loss: 2.3965Epoch [7/124], Batch [46/125] [#######-------------] 36.8%, Loss: 2.3175Epoch [7/124], Batch [47/125] [#######-------------] 37.6%, Loss: 2.0991Epoch [7/124], Batch [48/125] [#######-------------] 38.4%, Loss: 1.3454Epoch [7/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.8910Epoch [7/124], Batch [50/125] [########------------] 40.0%, Loss: 3.6135Epoch [7/124], Batch [51/125] [########------------] 40.8%, Loss: 2.4411Epoch [7/124], Batch [52/125] [########------------] 41.6%, Loss: 1.4151Epoch [7/124], Batch [53/125] [########------------] 42.4%, Loss: 2.9952Epoch [7/124], Batch [54/125] [########------------] 43.2%, Loss: 1.6754Epoch [7/124], Batch [55/125] [########------------] 44.0%, Loss: 1.6190Epoch [7/124], Batch [56/125] [########------------] 44.8%, Loss: 1.5153Epoch [7/124], Batch [57/125] [#########-----------] 45.6%, Loss: 2.7659Epoch [7/124], Batch [58/125] [#########-----------] 46.4%, Loss: 2.8860Epoch [7/124], Batch [59/125] [#########-----------] 47.2%, Loss: 2.8340Epoch [7/124], Batch [60/125] [#########-----------] 48.0%, Loss: 2.1764Epoch [7/124], Batch [61/125] [#########-----------] 48.8%, Loss: 2.7317Epoch [7/124], Batch [62/125] [#########-----------] 49.6%, Loss: 2.8212Epoch [7/124], Batch [63/125] [##########----------] 50.4%, Loss: 2.2818Epoch [7/124], Batch [64/125] [##########----------] 51.2%, Loss: 3.5624Epoch [7/124], Batch [65/125] [##########----------] 52.0%, Loss: 2.4273Epoch [7/124], Batch [66/125] [##########----------] 52.8%, Loss: 2.0839Epoch [7/124], Batch [67/125] [##########----------] 53.6%, Loss: 3.0677Epoch [7/124], Batch [68/125] [##########----------] 54.4%, Loss: 2.9880Epoch [7/124], Batch [69/125] [###########---------] 55.2%, Loss: 2.6514Epoch [7/124], Batch [70/125] [###########---------] 56.0%, Loss: 2.4325Epoch [7/124], Batch [71/125] [###########---------] 56.8%, Loss: 2.9271Epoch [7/124], Batch [72/125] [###########---------] 57.6%, Loss: 1.7284Epoch [7/124], Batch [73/125] [###########---------] 58.4%, Loss: 2.5450Epoch [7/124], Batch [74/125] [###########---------] 59.2%, Loss: 1.7096Epoch [7/124], Batch [75/125] [############--------] 60.0%, Loss: 1.5568Epoch [7/124], Batch [76/125] [############--------] 60.8%, Loss: 2.4585Epoch [7/124], Batch [77/125] [############--------] 61.6%, Loss: 2.9319Epoch [7/124], Batch [78/125] [############--------] 62.4%, Loss: 3.2826Epoch [7/124], Batch [79/125] [############--------] 63.2%, Loss: 1.4584Epoch [7/124], Batch [80/125] [############--------] 64.0%, Loss: 1.0252Epoch [7/124], Batch [81/125] [############--------] 64.8%, Loss: 1.0667Epoch [7/124], Batch [82/125] [#############-------] 65.6%, Loss: 2.4650Epoch [7/124], Batch [83/125] [#############-------] 66.4%, Loss: 3.2067Epoch [7/124], Batch [84/125] [#############-------] 67.2%, Loss: 1.5177Epoch [7/124], Batch [85/125] [#############-------] 68.0%, Loss: 1.7278Epoch [7/124], Batch [86/125] [#############-------] 68.8%, Loss: 1.7613Epoch [7/124], Batch [87/125] [#############-------] 69.6%, Loss: 2.9251Epoch [7/124], Batch [88/125] [##############------] 70.4%, Loss: 5.1308Epoch [7/124], Batch [89/125] [##############------] 71.2%, Loss: 3.9342Epoch [7/124], Batch [90/125] [##############------] 72.0%, Loss: 2.3690Epoch [7/124], Batch [91/125] [##############------] 72.8%, Loss: 2.3010Epoch [7/124], Batch [92/125] [##############------] 73.6%, Loss: 2.7001Epoch [7/124], Batch [93/125] [##############------] 74.4%, Loss: 2.5550Epoch [7/124], Batch [94/125] [###############-----] 75.2%, Loss: 1.8121Epoch [7/124], Batch [95/125] [###############-----] 76.0%, Loss: 2.3760Epoch [7/124], Batch [96/125] [###############-----] 76.8%, Loss: 2.6919Epoch [7/124], Batch [97/125] [###############-----] 77.6%, Loss: 3.3991Epoch [7/124], Batch [98/125] [###############-----] 78.4%, Loss: 1.3783Epoch [7/124], Batch [99/125] [###############-----] 79.2%, Loss: 3.3222Epoch [7/124], Batch [100/125] [################----] 80.0%, Loss: 3.7428Epoch [7/124], Batch [101/125] [################----] 80.8%, Loss: 1.6098Epoch [7/124], Batch [102/125] [################----] 81.6%, Loss: 2.5584Epoch [7/124], Batch [103/125] [################----] 82.4%, Loss: 2.9653Epoch [7/124], Batch [104/125] [################----] 83.2%, Loss: 2.4194Epoch [7/124], Batch [105/125] [################----] 84.0%, Loss: 2.3614Epoch [7/124], Batch [106/125] [################----] 84.8%, Loss: 2.7113Epoch [7/124], Batch [107/125] [#################---] 85.6%, Loss: 2.2939Epoch [7/124], Batch [108/125] [#################---] 86.4%, Loss: 2.9618Epoch [7/124], Batch [109/125] [#################---] 87.2%, Loss: 2.1067Epoch [7/124], Batch [110/125] [#################---] 88.0%, Loss: 1.8526Epoch [7/124], Batch [111/125] [#################---] 88.8%, Loss: 2.6409Epoch [7/124], Batch [112/125] [#################---] 89.6%, Loss: 1.9964Epoch [7/124], Batch [113/125] [##################--] 90.4%, Loss: 3.1779Epoch [7/124], Batch [114/125] [##################--] 91.2%, Loss: 2.4651Epoch [7/124], Batch [115/125] [##################--] 92.0%, Loss: 2.1758Epoch [7/124], Batch [116/125] [##################--] 92.8%, Loss: 1.3007Epoch [7/124], Batch [117/125] [##################--] 93.6%, Loss: 1.2508Epoch [7/124], Batch [118/125] [##################--] 94.4%, Loss: 2.0869Epoch [7/124], Batch [119/125] [###################-] 95.2%, Loss: 1.7258Epoch [7/124], Batch [120/125] [###################-] 96.0%, Loss: 2.3506Epoch [7/124], Batch [121/125] [###################-] 96.8%, Loss: 2.0377Epoch [7/124], Batch [122/125] [###################-] 97.6%, Loss: 3.8888Epoch [7/124], Batch [123/125] [###################-] 98.4%, Loss: 3.1314Epoch [7/124], Batch [124/125] [###################-] 99.2%, Loss: 1.8903Epoch [7/124], Batch [125/125] [####################] 100.0%, Loss: 2.0114
Epoch [7/124] finished. Average Loss: 2.3138
Training Accuracy: 83.80%
--- Saving checkpoint for epoch 7 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [8/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.3682Epoch [8/124], Batch [2/125] [--------------------] 1.6%, Loss: 1.4618Epoch [8/124], Batch [3/125] [--------------------] 2.4%, Loss: 1.0590Epoch [8/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.7308Epoch [8/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.9876Epoch [8/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.5297Epoch [8/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.7691Epoch [8/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.8707Epoch [8/124], Batch [9/125] [#-------------------] 7.2%, Loss: 2.0898Epoch [8/124], Batch [10/125] [#-------------------] 8.0%, Loss: 1.5809Epoch [8/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.9562Epoch [8/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.5998Epoch [8/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.3577Epoch [8/124], Batch [14/125] [##------------------] 11.2%, Loss: 1.3911Epoch [8/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.4933Epoch [8/124], Batch [16/125] [##------------------] 12.8%, Loss: 2.0903Epoch [8/124], Batch [17/125] [##------------------] 13.6%, Loss: 2.8283Epoch [8/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.6389Epoch [8/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.7817Epoch [8/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.6565Epoch [8/124], Batch [21/125] [###-----------------] 16.8%, Loss: 1.7019Epoch [8/124], Batch [22/125] [###-----------------] 17.6%, Loss: 1.0271Epoch [8/124], Batch [23/125] [###-----------------] 18.4%, Loss: 2.1517Epoch [8/124], Batch [24/125] [###-----------------] 19.2%, Loss: 1.4910Epoch [8/124], Batch [25/125] [####----------------] 20.0%, Loss: 1.3771Epoch [8/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.8870Epoch [8/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.4764Epoch [8/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.8417Epoch [8/124], Batch [29/125] [####----------------] 23.2%, Loss: 1.2269Epoch [8/124], Batch [30/125] [####----------------] 24.0%, Loss: 1.1506Epoch [8/124], Batch [31/125] [####----------------] 24.8%, Loss: 2.1609Epoch [8/124], Batch [32/125] [#####---------------] 25.6%, Loss: 1.1540Epoch [8/124], Batch [33/125] [#####---------------] 26.4%, Loss: 1.6668Epoch [8/124], Batch [34/125] [#####---------------] 27.2%, Loss: 1.6093Epoch [8/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.3712Epoch [8/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.7213Epoch [8/124], Batch [37/125] [#####---------------] 29.6%, Loss: 2.2528Epoch [8/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.9217Epoch [8/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.7136Epoch [8/124], Batch [40/125] [######--------------] 32.0%, Loss: 1.1678Epoch [8/124], Batch [41/125] [######--------------] 32.8%, Loss: 1.5542Epoch [8/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.5174Epoch [8/124], Batch [43/125] [######--------------] 34.4%, Loss: 1.1835Epoch [8/124], Batch [44/125] [#######-------------] 35.2%, Loss: 1.1491Epoch [8/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.8964Epoch [8/124], Batch [46/125] [#######-------------] 36.8%, Loss: 1.1406Epoch [8/124], Batch [47/125] [#######-------------] 37.6%, Loss: 1.7131Epoch [8/124], Batch [48/125] [#######-------------] 38.4%, Loss: 1.8427Epoch [8/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.7062Epoch [8/124], Batch [50/125] [########------------] 40.0%, Loss: 1.2882Epoch [8/124], Batch [51/125] [########------------] 40.8%, Loss: 0.9938Epoch [8/124], Batch [52/125] [########------------] 41.6%, Loss: 1.9446Epoch [8/124], Batch [53/125] [########------------] 42.4%, Loss: 1.0860Epoch [8/124], Batch [54/125] [########------------] 43.2%, Loss: 1.1506Epoch [8/124], Batch [55/125] [########------------] 44.0%, Loss: 1.3333Epoch [8/124], Batch [56/125] [########------------] 44.8%, Loss: 0.2947Epoch [8/124], Batch [57/125] [#########-----------] 45.6%, Loss: 1.6528Epoch [8/124], Batch [58/125] [#########-----------] 46.4%, Loss: 1.9654Epoch [8/124], Batch [59/125] [#########-----------] 47.2%, Loss: 1.2918Epoch [8/124], Batch [60/125] [#########-----------] 48.0%, Loss: 1.2954Epoch [8/124], Batch [61/125] [#########-----------] 48.8%, Loss: 1.3878Epoch [8/124], Batch [62/125] [#########-----------] 49.6%, Loss: 1.0421Epoch [8/124], Batch [63/125] [##########----------] 50.4%, Loss: 2.0041Epoch [8/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.7677Epoch [8/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.6786Epoch [8/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.7232Epoch [8/124], Batch [67/125] [##########----------] 53.6%, Loss: 1.2448Epoch [8/124], Batch [68/125] [##########----------] 54.4%, Loss: 1.8209Epoch [8/124], Batch [69/125] [###########---------] 55.2%, Loss: 2.4370Epoch [8/124], Batch [70/125] [###########---------] 56.0%, Loss: 2.8658Epoch [8/124], Batch [71/125] [###########---------] 56.8%, Loss: 1.2050Epoch [8/124], Batch [72/125] [###########---------] 57.6%, Loss: 1.3044Epoch [8/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.7679Epoch [8/124], Batch [74/125] [###########---------] 59.2%, Loss: 1.8487Epoch [8/124], Batch [75/125] [############--------] 60.0%, Loss: 0.9264Epoch [8/124], Batch [76/125] [############--------] 60.8%, Loss: 1.8933Epoch [8/124], Batch [77/125] [############--------] 61.6%, Loss: 1.1913Epoch [8/124], Batch [78/125] [############--------] 62.4%, Loss: 2.2911Epoch [8/124], Batch [79/125] [############--------] 63.2%, Loss: 2.3903Epoch [8/124], Batch [80/125] [############--------] 64.0%, Loss: 1.3171Epoch [8/124], Batch [81/125] [############--------] 64.8%, Loss: 1.2809Epoch [8/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.9706Epoch [8/124], Batch [83/125] [#############-------] 66.4%, Loss: 1.9928Epoch [8/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.6965Epoch [8/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.5897Epoch [8/124], Batch [86/125] [#############-------] 68.8%, Loss: 1.1074Epoch [8/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.8838Epoch [8/124], Batch [88/125] [##############------] 70.4%, Loss: 1.2330Epoch [8/124], Batch [89/125] [##############------] 71.2%, Loss: 1.4999Epoch [8/124], Batch [90/125] [##############------] 72.0%, Loss: 1.5065Epoch [8/124], Batch [91/125] [##############------] 72.8%, Loss: 1.6001Epoch [8/124], Batch [92/125] [##############------] 73.6%, Loss: 1.7807Epoch [8/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2474Epoch [8/124], Batch [94/125] [###############-----] 75.2%, Loss: 1.9054Epoch [8/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.5288Epoch [8/124], Batch [96/125] [###############-----] 76.8%, Loss: 1.9815Epoch [8/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.4102Epoch [8/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.7991Epoch [8/124], Batch [99/125] [###############-----] 79.2%, Loss: 1.3384Epoch [8/124], Batch [100/125] [################----] 80.0%, Loss: 2.1813Epoch [8/124], Batch [101/125] [################----] 80.8%, Loss: 0.9348Epoch [8/124], Batch [102/125] [################----] 81.6%, Loss: 1.1625Epoch [8/124], Batch [103/125] [################----] 82.4%, Loss: 0.4244Epoch [8/124], Batch [104/125] [################----] 83.2%, Loss: 0.6792Epoch [8/124], Batch [105/125] [################----] 84.0%, Loss: 1.0823Epoch [8/124], Batch [106/125] [################----] 84.8%, Loss: 2.4385Epoch [8/124], Batch [107/125] [#################---] 85.6%, Loss: 0.9596Epoch [8/124], Batch [108/125] [#################---] 86.4%, Loss: 2.1554Epoch [8/124], Batch [109/125] [#################---] 87.2%, Loss: 0.5119Epoch [8/124], Batch [110/125] [#################---] 88.0%, Loss: 0.9367Epoch [8/124], Batch [111/125] [#################---] 88.8%, Loss: 1.2231Epoch [8/124], Batch [112/125] [#################---] 89.6%, Loss: 1.6787Epoch [8/124], Batch [113/125] [##################--] 90.4%, Loss: 0.4291Epoch [8/124], Batch [114/125] [##################--] 91.2%, Loss: 1.2681Epoch [8/124], Batch [115/125] [##################--] 92.0%, Loss: 0.5810Epoch [8/124], Batch [116/125] [##################--] 92.8%, Loss: 1.5149Epoch [8/124], Batch [117/125] [##################--] 93.6%, Loss: 1.2447Epoch [8/124], Batch [118/125] [##################--] 94.4%, Loss: 0.6206Epoch [8/124], Batch [119/125] [###################-] 95.2%, Loss: 1.6764Epoch [8/124], Batch [120/125] [###################-] 96.0%, Loss: 0.9230Epoch [8/124], Batch [121/125] [###################-] 96.8%, Loss: 2.7684Epoch [8/124], Batch [122/125] [###################-] 97.6%, Loss: 0.5473Epoch [8/124], Batch [123/125] [###################-] 98.4%, Loss: 2.1551Epoch [8/124], Batch [124/125] [###################-] 99.2%, Loss: 0.5472Epoch [8/124], Batch [125/125] [####################] 100.0%, Loss: 1.7163
Epoch [8/124] finished. Average Loss: 1.2651
Training Accuracy: 97.80%
--- Saving checkpoint for epoch 8 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [9/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.4738Epoch [9/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.2785Epoch [9/124], Batch [3/125] [--------------------] 2.4%, Loss: 1.2263Epoch [9/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.4300Epoch [9/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.5284Epoch [9/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.7399Epoch [9/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.3427Epoch [9/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.4481Epoch [9/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.5444Epoch [9/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.2899Epoch [9/124], Batch [11/125] [#-------------------] 8.8%, Loss: 1.3564Epoch [9/124], Batch [12/125] [#-------------------] 9.6%, Loss: 1.7980Epoch [9/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.4902Epoch [9/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.8214Epoch [9/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.7443Epoch [9/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.9668Epoch [9/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3912Epoch [9/124], Batch [18/125] [##------------------] 14.4%, Loss: 1.3666Epoch [9/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.3785Epoch [9/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.3312Epoch [9/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.9786Epoch [9/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.5726Epoch [9/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.2413Epoch [9/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.3097Epoch [9/124], Batch [25/125] [####----------------] 20.0%, Loss: 1.0423Epoch [9/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.5944Epoch [9/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.2234Epoch [9/124], Batch [28/125] [####----------------] 22.4%, Loss: 1.2069Epoch [9/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.9476Epoch [9/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.2520Epoch [9/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.6840Epoch [9/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.3718Epoch [9/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.9183Epoch [9/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.3456Epoch [9/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.1869Epoch [9/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.4905Epoch [9/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0997Epoch [9/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.5139Epoch [9/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.2924Epoch [9/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.4687Epoch [9/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.3143Epoch [9/124], Batch [42/125] [######--------------] 33.6%, Loss: 1.1120Epoch [9/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.6095Epoch [9/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.3702Epoch [9/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.6721Epoch [9/124], Batch [46/125] [#######-------------] 36.8%, Loss: 2.2771Epoch [9/124], Batch [47/125] [#######-------------] 37.6%, Loss: 1.3045Epoch [9/124], Batch [48/125] [#######-------------] 38.4%, Loss: 1.3183Epoch [9/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.4367Epoch [9/124], Batch [50/125] [########------------] 40.0%, Loss: 0.5436Epoch [9/124], Batch [51/125] [########------------] 40.8%, Loss: 0.3439Epoch [9/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1801Epoch [9/124], Batch [53/125] [########------------] 42.4%, Loss: 0.5490Epoch [9/124], Batch [54/125] [########------------] 43.2%, Loss: 0.4107Epoch [9/124], Batch [55/125] [########------------] 44.0%, Loss: 0.4154Epoch [9/124], Batch [56/125] [########------------] 44.8%, Loss: 0.7320Epoch [9/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.8920Epoch [9/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1567Epoch [9/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2602Epoch [9/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0938Epoch [9/124], Batch [61/125] [#########-----------] 48.8%, Loss: 1.0203Epoch [9/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.8112Epoch [9/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.7878Epoch [9/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.5816Epoch [9/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.7578Epoch [9/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.9643Epoch [9/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.5517Epoch [9/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.4710Epoch [9/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.4604Epoch [9/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.7812Epoch [9/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.3777Epoch [9/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.8448Epoch [9/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.7176Epoch [9/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2910Epoch [9/124], Batch [75/125] [############--------] 60.0%, Loss: 0.3309Epoch [9/124], Batch [76/125] [############--------] 60.8%, Loss: 0.4877Epoch [9/124], Batch [77/125] [############--------] 61.6%, Loss: 0.2542Epoch [9/124], Batch [78/125] [############--------] 62.4%, Loss: 0.3302Epoch [9/124], Batch [79/125] [############--------] 63.2%, Loss: 0.8056Epoch [9/124], Batch [80/125] [############--------] 64.0%, Loss: 0.2907Epoch [9/124], Batch [81/125] [############--------] 64.8%, Loss: 1.8182Epoch [9/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.4381Epoch [9/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1526Epoch [9/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.8512Epoch [9/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.6004Epoch [9/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.3947Epoch [9/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.8335Epoch [9/124], Batch [88/125] [##############------] 70.4%, Loss: 0.2836Epoch [9/124], Batch [89/125] [##############------] 71.2%, Loss: 1.1874Epoch [9/124], Batch [90/125] [##############------] 72.0%, Loss: 0.7358Epoch [9/124], Batch [91/125] [##############------] 72.8%, Loss: 0.3908Epoch [9/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4180Epoch [9/124], Batch [93/125] [##############------] 74.4%, Loss: 0.5556Epoch [9/124], Batch [94/125] [###############-----] 75.2%, Loss: 1.2871Epoch [9/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2698Epoch [9/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.7005Epoch [9/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1910Epoch [9/124], Batch [98/125] [###############-----] 78.4%, Loss: 1.5668Epoch [9/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.4366Epoch [9/124], Batch [100/125] [################----] 80.0%, Loss: 1.0133Epoch [9/124], Batch [101/125] [################----] 80.8%, Loss: 0.7000Epoch [9/124], Batch [102/125] [################----] 81.6%, Loss: 0.2663Epoch [9/124], Batch [103/125] [################----] 82.4%, Loss: 0.9557Epoch [9/124], Batch [104/125] [################----] 83.2%, Loss: 1.2609Epoch [9/124], Batch [105/125] [################----] 84.0%, Loss: 1.0593Epoch [9/124], Batch [106/125] [################----] 84.8%, Loss: 1.0833Epoch [9/124], Batch [107/125] [#################---] 85.6%, Loss: 0.9189Epoch [9/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2154Epoch [9/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0419Epoch [9/124], Batch [110/125] [#################---] 88.0%, Loss: 0.6421Epoch [9/124], Batch [111/125] [#################---] 88.8%, Loss: 0.8176Epoch [9/124], Batch [112/125] [#################---] 89.6%, Loss: 0.6085Epoch [9/124], Batch [113/125] [##################--] 90.4%, Loss: 0.4987Epoch [9/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4359Epoch [9/124], Batch [115/125] [##################--] 92.0%, Loss: 0.6466Epoch [9/124], Batch [116/125] [##################--] 92.8%, Loss: 0.2621Epoch [9/124], Batch [117/125] [##################--] 93.6%, Loss: 0.5513Epoch [9/124], Batch [118/125] [##################--] 94.4%, Loss: 0.2419Epoch [9/124], Batch [119/125] [###################-] 95.2%, Loss: 0.9759Epoch [9/124], Batch [120/125] [###################-] 96.0%, Loss: 0.8531Epoch [9/124], Batch [121/125] [###################-] 96.8%, Loss: 0.5934Epoch [9/124], Batch [122/125] [###################-] 97.6%, Loss: 0.5605Epoch [9/124], Batch [123/125] [###################-] 98.4%, Loss: 0.7511Epoch [9/124], Batch [124/125] [###################-] 99.2%, Loss: 0.6725Epoch [9/124], Batch [125/125] [####################] 100.0%, Loss: 1.4563
Epoch [9/124] finished. Average Loss: 0.6463
Training Accuracy: 97.80%
--- Saving checkpoint for epoch 9 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [10/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.4789Epoch [10/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.2908Epoch [10/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.2585Epoch [10/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.1648Epoch [10/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1170Epoch [10/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0921Epoch [10/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0469Epoch [10/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0554Epoch [10/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2129Epoch [10/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0983Epoch [10/124], Batch [11/125] [#-------------------] 8.8%, Loss: 2.5500Epoch [10/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.6418Epoch [10/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3976Epoch [10/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.3861Epoch [10/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0416Epoch [10/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2507Epoch [10/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.4504Epoch [10/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0519Epoch [10/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.4420Epoch [10/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.2889Epoch [10/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0129Epoch [10/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1962Epoch [10/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1366Epoch [10/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.8935Epoch [10/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.6327Epoch [10/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.3050Epoch [10/124], Batch [27/125] [####----------------] 21.6%, Loss: 1.0337Epoch [10/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.4368Epoch [10/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1283Epoch [10/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1729Epoch [10/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.2335Epoch [10/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0372Epoch [10/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.7965Epoch [10/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0670Epoch [10/124], Batch [35/125] [#####---------------] 28.0%, Loss: 1.2848Epoch [10/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1840Epoch [10/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.4265Epoch [10/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.3264Epoch [10/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.4547Epoch [10/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1439Epoch [10/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0697Epoch [10/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.6238Epoch [10/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.4785Epoch [10/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.4017Epoch [10/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1743Epoch [10/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1261Epoch [10/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.4291Epoch [10/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.4592Epoch [10/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0682Epoch [10/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2407Epoch [10/124], Batch [51/125] [########------------] 40.8%, Loss: 0.4931Epoch [10/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1466Epoch [10/124], Batch [53/125] [########------------] 42.4%, Loss: 1.1652Epoch [10/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1402Epoch [10/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0828Epoch [10/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1086Epoch [10/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.3319Epoch [10/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.2741Epoch [10/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0714Epoch [10/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.3724Epoch [10/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2525Epoch [10/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.3386Epoch [10/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.6550Epoch [10/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.7750Epoch [10/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1728Epoch [10/124], Batch [66/125] [##########----------] 52.8%, Loss: 1.2047Epoch [10/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.7779Epoch [10/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.3521Epoch [10/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.3779Epoch [10/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.2976Epoch [10/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0641Epoch [10/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.4298Epoch [10/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.2524Epoch [10/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.3607Epoch [10/124], Batch [75/125] [############--------] 60.0%, Loss: 1.0307Epoch [10/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0916Epoch [10/124], Batch [77/125] [############--------] 61.6%, Loss: 0.2057Epoch [10/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1350Epoch [10/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0558Epoch [10/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1389Epoch [10/124], Batch [81/125] [############--------] 64.8%, Loss: 0.7365Epoch [10/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.5269Epoch [10/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.3263Epoch [10/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.5696Epoch [10/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.2509Epoch [10/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0739Epoch [10/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1084Epoch [10/124], Batch [88/125] [##############------] 70.4%, Loss: 0.2516Epoch [10/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3275Epoch [10/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1716Epoch [10/124], Batch [91/125] [##############------] 72.8%, Loss: 0.5250Epoch [10/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4758Epoch [10/124], Batch [93/125] [##############------] 74.4%, Loss: 2.0300Epoch [10/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.3006Epoch [10/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.4711Epoch [10/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1811Epoch [10/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.2407Epoch [10/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0413Epoch [10/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2488Epoch [10/124], Batch [100/125] [################----] 80.0%, Loss: 0.3023Epoch [10/124], Batch [101/125] [################----] 80.8%, Loss: 0.7003Epoch [10/124], Batch [102/125] [################----] 81.6%, Loss: 1.0387Epoch [10/124], Batch [103/125] [################----] 82.4%, Loss: 0.6193Epoch [10/124], Batch [104/125] [################----] 83.2%, Loss: 0.4633Epoch [10/124], Batch [105/125] [################----] 84.0%, Loss: 0.2407Epoch [10/124], Batch [106/125] [################----] 84.8%, Loss: 0.5628Epoch [10/124], Batch [107/125] [#################---] 85.6%, Loss: 0.4102Epoch [10/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0788Epoch [10/124], Batch [109/125] [#################---] 87.2%, Loss: 0.3216Epoch [10/124], Batch [110/125] [#################---] 88.0%, Loss: 0.2798Epoch [10/124], Batch [111/125] [#################---] 88.8%, Loss: 0.4448Epoch [10/124], Batch [112/125] [#################---] 89.6%, Loss: 0.2095Epoch [10/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1084Epoch [10/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0873Epoch [10/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0759Epoch [10/124], Batch [116/125] [##################--] 92.8%, Loss: 0.6975Epoch [10/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1560Epoch [10/124], Batch [118/125] [##################--] 94.4%, Loss: 0.4503Epoch [10/124], Batch [119/125] [###################-] 95.2%, Loss: 0.5262Epoch [10/124], Batch [120/125] [###################-] 96.0%, Loss: 0.4201Epoch [10/124], Batch [121/125] [###################-] 96.8%, Loss: 0.1519Epoch [10/124], Batch [122/125] [###################-] 97.6%, Loss: 0.3266Epoch [10/124], Batch [123/125] [###################-] 98.4%, Loss: 0.3222Epoch [10/124], Batch [124/125] [###################-] 99.2%, Loss: 0.5418Epoch [10/124], Batch [125/125] [####################] 100.0%, Loss: 0.1418
Epoch [10/124] finished. Average Loss: 0.3759
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 10 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [11/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.3234Epoch [11/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1343Epoch [11/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.4785Epoch [11/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.1963Epoch [11/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.3907Epoch [11/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.6809Epoch [11/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.5409Epoch [11/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.2472Epoch [11/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1412Epoch [11/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0495Epoch [11/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1256Epoch [11/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1004Epoch [11/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2019Epoch [11/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0974Epoch [11/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0999Epoch [11/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.5559Epoch [11/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.2454Epoch [11/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.2508Epoch [11/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.1650Epoch [11/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.2073Epoch [11/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.6605Epoch [11/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2061Epoch [11/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0410Epoch [11/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0202Epoch [11/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1697Epoch [11/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.2053Epoch [11/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0881Epoch [11/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.4969Epoch [11/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2476Epoch [11/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0672Epoch [11/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1169Epoch [11/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.4960Epoch [11/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.4266Epoch [11/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.3204Epoch [11/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.4861Epoch [11/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.2176Epoch [11/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1049Epoch [11/124], Batch [38/125] [######--------------] 30.4%, Loss: 1.5999Epoch [11/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1260Epoch [11/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1541Epoch [11/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.7236Epoch [11/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.6728Epoch [11/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1877Epoch [11/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.1291Epoch [11/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1692Epoch [11/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.5060Epoch [11/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1676Epoch [11/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0874Epoch [11/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0598Epoch [11/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0631Epoch [11/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0583Epoch [11/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0633Epoch [11/124], Batch [53/125] [########------------] 42.4%, Loss: 0.1018Epoch [11/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0957Epoch [11/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2587Epoch [11/124], Batch [56/125] [########------------] 44.8%, Loss: 0.9000Epoch [11/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1555Epoch [11/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1882Epoch [11/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1241Epoch [11/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.4308Epoch [11/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2862Epoch [11/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0222Epoch [11/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0507Epoch [11/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0838Epoch [11/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.3443Epoch [11/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0282Epoch [11/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0855Epoch [11/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.4082Epoch [11/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0817Epoch [11/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.2918Epoch [11/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.2981Epoch [11/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.4500Epoch [11/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0610Epoch [11/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1832Epoch [11/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0327Epoch [11/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2682Epoch [11/124], Batch [77/125] [############--------] 61.6%, Loss: 0.5131Epoch [11/124], Batch [78/125] [############--------] 62.4%, Loss: 0.4824Epoch [11/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1260Epoch [11/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0140Epoch [11/124], Batch [81/125] [############--------] 64.8%, Loss: 0.3530Epoch [11/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.2205Epoch [11/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.5081Epoch [11/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0875Epoch [11/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.5877Epoch [11/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.2422Epoch [11/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.2745Epoch [11/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0181Epoch [11/124], Batch [89/125] [##############------] 71.2%, Loss: 1.6366Epoch [11/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0988Epoch [11/124], Batch [91/125] [##############------] 72.8%, Loss: 0.4449Epoch [11/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1782Epoch [11/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0739Epoch [11/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0824Epoch [11/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0203Epoch [11/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0146Epoch [11/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.4715Epoch [11/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0911Epoch [11/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2223Epoch [11/124], Batch [100/125] [################----] 80.0%, Loss: 0.2753Epoch [11/124], Batch [101/125] [################----] 80.8%, Loss: 0.2366Epoch [11/124], Batch [102/125] [################----] 81.6%, Loss: 0.5607Epoch [11/124], Batch [103/125] [################----] 82.4%, Loss: 1.1901Epoch [11/124], Batch [104/125] [################----] 83.2%, Loss: 0.3974Epoch [11/124], Batch [105/125] [################----] 84.0%, Loss: 0.2354Epoch [11/124], Batch [106/125] [################----] 84.8%, Loss: 0.5439Epoch [11/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0577Epoch [11/124], Batch [108/125] [#################---] 86.4%, Loss: 0.6829Epoch [11/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2227Epoch [11/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0467Epoch [11/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1997Epoch [11/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0777Epoch [11/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0876Epoch [11/124], Batch [114/125] [##################--] 91.2%, Loss: 0.3460Epoch [11/124], Batch [115/125] [##################--] 92.0%, Loss: 1.1658Epoch [11/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0533Epoch [11/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1824Epoch [11/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1343Epoch [11/124], Batch [119/125] [###################-] 95.2%, Loss: 0.3038Epoch [11/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2928Epoch [11/124], Batch [121/125] [###################-] 96.8%, Loss: 0.3364Epoch [11/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2088Epoch [11/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1650Epoch [11/124], Batch [124/125] [###################-] 99.2%, Loss: 0.2353Epoch [11/124], Batch [125/125] [####################] 100.0%, Loss: 0.1120
Epoch [11/124] finished. Average Loss: 0.2857
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 11 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [12/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0710Epoch [12/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0123Epoch [12/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0140Epoch [12/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0119Epoch [12/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0633Epoch [12/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0459Epoch [12/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0336Epoch [12/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.2074Epoch [12/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1671Epoch [12/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.2903Epoch [12/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2063Epoch [12/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1295Epoch [12/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.1822Epoch [12/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.1239Epoch [12/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0548Epoch [12/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2618Epoch [12/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3724Epoch [12/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.4373Epoch [12/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.2765Epoch [12/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0481Epoch [12/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0418Epoch [12/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0084Epoch [12/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0469Epoch [12/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.3294Epoch [12/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1549Epoch [12/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0322Epoch [12/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0429Epoch [12/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.2697Epoch [12/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0438Epoch [12/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1467Epoch [12/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1902Epoch [12/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.9853Epoch [12/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1314Epoch [12/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.3601Epoch [12/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.6817Epoch [12/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0111Epoch [12/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0756Epoch [12/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1010Epoch [12/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1409Epoch [12/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.2619Epoch [12/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0247Epoch [12/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0225Epoch [12/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0329Epoch [12/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0381Epoch [12/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.4498Epoch [12/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0418Epoch [12/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.7896Epoch [12/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0486Epoch [12/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0909Epoch [12/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1935Epoch [12/124], Batch [51/125] [########------------] 40.8%, Loss: 0.2804Epoch [12/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1861Epoch [12/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0677Epoch [12/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0859Epoch [12/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2128Epoch [12/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0296Epoch [12/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0217Epoch [12/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0159Epoch [12/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1068Epoch [12/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.3093Epoch [12/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2948Epoch [12/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.2654Epoch [12/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0439Epoch [12/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0974Epoch [12/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0040Epoch [12/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0980Epoch [12/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1675Epoch [12/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0544Epoch [12/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1897Epoch [12/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0654Epoch [12/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0204Epoch [12/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0704Epoch [12/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0406Epoch [12/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0951Epoch [12/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0572Epoch [12/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0381Epoch [12/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0534Epoch [12/124], Batch [78/125] [############--------] 62.4%, Loss: 0.3790Epoch [12/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0190Epoch [12/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0340Epoch [12/124], Batch [81/125] [############--------] 64.8%, Loss: 0.2323Epoch [12/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.3017Epoch [12/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0920Epoch [12/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.1182Epoch [12/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1659Epoch [12/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.2332Epoch [12/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0271Epoch [12/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0798Epoch [12/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0951Epoch [12/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0451Epoch [12/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1203Epoch [12/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0299Epoch [12/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0427Epoch [12/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0466Epoch [12/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.1231Epoch [12/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0538Epoch [12/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.2668Epoch [12/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1676Epoch [12/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1420Epoch [12/124], Batch [100/125] [################----] 80.0%, Loss: 0.0151Epoch [12/124], Batch [101/125] [################----] 80.8%, Loss: 0.0362Epoch [12/124], Batch [102/125] [################----] 81.6%, Loss: 0.0519Epoch [12/124], Batch [103/125] [################----] 82.4%, Loss: 0.0193Epoch [12/124], Batch [104/125] [################----] 83.2%, Loss: 0.0466Epoch [12/124], Batch [105/125] [################----] 84.0%, Loss: 0.1864Epoch [12/124], Batch [106/125] [################----] 84.8%, Loss: 0.1014Epoch [12/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0645Epoch [12/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0393Epoch [12/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1158Epoch [12/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0088Epoch [12/124], Batch [111/125] [#################---] 88.8%, Loss: 0.6549Epoch [12/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0447Epoch [12/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2615Epoch [12/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1020Epoch [12/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1307Epoch [12/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1198Epoch [12/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0759Epoch [12/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0440Epoch [12/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0284Epoch [12/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0378Epoch [12/124], Batch [121/125] [###################-] 96.8%, Loss: 0.1464Epoch [12/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0427Epoch [12/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0171Epoch [12/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0231Epoch [12/124], Batch [125/125] [####################] 100.0%, Loss: 0.2676
Epoch [12/124] finished. Average Loss: 0.1381
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 12 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [13/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0123Epoch [13/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0088Epoch [13/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0749Epoch [13/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0505Epoch [13/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0195Epoch [13/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0901Epoch [13/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.5939Epoch [13/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1979Epoch [13/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2298Epoch [13/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0158Epoch [13/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0120Epoch [13/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0275Epoch [13/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0377Epoch [13/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.2680Epoch [13/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0087Epoch [13/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0296Epoch [13/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0146Epoch [13/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0178Epoch [13/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0155Epoch [13/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0780Epoch [13/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0879Epoch [13/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0539Epoch [13/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0174Epoch [13/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0337Epoch [13/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0194Epoch [13/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.4710Epoch [13/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0899Epoch [13/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.1073Epoch [13/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0122Epoch [13/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0173Epoch [13/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0775Epoch [13/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2315Epoch [13/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0691Epoch [13/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0120Epoch [13/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0126Epoch [13/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0272Epoch [13/124], Batch [37/125] [#####---------------] 29.6%, Loss: 1.3047Epoch [13/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0156Epoch [13/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0336Epoch [13/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1360Epoch [13/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0456Epoch [13/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0208Epoch [13/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0183Epoch [13/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0278Epoch [13/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0780Epoch [13/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0184Epoch [13/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0163Epoch [13/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0202Epoch [13/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0478Epoch [13/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0275Epoch [13/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0607Epoch [13/124], Batch [52/125] [########------------] 41.6%, Loss: 0.8941Epoch [13/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0479Epoch [13/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0086Epoch [13/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0409Epoch [13/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0758Epoch [13/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1548Epoch [13/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0393Epoch [13/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1557Epoch [13/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0468Epoch [13/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0227Epoch [13/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0128Epoch [13/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0323Epoch [13/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.6354Epoch [13/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0109Epoch [13/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0510Epoch [13/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.2198Epoch [13/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0195Epoch [13/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0677Epoch [13/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0563Epoch [13/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0278Epoch [13/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0901Epoch [13/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0139Epoch [13/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0229Epoch [13/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0296Epoch [13/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0756Epoch [13/124], Batch [77/125] [############--------] 61.6%, Loss: 0.3451Epoch [13/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0525Epoch [13/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1830Epoch [13/124], Batch [80/125] [############--------] 64.0%, Loss: 0.2011Epoch [13/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1340Epoch [13/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0108Epoch [13/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.9648Epoch [13/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0880Epoch [13/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0538Epoch [13/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0753Epoch [13/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0580Epoch [13/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0660Epoch [13/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0314Epoch [13/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0144Epoch [13/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0463Epoch [13/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0060Epoch [13/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1308Epoch [13/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.4398Epoch [13/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.1082Epoch [13/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1661Epoch [13/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1340Epoch [13/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1372Epoch [13/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0108Epoch [13/124], Batch [100/125] [################----] 80.0%, Loss: 0.3625Epoch [13/124], Batch [101/125] [################----] 80.8%, Loss: 0.2299Epoch [13/124], Batch [102/125] [################----] 81.6%, Loss: 0.0672Epoch [13/124], Batch [103/125] [################----] 82.4%, Loss: 0.0687Epoch [13/124], Batch [104/125] [################----] 83.2%, Loss: 0.0445Epoch [13/124], Batch [105/125] [################----] 84.0%, Loss: 0.0251Epoch [13/124], Batch [106/125] [################----] 84.8%, Loss: 0.0728Epoch [13/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0289Epoch [13/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2748Epoch [13/124], Batch [109/125] [#################---] 87.2%, Loss: 0.7656Epoch [13/124], Batch [110/125] [#################---] 88.0%, Loss: 0.4426Epoch [13/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0635Epoch [13/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0257Epoch [13/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0592Epoch [13/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1275Epoch [13/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0283Epoch [13/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0298Epoch [13/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0051Epoch [13/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1011Epoch [13/124], Batch [119/125] [###################-] 95.2%, Loss: 0.7548Epoch [13/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0042Epoch [13/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0127Epoch [13/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0393Epoch [13/124], Batch [123/125] [###################-] 98.4%, Loss: 0.3375Epoch [13/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1124Epoch [13/124], Batch [125/125] [####################] 100.0%, Loss: 0.0696
Epoch [13/124] finished. Average Loss: 0.1238
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 13 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [14/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0185Epoch [14/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0236Epoch [14/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0790Epoch [14/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0500Epoch [14/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0043Epoch [14/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.1016Epoch [14/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0531Epoch [14/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0810Epoch [14/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1084Epoch [14/124], Batch [10/125] [#-------------------] 8.0%, Loss: 1.5260Epoch [14/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0250Epoch [14/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.3264Epoch [14/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0067Epoch [14/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.1518Epoch [14/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.1406Epoch [14/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0274Epoch [14/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0205Epoch [14/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0829Epoch [14/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0935Epoch [14/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0398Epoch [14/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1169Epoch [14/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2323Epoch [14/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0556Epoch [14/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.4057Epoch [14/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0747Epoch [14/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0457Epoch [14/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0164Epoch [14/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0145Epoch [14/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0616Epoch [14/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0558Epoch [14/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0451Epoch [14/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0223Epoch [14/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0201Epoch [14/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1561Epoch [14/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0197Epoch [14/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0381Epoch [14/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.6212Epoch [14/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0290Epoch [14/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0531Epoch [14/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0679Epoch [14/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1247Epoch [14/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0636Epoch [14/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1328Epoch [14/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0254Epoch [14/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.2399Epoch [14/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0234Epoch [14/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0198Epoch [14/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1071Epoch [14/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0343Epoch [14/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0405Epoch [14/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0271Epoch [14/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1279Epoch [14/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0138Epoch [14/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0102Epoch [14/124], Batch [55/125] [########------------] 44.0%, Loss: 0.6170Epoch [14/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1191Epoch [14/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0625Epoch [14/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1180Epoch [14/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1571Epoch [14/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0230Epoch [14/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.1185Epoch [14/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0401Epoch [14/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0194Epoch [14/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2056Epoch [14/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0346Epoch [14/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1834Epoch [14/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0568Epoch [14/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0061Epoch [14/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1591Epoch [14/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.2903Epoch [14/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.3775Epoch [14/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0263Epoch [14/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0531Epoch [14/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0579Epoch [14/124], Batch [75/125] [############--------] 60.0%, Loss: 0.2301Epoch [14/124], Batch [76/125] [############--------] 60.8%, Loss: 1.4191Epoch [14/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0680Epoch [14/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1358Epoch [14/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0017Epoch [14/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1050Epoch [14/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0681Epoch [14/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0405Epoch [14/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0903Epoch [14/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0251Epoch [14/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1342Epoch [14/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0964Epoch [14/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0267Epoch [14/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0246Epoch [14/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2487Epoch [14/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0477Epoch [14/124], Batch [91/125] [##############------] 72.8%, Loss: 0.4263Epoch [14/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0644Epoch [14/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0785Epoch [14/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0803Epoch [14/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.1080Epoch [14/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1528Epoch [14/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1829Epoch [14/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0509Epoch [14/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0971Epoch [14/124], Batch [100/125] [################----] 80.0%, Loss: 0.0664Epoch [14/124], Batch [101/125] [################----] 80.8%, Loss: 0.0389Epoch [14/124], Batch [102/125] [################----] 81.6%, Loss: 0.0207Epoch [14/124], Batch [103/125] [################----] 82.4%, Loss: 0.1365Epoch [14/124], Batch [104/125] [################----] 83.2%, Loss: 0.0865Epoch [14/124], Batch [105/125] [################----] 84.0%, Loss: 0.0118Epoch [14/124], Batch [106/125] [################----] 84.8%, Loss: 0.0889Epoch [14/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0024Epoch [14/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0477Epoch [14/124], Batch [109/125] [#################---] 87.2%, Loss: 0.4601Epoch [14/124], Batch [110/125] [#################---] 88.0%, Loss: 0.5542Epoch [14/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0164Epoch [14/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1010Epoch [14/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1865Epoch [14/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0464Epoch [14/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2978Epoch [14/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0388Epoch [14/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0893Epoch [14/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0126Epoch [14/124], Batch [119/125] [###################-] 95.2%, Loss: 0.8887Epoch [14/124], Batch [120/125] [###################-] 96.0%, Loss: 0.3242Epoch [14/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0410Epoch [14/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0595Epoch [14/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0687Epoch [14/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1395Epoch [14/124], Batch [125/125] [####################] 100.0%, Loss: 0.0108
Epoch [14/124] finished. Average Loss: 0.1333
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 14 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [15/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1601Epoch [15/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0427Epoch [15/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0775Epoch [15/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0067Epoch [15/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.4991Epoch [15/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0593Epoch [15/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1976Epoch [15/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0397Epoch [15/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0025Epoch [15/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0176Epoch [15/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.4783Epoch [15/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0254Epoch [15/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0054Epoch [15/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.4382Epoch [15/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0675Epoch [15/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1880Epoch [15/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1129Epoch [15/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0120Epoch [15/124], Batch [19/125] [###-----------------] 15.2%, Loss: 1.5403Epoch [15/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0067Epoch [15/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0112Epoch [15/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0777Epoch [15/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0155Epoch [15/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.3795Epoch [15/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.4004Epoch [15/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0905Epoch [15/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0219Epoch [15/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0260Epoch [15/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0085Epoch [15/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0270Epoch [15/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0189Epoch [15/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0331Epoch [15/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0533Epoch [15/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0255Epoch [15/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.7474Epoch [15/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0622Epoch [15/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0265Epoch [15/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0504Epoch [15/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0422Epoch [15/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1476Epoch [15/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0685Epoch [15/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0316Epoch [15/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0949Epoch [15/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.7606Epoch [15/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0529Epoch [15/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.2925Epoch [15/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0132Epoch [15/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0449Epoch [15/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0881Epoch [15/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0077Epoch [15/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0734Epoch [15/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1636Epoch [15/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0420Epoch [15/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0652Epoch [15/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0410Epoch [15/124], Batch [56/125] [########------------] 44.8%, Loss: 0.3776Epoch [15/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.4599Epoch [15/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.8279Epoch [15/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0911Epoch [15/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.3366Epoch [15/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0564Epoch [15/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.4862Epoch [15/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0109Epoch [15/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.3348Epoch [15/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1385Epoch [15/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1302Epoch [15/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1759Epoch [15/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0281Epoch [15/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.5219Epoch [15/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.2587Epoch [15/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.1916Epoch [15/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1213Epoch [15/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.1384Epoch [15/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1054Epoch [15/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0788Epoch [15/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0041Epoch [15/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1143Epoch [15/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0217Epoch [15/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1196Epoch [15/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0316Epoch [15/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0304Epoch [15/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.3352Epoch [15/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1732Epoch [15/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.2607Epoch [15/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0170Epoch [15/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0809Epoch [15/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.2838Epoch [15/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0042Epoch [15/124], Batch [89/125] [##############------] 71.2%, Loss: 1.0480Epoch [15/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0020Epoch [15/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0729Epoch [15/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2853Epoch [15/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0120Epoch [15/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.6671Epoch [15/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0919Epoch [15/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0100Epoch [15/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0775Epoch [15/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1335Epoch [15/124], Batch [99/125] [###############-----] 79.2%, Loss: 1.1632Epoch [15/124], Batch [100/125] [################----] 80.0%, Loss: 0.1470Epoch [15/124], Batch [101/125] [################----] 80.8%, Loss: 0.1986Epoch [15/124], Batch [102/125] [################----] 81.6%, Loss: 0.0522Epoch [15/124], Batch [103/125] [################----] 82.4%, Loss: 0.2399Epoch [15/124], Batch [104/125] [################----] 83.2%, Loss: 0.4056Epoch [15/124], Batch [105/125] [################----] 84.0%, Loss: 0.1637Epoch [15/124], Batch [106/125] [################----] 84.8%, Loss: 0.5067Epoch [15/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1387Epoch [15/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1261Epoch [15/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0908Epoch [15/124], Batch [110/125] [#################---] 88.0%, Loss: 0.5860Epoch [15/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1236Epoch [15/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1787Epoch [15/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0423Epoch [15/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4491Epoch [15/124], Batch [115/125] [##################--] 92.0%, Loss: 1.0984Epoch [15/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1460Epoch [15/124], Batch [117/125] [##################--] 93.6%, Loss: 0.4482Epoch [15/124], Batch [118/125] [##################--] 94.4%, Loss: 1.0509Epoch [15/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0473Epoch [15/124], Batch [120/125] [###################-] 96.0%, Loss: 0.6961Epoch [15/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0227Epoch [15/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0326Epoch [15/124], Batch [123/125] [###################-] 98.4%, Loss: 0.3105Epoch [15/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1878Epoch [15/124], Batch [125/125] [####################] 100.0%, Loss: 0.9386
Epoch [15/124] finished. Average Loss: 0.2114
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 15 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [16/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.3643Epoch [16/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0876Epoch [16/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.2352Epoch [16/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.3751Epoch [16/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0326Epoch [16/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0733Epoch [16/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1306Epoch [16/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0403Epoch [16/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2391Epoch [16/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.2407Epoch [16/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2890Epoch [16/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1962Epoch [16/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3553Epoch [16/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0324Epoch [16/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0684Epoch [16/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0964Epoch [16/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0427Epoch [16/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0171Epoch [16/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.1342Epoch [16/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.5159Epoch [16/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0302Epoch [16/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0532Epoch [16/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.2515Epoch [16/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1886Epoch [16/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3075Epoch [16/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.2694Epoch [16/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0960Epoch [16/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.6142Epoch [16/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0491Epoch [16/124], Batch [30/125] [####----------------] 24.0%, Loss: 1.6708Epoch [16/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0970Epoch [16/124], Batch [32/125] [#####---------------] 25.6%, Loss: 1.7243Epoch [16/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.3399Epoch [16/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0913Epoch [16/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.1931Epoch [16/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0981Epoch [16/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.4336Epoch [16/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1686Epoch [16/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3854Epoch [16/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0839Epoch [16/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1368Epoch [16/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0994Epoch [16/124], Batch [43/125] [######--------------] 34.4%, Loss: 1.4092Epoch [16/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0451Epoch [16/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0981Epoch [16/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1963Epoch [16/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.4891Epoch [16/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0360Epoch [16/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.6017Epoch [16/124], Batch [50/125] [########------------] 40.0%, Loss: 0.3723Epoch [16/124], Batch [51/125] [########------------] 40.8%, Loss: 0.2922Epoch [16/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1240Epoch [16/124], Batch [53/125] [########------------] 42.4%, Loss: 0.3604Epoch [16/124], Batch [54/125] [########------------] 43.2%, Loss: 0.2216Epoch [16/124], Batch [55/125] [########------------] 44.0%, Loss: 0.4957Epoch [16/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0718Epoch [16/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0310Epoch [16/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.8198Epoch [16/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.7731Epoch [16/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0561Epoch [16/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2068Epoch [16/124], Batch [62/125] [#########-----------] 49.6%, Loss: 1.2918Epoch [16/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0788Epoch [16/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2446Epoch [16/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0489Epoch [16/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0106Epoch [16/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1045Epoch [16/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0663Epoch [16/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.2010Epoch [16/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0227Epoch [16/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0569Epoch [16/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1040Epoch [16/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0628Epoch [16/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.3835Epoch [16/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0556Epoch [16/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2032Epoch [16/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0494Epoch [16/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1483Epoch [16/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0268Epoch [16/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1106Epoch [16/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0389Epoch [16/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1223Epoch [16/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1777Epoch [16/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0581Epoch [16/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0046Epoch [16/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0138Epoch [16/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1139Epoch [16/124], Batch [88/125] [##############------] 70.4%, Loss: 0.3491Epoch [16/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3703Epoch [16/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1033Epoch [16/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1856Epoch [16/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0631Epoch [16/124], Batch [93/125] [##############------] 74.4%, Loss: 0.3545Epoch [16/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2371Epoch [16/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0522Epoch [16/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0455Epoch [16/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.3232Epoch [16/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1789Epoch [16/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0494Epoch [16/124], Batch [100/125] [################----] 80.0%, Loss: 0.0232Epoch [16/124], Batch [101/125] [################----] 80.8%, Loss: 0.0973Epoch [16/124], Batch [102/125] [################----] 81.6%, Loss: 0.6505Epoch [16/124], Batch [103/125] [################----] 82.4%, Loss: 0.4567Epoch [16/124], Batch [104/125] [################----] 83.2%, Loss: 0.0460Epoch [16/124], Batch [105/125] [################----] 84.0%, Loss: 0.4472Epoch [16/124], Batch [106/125] [################----] 84.8%, Loss: 0.0726Epoch [16/124], Batch [107/125] [#################---] 85.6%, Loss: 0.4441Epoch [16/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1579Epoch [16/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1373Epoch [16/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1917Epoch [16/124], Batch [111/125] [#################---] 88.8%, Loss: 0.7311Epoch [16/124], Batch [112/125] [#################---] 89.6%, Loss: 0.8680Epoch [16/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2028Epoch [16/124], Batch [114/125] [##################--] 91.2%, Loss: 0.3582Epoch [16/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1141Epoch [16/124], Batch [116/125] [##################--] 92.8%, Loss: 0.5439Epoch [16/124], Batch [117/125] [##################--] 93.6%, Loss: 0.9324Epoch [16/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0765Epoch [16/124], Batch [119/125] [###################-] 95.2%, Loss: 0.5014Epoch [16/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0757Epoch [16/124], Batch [121/125] [###################-] 96.8%, Loss: 0.2144Epoch [16/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1416Epoch [16/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1568Epoch [16/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0597Epoch [16/124], Batch [125/125] [####################] 100.0%, Loss: 0.0292
Epoch [16/124] finished. Average Loss: 0.2519
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 16 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [17/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.4105Epoch [17/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1435Epoch [17/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0160Epoch [17/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0229Epoch [17/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.7901Epoch [17/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.9431Epoch [17/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0836Epoch [17/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1057Epoch [17/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0975Epoch [17/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0498Epoch [17/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0161Epoch [17/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0251Epoch [17/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0700Epoch [17/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0840Epoch [17/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0848Epoch [17/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.4508Epoch [17/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0961Epoch [17/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0852Epoch [17/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.2777Epoch [17/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0721Epoch [17/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.3527Epoch [17/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1214Epoch [17/124], Batch [23/125] [###-----------------] 18.4%, Loss: 1.1085Epoch [17/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1235Epoch [17/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0130Epoch [17/124], Batch [26/125] [####----------------] 20.8%, Loss: 1.1212Epoch [17/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.8256Epoch [17/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0316Epoch [17/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1255Epoch [17/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.3460Epoch [17/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.9657Epoch [17/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.4695Epoch [17/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.2543Epoch [17/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0692Epoch [17/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.4135Epoch [17/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0183Epoch [17/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1686Epoch [17/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.3893Epoch [17/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.4866Epoch [17/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.2239Epoch [17/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2112Epoch [17/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.5153Epoch [17/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1352Epoch [17/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.5583Epoch [17/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.9124Epoch [17/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0318Epoch [17/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1288Epoch [17/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2124Epoch [17/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2891Epoch [17/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2261Epoch [17/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0181Epoch [17/124], Batch [52/125] [########------------] 41.6%, Loss: 0.3611Epoch [17/124], Batch [53/125] [########------------] 42.4%, Loss: 0.6081Epoch [17/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0255Epoch [17/124], Batch [55/125] [########------------] 44.0%, Loss: 0.4760Epoch [17/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0168Epoch [17/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1697Epoch [17/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0433Epoch [17/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.6671Epoch [17/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.3794Epoch [17/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0347Epoch [17/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.5165Epoch [17/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.6496Epoch [17/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2407Epoch [17/124], Batch [65/125] [##########----------] 52.0%, Loss: 1.5285Epoch [17/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1387Epoch [17/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0663Epoch [17/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1550Epoch [17/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0254Epoch [17/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1996Epoch [17/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.5796Epoch [17/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0416Epoch [17/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0584Epoch [17/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.4051Epoch [17/124], Batch [75/125] [############--------] 60.0%, Loss: 0.3707Epoch [17/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1733Epoch [17/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1115Epoch [17/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1221Epoch [17/124], Batch [79/125] [############--------] 63.2%, Loss: 0.4244Epoch [17/124], Batch [80/125] [############--------] 64.0%, Loss: 1.0168Epoch [17/124], Batch [81/125] [############--------] 64.8%, Loss: 0.6489Epoch [17/124], Batch [82/125] [#############-------] 65.6%, Loss: 1.4741Epoch [17/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1395Epoch [17/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.3074Epoch [17/124], Batch [85/125] [#############-------] 68.0%, Loss: 1.3801Epoch [17/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0175Epoch [17/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0434Epoch [17/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0632Epoch [17/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2173Epoch [17/124], Batch [90/125] [##############------] 72.0%, Loss: 0.4384Epoch [17/124], Batch [91/125] [##############------] 72.8%, Loss: 0.3016Epoch [17/124], Batch [92/125] [##############------] 73.6%, Loss: 0.5620Epoch [17/124], Batch [93/125] [##############------] 74.4%, Loss: 0.4208Epoch [17/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2421Epoch [17/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.4522Epoch [17/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0168Epoch [17/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.4535Epoch [17/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.4391Epoch [17/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0360Epoch [17/124], Batch [100/125] [################----] 80.0%, Loss: 0.1948Epoch [17/124], Batch [101/125] [################----] 80.8%, Loss: 0.2139Epoch [17/124], Batch [102/125] [################----] 81.6%, Loss: 0.3726Epoch [17/124], Batch [103/125] [################----] 82.4%, Loss: 0.1512Epoch [17/124], Batch [104/125] [################----] 83.2%, Loss: 0.3163Epoch [17/124], Batch [105/125] [################----] 84.0%, Loss: 0.6124Epoch [17/124], Batch [106/125] [################----] 84.8%, Loss: 0.0737Epoch [17/124], Batch [107/125] [#################---] 85.6%, Loss: 0.3759Epoch [17/124], Batch [108/125] [#################---] 86.4%, Loss: 0.3337Epoch [17/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2288Epoch [17/124], Batch [110/125] [#################---] 88.0%, Loss: 0.8559Epoch [17/124], Batch [111/125] [#################---] 88.8%, Loss: 0.9150Epoch [17/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1020Epoch [17/124], Batch [113/125] [##################--] 90.4%, Loss: 0.7912Epoch [17/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4555Epoch [17/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1720Epoch [17/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3328Epoch [17/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1402Epoch [17/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0508Epoch [17/124], Batch [119/125] [###################-] 95.2%, Loss: 0.3598Epoch [17/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0593Epoch [17/124], Batch [121/125] [###################-] 96.8%, Loss: 0.8710Epoch [17/124], Batch [122/125] [###################-] 97.6%, Loss: 0.3850Epoch [17/124], Batch [123/125] [###################-] 98.4%, Loss: 0.3396Epoch [17/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0693Epoch [17/124], Batch [125/125] [####################] 100.0%, Loss: 0.7248
Epoch [17/124] finished. Average Loss: 0.3324
Training Accuracy: 97.60%
--- Saving checkpoint for epoch 17 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [18/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.3768Epoch [18/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1546Epoch [18/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0190Epoch [18/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0678Epoch [18/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.2629Epoch [18/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.1111Epoch [18/124], Batch [7/125] [#-------------------] 5.6%, Loss: 1.0663Epoch [18/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1859Epoch [18/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1429Epoch [18/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.1236Epoch [18/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0212Epoch [18/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1194Epoch [18/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0748Epoch [18/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.3038Epoch [18/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.2480Epoch [18/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.4959Epoch [18/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1577Epoch [18/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.2030Epoch [18/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0957Epoch [18/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.3799Epoch [18/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0774Epoch [18/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.3680Epoch [18/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.3018Epoch [18/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0630Epoch [18/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3411Epoch [18/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.6479Epoch [18/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0492Epoch [18/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0064Epoch [18/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1083Epoch [18/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.5342Epoch [18/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1458Epoch [18/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2090Epoch [18/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0585Epoch [18/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1318Epoch [18/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.2170Epoch [18/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.2381Epoch [18/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.6115Epoch [18/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1254Epoch [18/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.2626Epoch [18/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1330Epoch [18/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0261Epoch [18/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.4422Epoch [18/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2737Epoch [18/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0377Epoch [18/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1110Epoch [18/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0543Epoch [18/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.2164Epoch [18/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2448Epoch [18/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0054Epoch [18/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1888Epoch [18/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0243Epoch [18/124], Batch [52/125] [########------------] 41.6%, Loss: 0.4288Epoch [18/124], Batch [53/125] [########------------] 42.4%, Loss: 0.1769Epoch [18/124], Batch [54/125] [########------------] 43.2%, Loss: 0.3484Epoch [18/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0070Epoch [18/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1447Epoch [18/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.3856Epoch [18/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.2094Epoch [18/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0561Epoch [18/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0118Epoch [18/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0141Epoch [18/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1576Epoch [18/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1344Epoch [18/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.5271Epoch [18/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0043Epoch [18/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1669Epoch [18/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0456Epoch [18/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.2118Epoch [18/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.3407Epoch [18/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0690Epoch [18/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0292Epoch [18/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0304Epoch [18/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.4716Epoch [18/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0112Epoch [18/124], Batch [75/125] [############--------] 60.0%, Loss: 0.6657Epoch [18/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1592Epoch [18/124], Batch [77/125] [############--------] 61.6%, Loss: 0.2540Epoch [18/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1697Epoch [18/124], Batch [79/125] [############--------] 63.2%, Loss: 0.7989Epoch [18/124], Batch [80/125] [############--------] 64.0%, Loss: 0.5272Epoch [18/124], Batch [81/125] [############--------] 64.8%, Loss: 1.0104Epoch [18/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1147Epoch [18/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.6780Epoch [18/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.7208Epoch [18/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.3125Epoch [18/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.2804Epoch [18/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1382Epoch [18/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0638Epoch [18/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3302Epoch [18/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0177Epoch [18/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0552Epoch [18/124], Batch [92/125] [##############------] 73.6%, Loss: 0.3344Epoch [18/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0479Epoch [18/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1153Epoch [18/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.5304Epoch [18/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0276Epoch [18/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0848Epoch [18/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.4075Epoch [18/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0351Epoch [18/124], Batch [100/125] [################----] 80.0%, Loss: 0.0312Epoch [18/124], Batch [101/125] [################----] 80.8%, Loss: 0.1693Epoch [18/124], Batch [102/125] [################----] 81.6%, Loss: 0.5090Epoch [18/124], Batch [103/125] [################----] 82.4%, Loss: 0.3191Epoch [18/124], Batch [104/125] [################----] 83.2%, Loss: 1.0825Epoch [18/124], Batch [105/125] [################----] 84.0%, Loss: 0.0778Epoch [18/124], Batch [106/125] [################----] 84.8%, Loss: 0.6644Epoch [18/124], Batch [107/125] [#################---] 85.6%, Loss: 0.5574Epoch [18/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0897Epoch [18/124], Batch [109/125] [#################---] 87.2%, Loss: 0.4552Epoch [18/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1234Epoch [18/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0411Epoch [18/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0205Epoch [18/124], Batch [113/125] [##################--] 90.4%, Loss: 0.6703Epoch [18/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1066Epoch [18/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2924Epoch [18/124], Batch [116/125] [##################--] 92.8%, Loss: 0.5696Epoch [18/124], Batch [117/125] [##################--] 93.6%, Loss: 0.2028Epoch [18/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0353Epoch [18/124], Batch [119/125] [###################-] 95.2%, Loss: 0.2630Epoch [18/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0513Epoch [18/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0177Epoch [18/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1033Epoch [18/124], Batch [123/125] [###################-] 98.4%, Loss: 0.8007Epoch [18/124], Batch [124/125] [###################-] 99.2%, Loss: 0.5578Epoch [18/124], Batch [125/125] [####################] 100.0%, Loss: 0.5361
Epoch [18/124] finished. Average Loss: 0.2486
Training Accuracy: 97.40%
--- Saving checkpoint for epoch 18 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [19/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0229Epoch [19/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1337Epoch [19/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0082Epoch [19/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0263Epoch [19/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0209Epoch [19/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.3423Epoch [19/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0749Epoch [19/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0439Epoch [19/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.4241Epoch [19/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.3141Epoch [19/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2563Epoch [19/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1101Epoch [19/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.5695Epoch [19/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0223Epoch [19/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0365Epoch [19/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.6419Epoch [19/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0498Epoch [19/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0319Epoch [19/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0422Epoch [19/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0484Epoch [19/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.7400Epoch [19/124], Batch [22/125] [###-----------------] 17.6%, Loss: 1.6823Epoch [19/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.4147Epoch [19/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.4145Epoch [19/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0885Epoch [19/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.3975Epoch [19/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.1479Epoch [19/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.7559Epoch [19/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0110Epoch [19/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0192Epoch [19/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.2765Epoch [19/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.5676Epoch [19/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.3659Epoch [19/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0603Epoch [19/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.6369Epoch [19/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1534Epoch [19/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.2745Epoch [19/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1179Epoch [19/124], Batch [39/125] [######--------------] 31.2%, Loss: 1.3696Epoch [19/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.6877Epoch [19/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.3352Epoch [19/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0946Epoch [19/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0481Epoch [19/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.2570Epoch [19/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0717Epoch [19/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0611Epoch [19/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0544Epoch [19/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2753Epoch [19/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.1723Epoch [19/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2198Epoch [19/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0047Epoch [19/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0246Epoch [19/124], Batch [53/125] [########------------] 42.4%, Loss: 1.0030Epoch [19/124], Batch [54/125] [########------------] 43.2%, Loss: 0.2355Epoch [19/124], Batch [55/125] [########------------] 44.0%, Loss: 0.9711Epoch [19/124], Batch [56/125] [########------------] 44.8%, Loss: 0.4893Epoch [19/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0524Epoch [19/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.2671Epoch [19/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0257Epoch [19/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.4716Epoch [19/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0377Epoch [19/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.5974Epoch [19/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.4499Epoch [19/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.1831Epoch [19/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.6327Epoch [19/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1887Epoch [19/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.2547Epoch [19/124], Batch [68/125] [##########----------] 54.4%, Loss: 1.4322Epoch [19/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.5230Epoch [19/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0299Epoch [19/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.5676Epoch [19/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1554Epoch [19/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.3931Epoch [19/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2014Epoch [19/124], Batch [75/125] [############--------] 60.0%, Loss: 0.5876Epoch [19/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0153Epoch [19/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1930Epoch [19/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0752Epoch [19/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1096Epoch [19/124], Batch [80/125] [############--------] 64.0%, Loss: 0.2696Epoch [19/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0460Epoch [19/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0724Epoch [19/124], Batch [83/125] [#############-------] 66.4%, Loss: 1.2882Epoch [19/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.7316Epoch [19/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.7027Epoch [19/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.2737Epoch [19/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.3541Epoch [19/124], Batch [88/125] [##############------] 70.4%, Loss: 0.6239Epoch [19/124], Batch [89/125] [##############------] 71.2%, Loss: 0.8413Epoch [19/124], Batch [90/125] [##############------] 72.0%, Loss: 0.8991Epoch [19/124], Batch [91/125] [##############------] 72.8%, Loss: 0.4590Epoch [19/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4516Epoch [19/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1351Epoch [19/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.5762Epoch [19/124], Batch [95/125] [###############-----] 76.0%, Loss: 1.6555Epoch [19/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.2366Epoch [19/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.7267Epoch [19/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0586Epoch [19/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.6269Epoch [19/124], Batch [100/125] [################----] 80.0%, Loss: 0.6885Epoch [19/124], Batch [101/125] [################----] 80.8%, Loss: 0.1889Epoch [19/124], Batch [102/125] [################----] 81.6%, Loss: 0.7632Epoch [19/124], Batch [103/125] [################----] 82.4%, Loss: 0.1677Epoch [19/124], Batch [104/125] [################----] 83.2%, Loss: 0.5066Epoch [19/124], Batch [105/125] [################----] 84.0%, Loss: 0.1236Epoch [19/124], Batch [106/125] [################----] 84.8%, Loss: 0.1534Epoch [19/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1325Epoch [19/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0490Epoch [19/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2180Epoch [19/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0616Epoch [19/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1282Epoch [19/124], Batch [112/125] [#################---] 89.6%, Loss: 0.4937Epoch [19/124], Batch [113/125] [##################--] 90.4%, Loss: 0.4473Epoch [19/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2001Epoch [19/124], Batch [115/125] [##################--] 92.0%, Loss: 0.4486Epoch [19/124], Batch [116/125] [##################--] 92.8%, Loss: 0.5206Epoch [19/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0263Epoch [19/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1598Epoch [19/124], Batch [119/125] [###################-] 95.2%, Loss: 0.4763Epoch [19/124], Batch [120/125] [###################-] 96.0%, Loss: 0.3503Epoch [19/124], Batch [121/125] [###################-] 96.8%, Loss: 1.0563Epoch [19/124], Batch [122/125] [###################-] 97.6%, Loss: 0.4188Epoch [19/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2667Epoch [19/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0475Epoch [19/124], Batch [125/125] [####################] 100.0%, Loss: 0.8737
Epoch [19/124] finished. Average Loss: 0.3533
Training Accuracy: 97.80%
--- Saving checkpoint for epoch 19 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [20/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0738Epoch [20/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1496Epoch [20/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0308Epoch [20/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.4462Epoch [20/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.9316Epoch [20/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0507Epoch [20/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.4094Epoch [20/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.4502Epoch [20/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0486Epoch [20/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.1701Epoch [20/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1339Epoch [20/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1051Epoch [20/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0199Epoch [20/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0059Epoch [20/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.3920Epoch [20/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0243Epoch [20/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0560Epoch [20/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.3043Epoch [20/124], Batch [19/125] [###-----------------] 15.2%, Loss: 1.3554Epoch [20/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0979Epoch [20/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1957Epoch [20/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0884Epoch [20/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.3133Epoch [20/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.7238Epoch [20/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.6350Epoch [20/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.2227Epoch [20/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0090Epoch [20/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.2736Epoch [20/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0480Epoch [20/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.4971Epoch [20/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0916Epoch [20/124], Batch [32/125] [#####---------------] 25.6%, Loss: 1.1589Epoch [20/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.7127Epoch [20/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0318Epoch [20/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0381Epoch [20/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1780Epoch [20/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1397Epoch [20/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.3844Epoch [20/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0112Epoch [20/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.3845Epoch [20/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.7189Epoch [20/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1034Epoch [20/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.7062Epoch [20/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.1962Epoch [20/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.2556Epoch [20/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.4270Epoch [20/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.3951Epoch [20/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2122Epoch [20/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.4340Epoch [20/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2504Epoch [20/124], Batch [51/125] [########------------] 40.8%, Loss: 1.8118Epoch [20/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0286Epoch [20/124], Batch [53/125] [########------------] 42.4%, Loss: 0.4745Epoch [20/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0066Epoch [20/124], Batch [55/125] [########------------] 44.0%, Loss: 0.9081Epoch [20/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0904Epoch [20/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1343Epoch [20/124], Batch [58/125] [#########-----------] 46.4%, Loss: 1.4285Epoch [20/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1034Epoch [20/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1647Epoch [20/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0333Epoch [20/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0768Epoch [20/124], Batch [63/125] [##########----------] 50.4%, Loss: 1.1775Epoch [20/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0912Epoch [20/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.4807Epoch [20/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0354Epoch [20/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0693Epoch [20/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0832Epoch [20/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1525Epoch [20/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1371Epoch [20/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.7162Epoch [20/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0189Epoch [20/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.4971Epoch [20/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0925Epoch [20/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0458Epoch [20/124], Batch [76/125] [############--------] 60.8%, Loss: 1.2695Epoch [20/124], Batch [77/125] [############--------] 61.6%, Loss: 0.7901Epoch [20/124], Batch [78/125] [############--------] 62.4%, Loss: 0.3277Epoch [20/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0100Epoch [20/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1078Epoch [20/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1774Epoch [20/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1414Epoch [20/124], Batch [83/125] [#############-------] 66.4%, Loss: 1.5375Epoch [20/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.1420Epoch [20/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.6099Epoch [20/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0487Epoch [20/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.6145Epoch [20/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0112Epoch [20/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3794Epoch [20/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0235Epoch [20/124], Batch [91/125] [##############------] 72.8%, Loss: 0.4783Epoch [20/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1354Epoch [20/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1664Epoch [20/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.6653Epoch [20/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.5136Epoch [20/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0891Epoch [20/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0492Epoch [20/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0139Epoch [20/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2656Epoch [20/124], Batch [100/125] [################----] 80.0%, Loss: 0.7835Epoch [20/124], Batch [101/125] [################----] 80.8%, Loss: 0.6286Epoch [20/124], Batch [102/125] [################----] 81.6%, Loss: 0.4572Epoch [20/124], Batch [103/125] [################----] 82.4%, Loss: 0.7158Epoch [20/124], Batch [104/125] [################----] 83.2%, Loss: 0.1482Epoch [20/124], Batch [105/125] [################----] 84.0%, Loss: 0.0758Epoch [20/124], Batch [106/125] [################----] 84.8%, Loss: 0.0519Epoch [20/124], Batch [107/125] [#################---] 85.6%, Loss: 0.4865Epoch [20/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1093Epoch [20/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0977Epoch [20/124], Batch [110/125] [#################---] 88.0%, Loss: 1.8146Epoch [20/124], Batch [111/125] [#################---] 88.8%, Loss: 0.5492Epoch [20/124], Batch [112/125] [#################---] 89.6%, Loss: 0.2111Epoch [20/124], Batch [113/125] [##################--] 90.4%, Loss: 0.6590Epoch [20/124], Batch [114/125] [##################--] 91.2%, Loss: 0.3939Epoch [20/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0212Epoch [20/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3353Epoch [20/124], Batch [117/125] [##################--] 93.6%, Loss: 0.6079Epoch [20/124], Batch [118/125] [##################--] 94.4%, Loss: 0.5390Epoch [20/124], Batch [119/125] [###################-] 95.2%, Loss: 0.1150Epoch [20/124], Batch [120/125] [###################-] 96.0%, Loss: 0.5319Epoch [20/124], Batch [121/125] [###################-] 96.8%, Loss: 0.2523Epoch [20/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0992Epoch [20/124], Batch [123/125] [###################-] 98.4%, Loss: 1.0768Epoch [20/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1098Epoch [20/124], Batch [125/125] [####################] 100.0%, Loss: 0.4091
Epoch [20/124] finished. Average Loss: 0.3504
Training Accuracy: 96.40%
--- Saving checkpoint for epoch 20 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [21/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0450Epoch [21/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0304Epoch [21/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0085Epoch [21/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0363Epoch [21/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0478Epoch [21/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0651Epoch [21/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.6935Epoch [21/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.3819Epoch [21/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1123Epoch [21/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.4121Epoch [21/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0980Epoch [21/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0308Epoch [21/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0122Epoch [21/124], Batch [14/125] [##------------------] 11.2%, Loss: 2.5257Epoch [21/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.5999Epoch [21/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0763Epoch [21/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.4359Epoch [21/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0427Epoch [21/124], Batch [19/125] [###-----------------] 15.2%, Loss: 1.0483Epoch [21/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1841Epoch [21/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0383Epoch [21/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0064Epoch [21/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.3006Epoch [21/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0415Epoch [21/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.8362Epoch [21/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1134Epoch [21/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0167Epoch [21/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.2920Epoch [21/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0691Epoch [21/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0239Epoch [21/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1523Epoch [21/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0608Epoch [21/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0229Epoch [21/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0243Epoch [21/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0353Epoch [21/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1585Epoch [21/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1444Epoch [21/124], Batch [38/125] [######--------------] 30.4%, Loss: 1.0576Epoch [21/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.2147Epoch [21/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0221Epoch [21/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0733Epoch [21/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.2176Epoch [21/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.7431Epoch [21/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.5613Epoch [21/124], Batch [45/125] [#######-------------] 36.0%, Loss: 1.0498Epoch [21/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0489Epoch [21/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0239Epoch [21/124], Batch [48/125] [#######-------------] 38.4%, Loss: 3.7301Epoch [21/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0078Epoch [21/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0707Epoch [21/124], Batch [51/125] [########------------] 40.8%, Loss: 0.5218Epoch [21/124], Batch [52/125] [########------------] 41.6%, Loss: 0.3359Epoch [21/124], Batch [53/125] [########------------] 42.4%, Loss: 0.3214Epoch [21/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0117Epoch [21/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2091Epoch [21/124], Batch [56/125] [########------------] 44.8%, Loss: 0.3265Epoch [21/124], Batch [57/125] [#########-----------] 45.6%, Loss: 1.8497Epoch [21/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0172Epoch [21/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.3603Epoch [21/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0375Epoch [21/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2213Epoch [21/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.3870Epoch [21/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.2750Epoch [21/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.1224Epoch [21/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.5634Epoch [21/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.4352Epoch [21/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.2595Epoch [21/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.3604Epoch [21/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0037Epoch [21/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.2441Epoch [21/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0277Epoch [21/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1520Epoch [21/124], Batch [73/125] [###########---------] 58.4%, Loss: 1.0415Epoch [21/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0232Epoch [21/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0920Epoch [21/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1786Epoch [21/124], Batch [77/125] [############--------] 61.6%, Loss: 1.1079Epoch [21/124], Batch [78/125] [############--------] 62.4%, Loss: 0.2168Epoch [21/124], Batch [79/125] [############--------] 63.2%, Loss: 0.3553Epoch [21/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0473Epoch [21/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0192Epoch [21/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0731Epoch [21/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1192Epoch [21/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.2257Epoch [21/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0480Epoch [21/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.3084Epoch [21/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.3985Epoch [21/124], Batch [88/125] [##############------] 70.4%, Loss: 0.5312Epoch [21/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0290Epoch [21/124], Batch [90/125] [##############------] 72.0%, Loss: 0.2725Epoch [21/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1054Epoch [21/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1416Epoch [21/124], Batch [93/125] [##############------] 74.4%, Loss: 1.9816Epoch [21/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0519Epoch [21/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2040Epoch [21/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1732Epoch [21/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1159Epoch [21/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.3307Epoch [21/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0105Epoch [21/124], Batch [100/125] [################----] 80.0%, Loss: 0.0073Epoch [21/124], Batch [101/125] [################----] 80.8%, Loss: 0.0590Epoch [21/124], Batch [102/125] [################----] 81.6%, Loss: 0.0622Epoch [21/124], Batch [103/125] [################----] 82.4%, Loss: 0.4496Epoch [21/124], Batch [104/125] [################----] 83.2%, Loss: 0.2130Epoch [21/124], Batch [105/125] [################----] 84.0%, Loss: 1.6604Epoch [21/124], Batch [106/125] [################----] 84.8%, Loss: 0.0190Epoch [21/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1211Epoch [21/124], Batch [108/125] [#################---] 86.4%, Loss: 0.5020Epoch [21/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1190Epoch [21/124], Batch [110/125] [#################---] 88.0%, Loss: 0.6827Epoch [21/124], Batch [111/125] [#################---] 88.8%, Loss: 1.4115Epoch [21/124], Batch [112/125] [#################---] 89.6%, Loss: 0.5135Epoch [21/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2490Epoch [21/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0839Epoch [21/124], Batch [115/125] [##################--] 92.0%, Loss: 0.3919Epoch [21/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1710Epoch [21/124], Batch [117/125] [##################--] 93.6%, Loss: 0.2663Epoch [21/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0363Epoch [21/124], Batch [119/125] [###################-] 95.2%, Loss: 0.2530Epoch [21/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2189Epoch [21/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0083Epoch [21/124], Batch [122/125] [###################-] 97.6%, Loss: 0.3437Epoch [21/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1161Epoch [21/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1988Epoch [21/124], Batch [125/125] [####################] 100.0%, Loss: 0.0658
Epoch [21/124] finished. Average Loss: 0.3241
Training Accuracy: 96.80%
--- Saving checkpoint for epoch 21 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [22/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0410Epoch [22/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0413Epoch [22/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0449Epoch [22/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0237Epoch [22/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0261Epoch [22/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0203Epoch [22/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0424Epoch [22/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.2002Epoch [22/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1547Epoch [22/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0265Epoch [22/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0558Epoch [22/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0896Epoch [22/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2031Epoch [22/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0060Epoch [22/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0280Epoch [22/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1235Epoch [22/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.2482Epoch [22/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.3431Epoch [22/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.2617Epoch [22/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0345Epoch [22/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0491Epoch [22/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0216Epoch [22/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0402Epoch [22/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0578Epoch [22/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.2228Epoch [22/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1826Epoch [22/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.6942Epoch [22/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0611Epoch [22/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2459Epoch [22/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.2842Epoch [22/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0019Epoch [22/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.1091Epoch [22/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.2595Epoch [22/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.2314Epoch [22/124], Batch [35/125] [#####---------------] 28.0%, Loss: 1.0885Epoch [22/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.6876Epoch [22/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0451Epoch [22/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0061Epoch [22/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0839Epoch [22/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0958Epoch [22/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2539Epoch [22/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0263Epoch [22/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2238Epoch [22/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0223Epoch [22/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0162Epoch [22/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0568Epoch [22/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0396Epoch [22/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.3795Epoch [22/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0055Epoch [22/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2998Epoch [22/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1366Epoch [22/124], Batch [52/125] [########------------] 41.6%, Loss: 0.8158Epoch [22/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0927Epoch [22/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0290Epoch [22/124], Batch [55/125] [########------------] 44.0%, Loss: 0.5675Epoch [22/124], Batch [56/125] [########------------] 44.8%, Loss: 0.4249Epoch [22/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.5477Epoch [22/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0272Epoch [22/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2420Epoch [22/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0687Epoch [22/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0858Epoch [22/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0075Epoch [22/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0480Epoch [22/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2131Epoch [22/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0245Epoch [22/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0068Epoch [22/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0775Epoch [22/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1268Epoch [22/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0161Epoch [22/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0199Epoch [22/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0779Epoch [22/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1232Epoch [22/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.5455Epoch [22/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1656Epoch [22/124], Batch [75/125] [############--------] 60.0%, Loss: 0.2009Epoch [22/124], Batch [76/125] [############--------] 60.8%, Loss: 0.5240Epoch [22/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1209Epoch [22/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0513Epoch [22/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0302Epoch [22/124], Batch [80/125] [############--------] 64.0%, Loss: 1.1524Epoch [22/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0154Epoch [22/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0168Epoch [22/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1951Epoch [22/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0688Epoch [22/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.6966Epoch [22/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1260Epoch [22/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1812Epoch [22/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0463Epoch [22/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0851Epoch [22/124], Batch [90/125] [##############------] 72.0%, Loss: 0.2266Epoch [22/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0886Epoch [22/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0065Epoch [22/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1416Epoch [22/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0415Epoch [22/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3472Epoch [22/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.5334Epoch [22/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0484Epoch [22/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0873Epoch [22/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0883Epoch [22/124], Batch [100/125] [################----] 80.0%, Loss: 0.2571Epoch [22/124], Batch [101/125] [################----] 80.8%, Loss: 0.0054Epoch [22/124], Batch [102/125] [################----] 81.6%, Loss: 0.0181Epoch [22/124], Batch [103/125] [################----] 82.4%, Loss: 0.1610Epoch [22/124], Batch [104/125] [################----] 83.2%, Loss: 0.0721Epoch [22/124], Batch [105/125] [################----] 84.0%, Loss: 0.0601Epoch [22/124], Batch [106/125] [################----] 84.8%, Loss: 0.0067Epoch [22/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0632Epoch [22/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0162Epoch [22/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1541Epoch [22/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0202Epoch [22/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0493Epoch [22/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1772Epoch [22/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0183Epoch [22/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0814Epoch [22/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0324Epoch [22/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0070Epoch [22/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0642Epoch [22/124], Batch [118/125] [##################--] 94.4%, Loss: 0.2994Epoch [22/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0025Epoch [22/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0096Epoch [22/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0073Epoch [22/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0225Epoch [22/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0120Epoch [22/124], Batch [124/125] [###################-] 99.2%, Loss: 0.2843Epoch [22/124], Batch [125/125] [####################] 100.0%, Loss: 0.0412
Epoch [22/124] finished. Average Loss: 0.1549
Training Accuracy: 99.40%
--- Saving checkpoint for epoch 22 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [23/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0167Epoch [23/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.2359Epoch [23/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0113Epoch [23/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.2851Epoch [23/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0032Epoch [23/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0257Epoch [23/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.7881Epoch [23/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0235Epoch [23/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1247Epoch [23/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0129Epoch [23/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0152Epoch [23/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0127Epoch [23/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0255Epoch [23/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.6477Epoch [23/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0219Epoch [23/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0691Epoch [23/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0037Epoch [23/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0293Epoch [23/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.1267Epoch [23/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0425Epoch [23/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1677Epoch [23/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0033Epoch [23/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1737Epoch [23/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.4285Epoch [23/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0030Epoch [23/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0019Epoch [23/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.2148Epoch [23/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0689Epoch [23/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0038Epoch [23/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.5143Epoch [23/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0225Epoch [23/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0118Epoch [23/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0050Epoch [23/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0061Epoch [23/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0213Epoch [23/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0422Epoch [23/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0028Epoch [23/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.2513Epoch [23/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0113Epoch [23/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0236Epoch [23/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0235Epoch [23/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0863Epoch [23/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0144Epoch [23/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.8325Epoch [23/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.3471Epoch [23/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0533Epoch [23/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0071Epoch [23/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1455Epoch [23/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2192Epoch [23/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2345Epoch [23/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0751Epoch [23/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0274Epoch [23/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0190Epoch [23/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0956Epoch [23/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0485Epoch [23/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0390Epoch [23/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.3588Epoch [23/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0188Epoch [23/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0419Epoch [23/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1059Epoch [23/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2623Epoch [23/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1055Epoch [23/124], Batch [63/125] [##########----------] 50.4%, Loss: 1.3083Epoch [23/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0157Epoch [23/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0103Epoch [23/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0235Epoch [23/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0103Epoch [23/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0220Epoch [23/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0096Epoch [23/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0108Epoch [23/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0152Epoch [23/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0396Epoch [23/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0035Epoch [23/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2052Epoch [23/124], Batch [75/125] [############--------] 60.0%, Loss: 0.4224Epoch [23/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2372Epoch [23/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0064Epoch [23/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0009Epoch [23/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0678Epoch [23/124], Batch [80/125] [############--------] 64.0%, Loss: 0.2636Epoch [23/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0408Epoch [23/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0163Epoch [23/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1322Epoch [23/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0175Epoch [23/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0191Epoch [23/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0134Epoch [23/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1291Epoch [23/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0191Epoch [23/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2259Epoch [23/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1689Epoch [23/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0629Epoch [23/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0509Epoch [23/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2597Epoch [23/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0349Epoch [23/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0228Epoch [23/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0207Epoch [23/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0088Epoch [23/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0573Epoch [23/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1081Epoch [23/124], Batch [100/125] [################----] 80.0%, Loss: 0.0673Epoch [23/124], Batch [101/125] [################----] 80.8%, Loss: 0.0383Epoch [23/124], Batch [102/125] [################----] 81.6%, Loss: 0.0045Epoch [23/124], Batch [103/125] [################----] 82.4%, Loss: 0.0284Epoch [23/124], Batch [104/125] [################----] 83.2%, Loss: 0.0172Epoch [23/124], Batch [105/125] [################----] 84.0%, Loss: 0.1222Epoch [23/124], Batch [106/125] [################----] 84.8%, Loss: 0.0629Epoch [23/124], Batch [107/125] [#################---] 85.6%, Loss: 0.2040Epoch [23/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0538Epoch [23/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2491Epoch [23/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0166Epoch [23/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0534Epoch [23/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0058Epoch [23/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1082Epoch [23/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0110Epoch [23/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0156Epoch [23/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0047Epoch [23/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1045Epoch [23/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0357Epoch [23/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0197Epoch [23/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1003Epoch [23/124], Batch [121/125] [###################-] 96.8%, Loss: 0.6209Epoch [23/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0971Epoch [23/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0991Epoch [23/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1210Epoch [23/124], Batch [125/125] [####################] 100.0%, Loss: 0.4142
Epoch [23/124] finished. Average Loss: 0.1153
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 23 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [24/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0194Epoch [24/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0778Epoch [24/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0190Epoch [24/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0067Epoch [24/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0068Epoch [24/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0026Epoch [24/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0036Epoch [24/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0501Epoch [24/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0043Epoch [24/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0047Epoch [24/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0104Epoch [24/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.1196Epoch [24/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0742Epoch [24/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0082Epoch [24/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0150Epoch [24/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0002Epoch [24/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0891Epoch [24/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0040Epoch [24/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0008Epoch [24/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0993Epoch [24/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.3828Epoch [24/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0078Epoch [24/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0063Epoch [24/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0088Epoch [24/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0671Epoch [24/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0036Epoch [24/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0107Epoch [24/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.7034Epoch [24/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0113Epoch [24/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0949Epoch [24/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.9610Epoch [24/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0367Epoch [24/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0147Epoch [24/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0226Epoch [24/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0232Epoch [24/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0086Epoch [24/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0435Epoch [24/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0394Epoch [24/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0005Epoch [24/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0333Epoch [24/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2616Epoch [24/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0225Epoch [24/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1721Epoch [24/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.1113Epoch [24/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0040Epoch [24/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0084Epoch [24/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0144Epoch [24/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0512Epoch [24/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0036Epoch [24/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0103Epoch [24/124], Batch [51/125] [########------------] 40.8%, Loss: 0.3580Epoch [24/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0564Epoch [24/124], Batch [53/125] [########------------] 42.4%, Loss: 0.1868Epoch [24/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0264Epoch [24/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0194Epoch [24/124], Batch [56/125] [########------------] 44.8%, Loss: 0.3256Epoch [24/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0107Epoch [24/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1678Epoch [24/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0092Epoch [24/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0044Epoch [24/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0170Epoch [24/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0168Epoch [24/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0052Epoch [24/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0024Epoch [24/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0009Epoch [24/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.3432Epoch [24/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0060Epoch [24/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0265Epoch [24/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0089Epoch [24/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1049Epoch [24/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0028Epoch [24/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0025Epoch [24/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0031Epoch [24/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0235Epoch [24/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0503Epoch [24/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0019Epoch [24/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0099Epoch [24/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0047Epoch [24/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0020Epoch [24/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0101Epoch [24/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0065Epoch [24/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0852Epoch [24/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0251Epoch [24/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0304Epoch [24/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0435Epoch [24/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0952Epoch [24/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.3992Epoch [24/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1027Epoch [24/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2077Epoch [24/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0131Epoch [24/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0425Epoch [24/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0046Epoch [24/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0369Epoch [24/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0324Epoch [24/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0023Epoch [24/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0391Epoch [24/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0206Epoch [24/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1511Epoch [24/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0317Epoch [24/124], Batch [100/125] [################----] 80.0%, Loss: 0.0050Epoch [24/124], Batch [101/125] [################----] 80.8%, Loss: 0.0241Epoch [24/124], Batch [102/125] [################----] 81.6%, Loss: 0.0264Epoch [24/124], Batch [103/125] [################----] 82.4%, Loss: 0.0107Epoch [24/124], Batch [104/125] [################----] 83.2%, Loss: 0.0413Epoch [24/124], Batch [105/125] [################----] 84.0%, Loss: 0.6372Epoch [24/124], Batch [106/125] [################----] 84.8%, Loss: 0.0031Epoch [24/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0009Epoch [24/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0070Epoch [24/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0340Epoch [24/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0085Epoch [24/124], Batch [111/125] [#################---] 88.8%, Loss: 0.6270Epoch [24/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1209Epoch [24/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1691Epoch [24/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0457Epoch [24/124], Batch [115/125] [##################--] 92.0%, Loss: 0.8827Epoch [24/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0364Epoch [24/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0934Epoch [24/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0030Epoch [24/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0258Epoch [24/124], Batch [120/125] [###################-] 96.0%, Loss: 0.9066Epoch [24/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0134Epoch [24/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2864Epoch [24/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0042Epoch [24/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0086Epoch [24/124], Batch [125/125] [####################] 100.0%, Loss: 0.9863
Epoch [24/124] finished. Average Loss: 0.0955
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 24 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [25/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0132Epoch [25/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0040Epoch [25/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0172Epoch [25/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0416Epoch [25/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0024Epoch [25/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0115Epoch [25/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1326Epoch [25/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0801Epoch [25/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0070Epoch [25/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0053Epoch [25/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.5307Epoch [25/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.6974Epoch [25/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.0112Epoch [25/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0110Epoch [25/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0223Epoch [25/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2472Epoch [25/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.4146Epoch [25/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0070Epoch [25/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0229Epoch [25/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0132Epoch [25/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0601Epoch [25/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1569Epoch [25/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1151Epoch [25/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0429Epoch [25/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3075Epoch [25/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0675Epoch [25/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.2994Epoch [25/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0305Epoch [25/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.5213Epoch [25/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1643Epoch [25/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.7636Epoch [25/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.3068Epoch [25/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0341Epoch [25/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0224Epoch [25/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.1763Epoch [25/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1318Epoch [25/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0013Epoch [25/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0260Epoch [25/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0995Epoch [25/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0212Epoch [25/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0328Epoch [25/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.3459Epoch [25/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0062Epoch [25/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.4025Epoch [25/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1439Epoch [25/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0433Epoch [25/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0147Epoch [25/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.4673Epoch [25/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.1128Epoch [25/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1365Epoch [25/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0054Epoch [25/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0443Epoch [25/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2233Epoch [25/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0594Epoch [25/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0946Epoch [25/124], Batch [56/125] [########------------] 44.8%, Loss: 0.5204Epoch [25/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.2233Epoch [25/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0666Epoch [25/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0049Epoch [25/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0338Epoch [25/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0123Epoch [25/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.2427Epoch [25/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0029Epoch [25/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0044Epoch [25/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0144Epoch [25/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.3106Epoch [25/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0042Epoch [25/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0636Epoch [25/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0050Epoch [25/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.4422Epoch [25/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0029Epoch [25/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0139Epoch [25/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.4830Epoch [25/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0395Epoch [25/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0096Epoch [25/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1311Epoch [25/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1578Epoch [25/124], Batch [78/125] [############--------] 62.4%, Loss: 0.4323Epoch [25/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0177Epoch [25/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0204Epoch [25/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0839Epoch [25/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0478Epoch [25/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0287Epoch [25/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0289Epoch [25/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0154Epoch [25/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0004Epoch [25/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0671Epoch [25/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0327Epoch [25/124], Batch [89/125] [##############------] 71.2%, Loss: 0.1340Epoch [25/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0270Epoch [25/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0904Epoch [25/124], Batch [92/125] [##############------] 73.6%, Loss: 0.3217Epoch [25/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0779Epoch [25/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0375Epoch [25/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2914Epoch [25/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0400Epoch [25/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0038Epoch [25/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0067Epoch [25/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0024Epoch [25/124], Batch [100/125] [################----] 80.0%, Loss: 0.0704Epoch [25/124], Batch [101/125] [################----] 80.8%, Loss: 0.1078Epoch [25/124], Batch [102/125] [################----] 81.6%, Loss: 0.2366Epoch [25/124], Batch [103/125] [################----] 82.4%, Loss: 0.0116Epoch [25/124], Batch [104/125] [################----] 83.2%, Loss: 0.6269Epoch [25/124], Batch [105/125] [################----] 84.0%, Loss: 0.0935Epoch [25/124], Batch [106/125] [################----] 84.8%, Loss: 0.1636Epoch [25/124], Batch [107/125] [#################---] 85.6%, Loss: 0.3638Epoch [25/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0053Epoch [25/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0586Epoch [25/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0029Epoch [25/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0188Epoch [25/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0196Epoch [25/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2138Epoch [25/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0106Epoch [25/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1927Epoch [25/124], Batch [116/125] [##################--] 92.8%, Loss: 0.6671Epoch [25/124], Batch [117/125] [##################--] 93.6%, Loss: 0.4727Epoch [25/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1148Epoch [25/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0221Epoch [25/124], Batch [120/125] [###################-] 96.0%, Loss: 0.7133Epoch [25/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0037Epoch [25/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0263Epoch [25/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0785Epoch [25/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0164Epoch [25/124], Batch [125/125] [####################] 100.0%, Loss: 0.1352
Epoch [25/124] finished. Average Loss: 0.1425
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 25 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [26/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0170Epoch [26/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0207Epoch [26/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0138Epoch [26/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0277Epoch [26/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.8881Epoch [26/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0029Epoch [26/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0182Epoch [26/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0240Epoch [26/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0763Epoch [26/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0611Epoch [26/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0462Epoch [26/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0255Epoch [26/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0277Epoch [26/124], Batch [14/125] [##------------------] 11.2%, Loss: 1.2345Epoch [26/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0243Epoch [26/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0464Epoch [26/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0408Epoch [26/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0313Epoch [26/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0501Epoch [26/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0137Epoch [26/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0052Epoch [26/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2538Epoch [26/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0467Epoch [26/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0429Epoch [26/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.6230Epoch [26/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.5071Epoch [26/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.8016Epoch [26/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0514Epoch [26/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0235Epoch [26/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0045Epoch [26/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0512Epoch [26/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0651Epoch [26/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0494Epoch [26/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0035Epoch [26/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0422Epoch [26/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0069Epoch [26/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0399Epoch [26/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1843Epoch [26/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1952Epoch [26/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0032Epoch [26/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1000Epoch [26/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0738Epoch [26/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.3682Epoch [26/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0594Epoch [26/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1945Epoch [26/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0121Epoch [26/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0562Epoch [26/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1590Epoch [26/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0058Epoch [26/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1034Epoch [26/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0644Epoch [26/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0381Epoch [26/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0810Epoch [26/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0006Epoch [26/124], Batch [55/125] [########------------] 44.0%, Loss: 0.1142Epoch [26/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0877Epoch [26/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0478Epoch [26/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0359Epoch [26/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0154Epoch [26/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0078Epoch [26/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0125Epoch [26/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0252Epoch [26/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0434Epoch [26/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.1242Epoch [26/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1676Epoch [26/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2621Epoch [26/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0293Epoch [26/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0096Epoch [26/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0129Epoch [26/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.2196Epoch [26/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.5906Epoch [26/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0692Epoch [26/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0055Epoch [26/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2924Epoch [26/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0965Epoch [26/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0085Epoch [26/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0034Epoch [26/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0350Epoch [26/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1242Epoch [26/124], Batch [80/125] [############--------] 64.0%, Loss: 0.5988Epoch [26/124], Batch [81/125] [############--------] 64.8%, Loss: 0.3112Epoch [26/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0262Epoch [26/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0105Epoch [26/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.1017Epoch [26/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.5397Epoch [26/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0309Epoch [26/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0615Epoch [26/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0457Epoch [26/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0725Epoch [26/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0316Epoch [26/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0080Epoch [26/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0589Epoch [26/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2796Epoch [26/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0117Epoch [26/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0176Epoch [26/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.2943Epoch [26/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0859Epoch [26/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.5270Epoch [26/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0109Epoch [26/124], Batch [100/125] [################----] 80.0%, Loss: 0.1309Epoch [26/124], Batch [101/125] [################----] 80.8%, Loss: 0.4217Epoch [26/124], Batch [102/125] [################----] 81.6%, Loss: 0.0113Epoch [26/124], Batch [103/125] [################----] 82.4%, Loss: 0.2005Epoch [26/124], Batch [104/125] [################----] 83.2%, Loss: 0.0719Epoch [26/124], Batch [105/125] [################----] 84.0%, Loss: 0.2327Epoch [26/124], Batch [106/125] [################----] 84.8%, Loss: 0.0164Epoch [26/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0352Epoch [26/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2889Epoch [26/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0188Epoch [26/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0055Epoch [26/124], Batch [111/125] [#################---] 88.8%, Loss: 0.7562Epoch [26/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1969Epoch [26/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1128Epoch [26/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4904Epoch [26/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0278Epoch [26/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0341Epoch [26/124], Batch [117/125] [##################--] 93.6%, Loss: 0.2771Epoch [26/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0076Epoch [26/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0467Epoch [26/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0452Epoch [26/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0021Epoch [26/124], Batch [122/125] [###################-] 97.6%, Loss: 0.4295Epoch [26/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0179Epoch [26/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0336Epoch [26/124], Batch [125/125] [####################] 100.0%, Loss: 0.0322
Epoch [26/124] finished. Average Loss: 0.1401
Training Accuracy: 98.00%
--- Saving checkpoint for epoch 26 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [27/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1314Epoch [27/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0115Epoch [27/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0668Epoch [27/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0399Epoch [27/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.2649Epoch [27/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0260Epoch [27/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0004Epoch [27/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.3511Epoch [27/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2459Epoch [27/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0034Epoch [27/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0090Epoch [27/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0127Epoch [27/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.0948Epoch [27/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.1000Epoch [27/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.9365Epoch [27/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0172Epoch [27/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0391Epoch [27/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0419Epoch [27/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.2105Epoch [27/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.4095Epoch [27/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0144Epoch [27/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0207Epoch [27/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0059Epoch [27/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0046Epoch [27/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.6472Epoch [27/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.2964Epoch [27/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.5155Epoch [27/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0172Epoch [27/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0162Epoch [27/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0322Epoch [27/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0128Epoch [27/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.7784Epoch [27/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0607Epoch [27/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0400Epoch [27/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0044Epoch [27/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0937Epoch [27/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0532Epoch [27/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1804Epoch [27/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1298Epoch [27/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0840Epoch [27/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2895Epoch [27/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0096Epoch [27/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1025Epoch [27/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0546Epoch [27/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0148Epoch [27/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0895Epoch [27/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1226Epoch [27/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0205Epoch [27/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0630Epoch [27/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1462Epoch [27/124], Batch [51/125] [########------------] 40.8%, Loss: 0.2483Epoch [27/124], Batch [52/125] [########------------] 41.6%, Loss: 0.6321Epoch [27/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2783Epoch [27/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1847Epoch [27/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0318Epoch [27/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0970Epoch [27/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0443Epoch [27/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0300Epoch [27/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0243Epoch [27/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0118Epoch [27/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.5184Epoch [27/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0007Epoch [27/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0376Epoch [27/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.1257Epoch [27/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0105Epoch [27/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1657Epoch [27/124], Batch [67/125] [##########----------] 53.6%, Loss: 1.4117Epoch [27/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0089Epoch [27/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1213Epoch [27/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0157Epoch [27/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.3306Epoch [27/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0068Epoch [27/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0769Epoch [27/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0025Epoch [27/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1191Epoch [27/124], Batch [76/125] [############--------] 60.8%, Loss: 0.8268Epoch [27/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1893Epoch [27/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0658Epoch [27/124], Batch [79/125] [############--------] 63.2%, Loss: 0.3502Epoch [27/124], Batch [80/125] [############--------] 64.0%, Loss: 0.5371Epoch [27/124], Batch [81/125] [############--------] 64.8%, Loss: 0.6680Epoch [27/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0405Epoch [27/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1037Epoch [27/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0856Epoch [27/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.4627Epoch [27/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0634Epoch [27/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0060Epoch [27/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0068Epoch [27/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0491Epoch [27/124], Batch [90/125] [##############------] 72.0%, Loss: 0.3365Epoch [27/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0318Epoch [27/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0109Epoch [27/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1006Epoch [27/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1130Epoch [27/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2515Epoch [27/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1343Epoch [27/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1410Epoch [27/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.3426Epoch [27/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.3159Epoch [27/124], Batch [100/125] [################----] 80.0%, Loss: 0.0305Epoch [27/124], Batch [101/125] [################----] 80.8%, Loss: 0.0157Epoch [27/124], Batch [102/125] [################----] 81.6%, Loss: 0.0263Epoch [27/124], Batch [103/125] [################----] 82.4%, Loss: 0.0376Epoch [27/124], Batch [104/125] [################----] 83.2%, Loss: 0.1767Epoch [27/124], Batch [105/125] [################----] 84.0%, Loss: 0.0242Epoch [27/124], Batch [106/125] [################----] 84.8%, Loss: 0.0806Epoch [27/124], Batch [107/125] [#################---] 85.6%, Loss: 0.5039Epoch [27/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1120Epoch [27/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1854Epoch [27/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1464Epoch [27/124], Batch [111/125] [#################---] 88.8%, Loss: 2.5088Epoch [27/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1770Epoch [27/124], Batch [113/125] [##################--] 90.4%, Loss: 0.4638Epoch [27/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0115Epoch [27/124], Batch [115/125] [##################--] 92.0%, Loss: 0.8004Epoch [27/124], Batch [116/125] [##################--] 92.8%, Loss: 0.2724Epoch [27/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0311Epoch [27/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0200Epoch [27/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0074Epoch [27/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0287Epoch [27/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0858Epoch [27/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0506Epoch [27/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2587Epoch [27/124], Batch [124/125] [###################-] 99.2%, Loss: 0.3478Epoch [27/124], Batch [125/125] [####################] 100.0%, Loss: 0.3049
Epoch [27/124] finished. Average Loss: 0.1953
Training Accuracy: 98.00%
--- Saving checkpoint for epoch 27 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [28/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0151Epoch [28/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0065Epoch [28/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0016Epoch [28/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0957Epoch [28/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0129Epoch [28/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.3599Epoch [28/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.4246Epoch [28/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1096Epoch [28/124], Batch [9/125] [#-------------------] 7.2%, Loss: 1.4952Epoch [28/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.3178Epoch [28/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0435Epoch [28/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0276Epoch [28/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.8996Epoch [28/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0134Epoch [28/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.4544Epoch [28/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1016Epoch [28/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0358Epoch [28/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0993Epoch [28/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0231Epoch [28/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.3281Epoch [28/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0415Epoch [28/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0486Epoch [28/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.2309Epoch [28/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0646Epoch [28/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0355Epoch [28/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0185Epoch [28/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.3812Epoch [28/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0132Epoch [28/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.8720Epoch [28/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0569Epoch [28/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0051Epoch [28/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.4467Epoch [28/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.8976Epoch [28/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0400Epoch [28/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.3980Epoch [28/124], Batch [36/125] [#####---------------] 28.8%, Loss: 1.2121Epoch [28/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1102Epoch [28/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0289Epoch [28/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0316Epoch [28/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1271Epoch [28/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2274Epoch [28/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.4782Epoch [28/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1979Epoch [28/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0070Epoch [28/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0672Epoch [28/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0215Epoch [28/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1247Epoch [28/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1197Epoch [28/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0064Epoch [28/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1726Epoch [28/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0366Epoch [28/124], Batch [52/125] [########------------] 41.6%, Loss: 0.3013Epoch [28/124], Batch [53/125] [########------------] 42.4%, Loss: 1.2297Epoch [28/124], Batch [54/125] [########------------] 43.2%, Loss: 0.4600Epoch [28/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0239Epoch [28/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0215Epoch [28/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0392Epoch [28/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.6886Epoch [28/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0318Epoch [28/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1770Epoch [28/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.1792Epoch [28/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1320Epoch [28/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0374Epoch [28/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0184Epoch [28/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.2754Epoch [28/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0691Epoch [28/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.5105Epoch [28/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.6449Epoch [28/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1636Epoch [28/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0453Epoch [28/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0506Epoch [28/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0766Epoch [28/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.2781Epoch [28/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0146Epoch [28/124], Batch [75/125] [############--------] 60.0%, Loss: 0.4450Epoch [28/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0235Epoch [28/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0135Epoch [28/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0720Epoch [28/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0310Epoch [28/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1895Epoch [28/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0667Epoch [28/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0725Epoch [28/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0765Epoch [28/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0380Epoch [28/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1196Epoch [28/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.5095Epoch [28/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.6726Epoch [28/124], Batch [88/125] [##############------] 70.4%, Loss: 1.2514Epoch [28/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0834Epoch [28/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0095Epoch [28/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1675Epoch [28/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1563Epoch [28/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0427Epoch [28/124], Batch [94/125] [###############-----] 75.2%, Loss: 2.4458Epoch [28/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0023Epoch [28/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0730Epoch [28/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0073Epoch [28/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1134Epoch [28/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.3615Epoch [28/124], Batch [100/125] [################----] 80.0%, Loss: 0.4031Epoch [28/124], Batch [101/125] [################----] 80.8%, Loss: 0.0783Epoch [28/124], Batch [102/125] [################----] 81.6%, Loss: 0.0186Epoch [28/124], Batch [103/125] [################----] 82.4%, Loss: 0.0256Epoch [28/124], Batch [104/125] [################----] 83.2%, Loss: 0.5422Epoch [28/124], Batch [105/125] [################----] 84.0%, Loss: 0.0186Epoch [28/124], Batch [106/125] [################----] 84.8%, Loss: 0.0357Epoch [28/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1253Epoch [28/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1553Epoch [28/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1147Epoch [28/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0929Epoch [28/124], Batch [111/125] [#################---] 88.8%, Loss: 0.3003Epoch [28/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0587Epoch [28/124], Batch [113/125] [##################--] 90.4%, Loss: 1.1281Epoch [28/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2671Epoch [28/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0720Epoch [28/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0764Epoch [28/124], Batch [117/125] [##################--] 93.6%, Loss: 0.6618Epoch [28/124], Batch [118/125] [##################--] 94.4%, Loss: 0.7863Epoch [28/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0355Epoch [28/124], Batch [120/125] [###################-] 96.0%, Loss: 0.8749Epoch [28/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0480Epoch [28/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0317Epoch [28/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0855Epoch [28/124], Batch [124/125] [###################-] 99.2%, Loss: 0.8615Epoch [28/124], Batch [125/125] [####################] 100.0%, Loss: 0.1775
Epoch [28/124] finished. Average Loss: 0.2478
Training Accuracy: 96.20%
--- Saving checkpoint for epoch 28 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [29/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1260Epoch [29/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0576Epoch [29/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0056Epoch [29/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0699Epoch [29/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1568Epoch [29/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0309Epoch [29/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0055Epoch [29/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1659Epoch [29/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.3746Epoch [29/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0082Epoch [29/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.7644Epoch [29/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0714Epoch [29/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0188Epoch [29/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.1027Epoch [29/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.0845Epoch [29/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0074Epoch [29/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0627Epoch [29/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0035Epoch [29/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0024Epoch [29/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.9052Epoch [29/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1410Epoch [29/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.6930Epoch [29/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1133Epoch [29/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1144Epoch [29/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0720Epoch [29/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.3025Epoch [29/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.2229Epoch [29/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0380Epoch [29/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0393Epoch [29/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.2212Epoch [29/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0199Epoch [29/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.4269Epoch [29/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0199Epoch [29/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0217Epoch [29/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0554Epoch [29/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.4406Epoch [29/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0694Epoch [29/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.4771Epoch [29/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.5842Epoch [29/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0148Epoch [29/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.5939Epoch [29/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1670Epoch [29/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.5227Epoch [29/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.3096Epoch [29/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.2283Epoch [29/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1654Epoch [29/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0038Epoch [29/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.3161Epoch [29/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0076Epoch [29/124], Batch [50/125] [########------------] 40.0%, Loss: 0.3693Epoch [29/124], Batch [51/125] [########------------] 40.8%, Loss: 0.4997Epoch [29/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0188Epoch [29/124], Batch [53/125] [########------------] 42.4%, Loss: 0.1148Epoch [29/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1487Epoch [29/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0563Epoch [29/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0789Epoch [29/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0452Epoch [29/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1250Epoch [29/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0133Epoch [29/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0217Epoch [29/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0059Epoch [29/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1919Epoch [29/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0013Epoch [29/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.3896Epoch [29/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0501Epoch [29/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0370Epoch [29/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1039Epoch [29/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0158Epoch [29/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.3498Epoch [29/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0226Epoch [29/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0493Epoch [29/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1070Epoch [29/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.1150Epoch [29/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0595Epoch [29/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1046Epoch [29/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1365Epoch [29/124], Batch [77/125] [############--------] 61.6%, Loss: 0.3028Epoch [29/124], Batch [78/125] [############--------] 62.4%, Loss: 0.8140Epoch [29/124], Batch [79/125] [############--------] 63.2%, Loss: 0.5599Epoch [29/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0780Epoch [29/124], Batch [81/125] [############--------] 64.8%, Loss: 0.3435Epoch [29/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.5672Epoch [29/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.9129Epoch [29/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0888Epoch [29/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0983Epoch [29/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0220Epoch [29/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1174Epoch [29/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1555Epoch [29/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0151Epoch [29/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0602Epoch [29/124], Batch [91/125] [##############------] 72.8%, Loss: 0.3948Epoch [29/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0334Epoch [29/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0326Epoch [29/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2881Epoch [29/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0242Epoch [29/124], Batch [96/125] [###############-----] 76.8%, Loss: 1.5799Epoch [29/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0479Epoch [29/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0125Epoch [29/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2836Epoch [29/124], Batch [100/125] [################----] 80.0%, Loss: 0.0169Epoch [29/124], Batch [101/125] [################----] 80.8%, Loss: 0.0120Epoch [29/124], Batch [102/125] [################----] 81.6%, Loss: 0.7132Epoch [29/124], Batch [103/125] [################----] 82.4%, Loss: 0.0058Epoch [29/124], Batch [104/125] [################----] 83.2%, Loss: 0.4773Epoch [29/124], Batch [105/125] [################----] 84.0%, Loss: 0.9523Epoch [29/124], Batch [106/125] [################----] 84.8%, Loss: 0.1268Epoch [29/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0723Epoch [29/124], Batch [108/125] [#################---] 86.4%, Loss: 0.3519Epoch [29/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1597Epoch [29/124], Batch [110/125] [#################---] 88.0%, Loss: 0.5890Epoch [29/124], Batch [111/125] [#################---] 88.8%, Loss: 0.3104Epoch [29/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0377Epoch [29/124], Batch [113/125] [##################--] 90.4%, Loss: 0.6028Epoch [29/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1858Epoch [29/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1602Epoch [29/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3602Epoch [29/124], Batch [117/125] [##################--] 93.6%, Loss: 0.6980Epoch [29/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1961Epoch [29/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0163Epoch [29/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0874Epoch [29/124], Batch [121/125] [###################-] 96.8%, Loss: 0.1763Epoch [29/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1985Epoch [29/124], Batch [123/125] [###################-] 98.4%, Loss: 1.3434Epoch [29/124], Batch [124/125] [###################-] 99.2%, Loss: 1.2582Epoch [29/124], Batch [125/125] [####################] 100.0%, Loss: 0.0445
Epoch [29/124] finished. Average Loss: 0.2371
Training Accuracy: 95.80%
--- Saving checkpoint for epoch 29 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [30/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.3220Epoch [30/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0008Epoch [30/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0426Epoch [30/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0239Epoch [30/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0680Epoch [30/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0093Epoch [30/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1209Epoch [30/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0536Epoch [30/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0041Epoch [30/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0485Epoch [30/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.5830Epoch [30/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0407Epoch [30/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.1715Epoch [30/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0855Epoch [30/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.7817Epoch [30/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0113Epoch [30/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.2793Epoch [30/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.2834Epoch [30/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0281Epoch [30/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0196Epoch [30/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.3926Epoch [30/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.3611Epoch [30/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1076Epoch [30/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.2389Epoch [30/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1266Epoch [30/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0172Epoch [30/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0073Epoch [30/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0202Epoch [30/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0403Epoch [30/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0665Epoch [30/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1717Epoch [30/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.6323Epoch [30/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0149Epoch [30/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1872Epoch [30/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.2784Epoch [30/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.5965Epoch [30/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1893Epoch [30/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0757Epoch [30/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0016Epoch [30/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.3538Epoch [30/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.4576Epoch [30/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.5392Epoch [30/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.3530Epoch [30/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0330Epoch [30/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0173Epoch [30/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0099Epoch [30/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.9727Epoch [30/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1137Epoch [30/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0688Epoch [30/124], Batch [50/125] [########------------] 40.0%, Loss: 0.8717Epoch [30/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1704Epoch [30/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0379Epoch [30/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0493Epoch [30/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1869Epoch [30/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2448Epoch [30/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0252Epoch [30/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0201Epoch [30/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0074Epoch [30/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.9560Epoch [30/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0535Epoch [30/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.6378Epoch [30/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0015Epoch [30/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0057Epoch [30/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2254Epoch [30/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0098Epoch [30/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.4472Epoch [30/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1161Epoch [30/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1886Epoch [30/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0568Epoch [30/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.0993Epoch [30/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0297Epoch [30/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0314Epoch [30/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0076Epoch [30/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0744Epoch [30/124], Batch [75/125] [############--------] 60.0%, Loss: 0.2929Epoch [30/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0145Epoch [30/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0176Epoch [30/124], Batch [78/125] [############--------] 62.4%, Loss: 1.1909Epoch [30/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0150Epoch [30/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1625Epoch [30/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0723Epoch [30/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0206Epoch [30/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0245Epoch [30/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0514Epoch [30/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1562Epoch [30/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0154Epoch [30/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0211Epoch [30/124], Batch [88/125] [##############------] 70.4%, Loss: 2.0092Epoch [30/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0967Epoch [30/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0350Epoch [30/124], Batch [91/125] [##############------] 72.8%, Loss: 0.4256Epoch [30/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1721Epoch [30/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0065Epoch [30/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0164Epoch [30/124], Batch [95/125] [###############-----] 76.0%, Loss: 1.0030Epoch [30/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.4435Epoch [30/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0209Epoch [30/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0473Epoch [30/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0300Epoch [30/124], Batch [100/125] [################----] 80.0%, Loss: 0.2048Epoch [30/124], Batch [101/125] [################----] 80.8%, Loss: 0.9552Epoch [30/124], Batch [102/125] [################----] 81.6%, Loss: 0.0109Epoch [30/124], Batch [103/125] [################----] 82.4%, Loss: 0.2214Epoch [30/124], Batch [104/125] [################----] 83.2%, Loss: 0.0437Epoch [30/124], Batch [105/125] [################----] 84.0%, Loss: 0.5705Epoch [30/124], Batch [106/125] [################----] 84.8%, Loss: 0.0023Epoch [30/124], Batch [107/125] [#################---] 85.6%, Loss: 0.2166Epoch [30/124], Batch [108/125] [#################---] 86.4%, Loss: 0.7672Epoch [30/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0674Epoch [30/124], Batch [110/125] [#################---] 88.0%, Loss: 0.2707Epoch [30/124], Batch [111/125] [#################---] 88.8%, Loss: 0.5254Epoch [30/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0939Epoch [30/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0238Epoch [30/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1945Epoch [30/124], Batch [115/125] [##################--] 92.0%, Loss: 1.3452Epoch [30/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1661Epoch [30/124], Batch [117/125] [##################--] 93.6%, Loss: 0.6312Epoch [30/124], Batch [118/125] [##################--] 94.4%, Loss: 0.2944Epoch [30/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0095Epoch [30/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0211Epoch [30/124], Batch [121/125] [###################-] 96.8%, Loss: 0.6936Epoch [30/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0256Epoch [30/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0545Epoch [30/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1162Epoch [30/124], Batch [125/125] [####################] 100.0%, Loss: 0.4460
Epoch [30/124] finished. Average Loss: 0.2425
Training Accuracy: 96.00%
--- Saving checkpoint for epoch 30 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [31/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0277Epoch [31/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0203Epoch [31/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0803Epoch [31/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0312Epoch [31/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.2467Epoch [31/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.2807Epoch [31/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.8461Epoch [31/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0184Epoch [31/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0657Epoch [31/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.2608Epoch [31/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0905Epoch [31/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0115Epoch [31/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.4285Epoch [31/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.2710Epoch [31/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0446Epoch [31/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0379Epoch [31/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1042Epoch [31/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1294Epoch [31/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.3596Epoch [31/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0033Epoch [31/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0255Epoch [31/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1535Epoch [31/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.4976Epoch [31/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0261Epoch [31/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3583Epoch [31/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1248Epoch [31/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0266Epoch [31/124], Batch [28/125] [####----------------] 22.4%, Loss: 1.1520Epoch [31/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1005Epoch [31/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0148Epoch [31/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.7581Epoch [31/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.6288Epoch [31/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.3752Epoch [31/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0148Epoch [31/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0042Epoch [31/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.5616Epoch [31/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.3468Epoch [31/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0340Epoch [31/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0661Epoch [31/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1036Epoch [31/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.3061Epoch [31/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.8008Epoch [31/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2587Epoch [31/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0092Epoch [31/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0647Epoch [31/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1799Epoch [31/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.5026Epoch [31/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0846Epoch [31/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0221Epoch [31/124], Batch [50/125] [########------------] 40.0%, Loss: 0.5016Epoch [31/124], Batch [51/125] [########------------] 40.8%, Loss: 0.3028Epoch [31/124], Batch [52/125] [########------------] 41.6%, Loss: 0.4144Epoch [31/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2123Epoch [31/124], Batch [54/125] [########------------] 43.2%, Loss: 0.9443Epoch [31/124], Batch [55/125] [########------------] 44.0%, Loss: 0.4703Epoch [31/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1340Epoch [31/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.2068Epoch [31/124], Batch [58/125] [#########-----------] 46.4%, Loss: 1.1008Epoch [31/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1032Epoch [31/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0366Epoch [31/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0504Epoch [31/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.8351Epoch [31/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0333Epoch [31/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0537Epoch [31/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0177Epoch [31/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.4277Epoch [31/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1058Epoch [31/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1347Epoch [31/124], Batch [69/125] [###########---------] 55.2%, Loss: 1.2475Epoch [31/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1590Epoch [31/124], Batch [71/125] [###########---------] 56.8%, Loss: 1.7548Epoch [31/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.8943Epoch [31/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0122Epoch [31/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1433Epoch [31/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0182Epoch [31/124], Batch [76/125] [############--------] 60.8%, Loss: 0.7922Epoch [31/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0082Epoch [31/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0628Epoch [31/124], Batch [79/125] [############--------] 63.2%, Loss: 0.5192Epoch [31/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0701Epoch [31/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0977Epoch [31/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.2866Epoch [31/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1406Epoch [31/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.7606Epoch [31/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1443Epoch [31/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0170Epoch [31/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0842Epoch [31/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0857Epoch [31/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0599Epoch [31/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1706Epoch [31/124], Batch [91/125] [##############------] 72.8%, Loss: 0.2191Epoch [31/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0591Epoch [31/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0052Epoch [31/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1133Epoch [31/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0343Epoch [31/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0049Epoch [31/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0055Epoch [31/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1203Epoch [31/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1869Epoch [31/124], Batch [100/125] [################----] 80.0%, Loss: 0.7340Epoch [31/124], Batch [101/125] [################----] 80.8%, Loss: 0.2605Epoch [31/124], Batch [102/125] [################----] 81.6%, Loss: 0.0807Epoch [31/124], Batch [103/125] [################----] 82.4%, Loss: 0.0382Epoch [31/124], Batch [104/125] [################----] 83.2%, Loss: 0.2479Epoch [31/124], Batch [105/125] [################----] 84.0%, Loss: 0.0066Epoch [31/124], Batch [106/125] [################----] 84.8%, Loss: 0.2281Epoch [31/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0296Epoch [31/124], Batch [108/125] [#################---] 86.4%, Loss: 0.4000Epoch [31/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0194Epoch [31/124], Batch [110/125] [#################---] 88.0%, Loss: 0.2491Epoch [31/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0404Epoch [31/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0446Epoch [31/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0139Epoch [31/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2878Epoch [31/124], Batch [115/125] [##################--] 92.0%, Loss: 0.9452Epoch [31/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0812Epoch [31/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0905Epoch [31/124], Batch [118/125] [##################--] 94.4%, Loss: 0.3734Epoch [31/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0223Epoch [31/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2387Epoch [31/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0317Epoch [31/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2115Epoch [31/124], Batch [123/125] [###################-] 98.4%, Loss: 0.7982Epoch [31/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0138Epoch [31/124], Batch [125/125] [####################] 100.0%, Loss: 0.0795
Epoch [31/124] finished. Average Loss: 0.2471
Training Accuracy: 95.80%
--- Saving checkpoint for epoch 31 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [32/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.9087Epoch [32/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0353Epoch [32/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0628Epoch [32/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0698Epoch [32/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0245Epoch [32/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.1835Epoch [32/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0591Epoch [32/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0527Epoch [32/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2682Epoch [32/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0026Epoch [32/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2555Epoch [32/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0006Epoch [32/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0037Epoch [32/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0081Epoch [32/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0189Epoch [32/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0208Epoch [32/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0035Epoch [32/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0304Epoch [32/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.1649Epoch [32/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0480Epoch [32/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0047Epoch [32/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0363Epoch [32/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0387Epoch [32/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.5025Epoch [32/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1629Epoch [32/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.3674Epoch [32/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0492Epoch [32/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.3222Epoch [32/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1329Epoch [32/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.4877Epoch [32/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0660Epoch [32/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0041Epoch [32/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0440Epoch [32/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0038Epoch [32/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.3118Epoch [32/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.2721Epoch [32/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0290Epoch [32/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0258Epoch [32/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0504Epoch [32/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.2098Epoch [32/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0470Epoch [32/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1626Epoch [32/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.8249Epoch [32/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0162Epoch [32/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0968Epoch [32/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0020Epoch [32/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1026Epoch [32/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.3859Epoch [32/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.1129Epoch [32/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1538Epoch [32/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0139Epoch [32/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0754Epoch [32/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0582Epoch [32/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1345Epoch [32/124], Batch [55/125] [########------------] 44.0%, Loss: 0.1340Epoch [32/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0013Epoch [32/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0332Epoch [32/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0928Epoch [32/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0585Epoch [32/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0692Epoch [32/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.1084Epoch [32/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1536Epoch [32/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1310Epoch [32/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0483Epoch [32/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0195Epoch [32/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0269Epoch [32/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0696Epoch [32/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.3056Epoch [32/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0121Epoch [32/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0461Epoch [32/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0015Epoch [32/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0819Epoch [32/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0136Epoch [32/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0156Epoch [32/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0292Epoch [32/124], Batch [76/125] [############--------] 60.8%, Loss: 0.3710Epoch [32/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0531Epoch [32/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0108Epoch [32/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0125Epoch [32/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0690Epoch [32/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1335Epoch [32/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0840Epoch [32/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1129Epoch [32/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0018Epoch [32/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0347Epoch [32/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.2344Epoch [32/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0101Epoch [32/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0113Epoch [32/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2168Epoch [32/124], Batch [90/125] [##############------] 72.0%, Loss: 0.2530Epoch [32/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0034Epoch [32/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0214Epoch [32/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0329Epoch [32/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.3937Epoch [32/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0026Epoch [32/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0322Epoch [32/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0132Epoch [32/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0402Epoch [32/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0215Epoch [32/124], Batch [100/125] [################----] 80.0%, Loss: 0.0260Epoch [32/124], Batch [101/125] [################----] 80.8%, Loss: 0.0832Epoch [32/124], Batch [102/125] [################----] 81.6%, Loss: 0.0081Epoch [32/124], Batch [103/125] [################----] 82.4%, Loss: 0.0993Epoch [32/124], Batch [104/125] [################----] 83.2%, Loss: 0.0657Epoch [32/124], Batch [105/125] [################----] 84.0%, Loss: 0.6300Epoch [32/124], Batch [106/125] [################----] 84.8%, Loss: 0.0161Epoch [32/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0376Epoch [32/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0952Epoch [32/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0474Epoch [32/124], Batch [110/125] [#################---] 88.0%, Loss: 0.4644Epoch [32/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0009Epoch [32/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0037Epoch [32/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0072Epoch [32/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1045Epoch [32/124], Batch [115/125] [##################--] 92.0%, Loss: 0.6951Epoch [32/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0028Epoch [32/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0101Epoch [32/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0036Epoch [32/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0842Epoch [32/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0091Epoch [32/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0317Epoch [32/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0645Epoch [32/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0010Epoch [32/124], Batch [124/125] [###################-] 99.2%, Loss: 1.3780Epoch [32/124], Batch [125/125] [####################] 100.0%, Loss: 0.0053
Epoch [32/124] finished. Average Loss: 0.1210
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 32 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [33/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1354Epoch [33/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0035Epoch [33/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0116Epoch [33/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0411Epoch [33/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0015Epoch [33/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0447Epoch [33/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0167Epoch [33/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0040Epoch [33/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.4359Epoch [33/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0797Epoch [33/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0243Epoch [33/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.5105Epoch [33/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.7347Epoch [33/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0013Epoch [33/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.1010Epoch [33/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0081Epoch [33/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3270Epoch [33/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0097Epoch [33/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0028Epoch [33/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0098Epoch [33/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.7062Epoch [33/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1659Epoch [33/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0103Epoch [33/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0013Epoch [33/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0118Epoch [33/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0100Epoch [33/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0150Epoch [33/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0034Epoch [33/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0980Epoch [33/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0070Epoch [33/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0329Epoch [33/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0057Epoch [33/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.5064Epoch [33/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0201Epoch [33/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0018Epoch [33/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0096Epoch [33/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0040Epoch [33/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0178Epoch [33/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.2358Epoch [33/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0179Epoch [33/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0053Epoch [33/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0071Epoch [33/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2921Epoch [33/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0544Epoch [33/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0860Epoch [33/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0065Epoch [33/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.4489Epoch [33/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0708Epoch [33/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0028Epoch [33/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0330Epoch [33/124], Batch [51/125] [########------------] 40.8%, Loss: 0.8717Epoch [33/124], Batch [52/125] [########------------] 41.6%, Loss: 0.7875Epoch [33/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0028Epoch [33/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0069Epoch [33/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0141Epoch [33/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1939Epoch [33/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0318Epoch [33/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0251Epoch [33/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0094Epoch [33/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.3355Epoch [33/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0549Epoch [33/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.6115Epoch [33/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1621Epoch [33/124], Batch [64/125] [##########----------] 51.2%, Loss: 1.4029Epoch [33/124], Batch [65/125] [##########----------] 52.0%, Loss: 1.1341Epoch [33/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1766Epoch [33/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0046Epoch [33/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0166Epoch [33/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0176Epoch [33/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0131Epoch [33/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0026Epoch [33/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0382Epoch [33/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.3406Epoch [33/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0432Epoch [33/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0102Epoch [33/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0488Epoch [33/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0070Epoch [33/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1001Epoch [33/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1394Epoch [33/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0671Epoch [33/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0314Epoch [33/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0691Epoch [33/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0051Epoch [33/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0805Epoch [33/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1562Epoch [33/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0151Epoch [33/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0450Epoch [33/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0516Epoch [33/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0240Epoch [33/124], Batch [90/125] [##############------] 72.0%, Loss: 0.3523Epoch [33/124], Batch [91/125] [##############------] 72.8%, Loss: 0.2406Epoch [33/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4381Epoch [33/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0351Epoch [33/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2872Epoch [33/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0033Epoch [33/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0060Epoch [33/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1305Epoch [33/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0016Epoch [33/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.3297Epoch [33/124], Batch [100/125] [################----] 80.0%, Loss: 0.5931Epoch [33/124], Batch [101/125] [################----] 80.8%, Loss: 0.2052Epoch [33/124], Batch [102/125] [################----] 81.6%, Loss: 0.3213Epoch [33/124], Batch [103/125] [################----] 82.4%, Loss: 0.0055Epoch [33/124], Batch [104/125] [################----] 83.2%, Loss: 0.0791Epoch [33/124], Batch [105/125] [################----] 84.0%, Loss: 0.0946Epoch [33/124], Batch [106/125] [################----] 84.8%, Loss: 0.1794Epoch [33/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0755Epoch [33/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0740Epoch [33/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0152Epoch [33/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0483Epoch [33/124], Batch [111/125] [#################---] 88.8%, Loss: 0.2823Epoch [33/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0208Epoch [33/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0886Epoch [33/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0370Epoch [33/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0250Epoch [33/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0325Epoch [33/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1413Epoch [33/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0346Epoch [33/124], Batch [119/125] [###################-] 95.2%, Loss: 0.3905Epoch [33/124], Batch [120/125] [###################-] 96.0%, Loss: 0.4935Epoch [33/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0160Epoch [33/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2850Epoch [33/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0080Epoch [33/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0007Epoch [33/124], Batch [125/125] [####################] 100.0%, Loss: 0.8878
Epoch [33/124] finished. Average Loss: 0.1584
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 33 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [34/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0014Epoch [34/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.3249Epoch [34/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0277Epoch [34/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.2067Epoch [34/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0030Epoch [34/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0029Epoch [34/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0068Epoch [34/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.3239Epoch [34/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0293Epoch [34/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0149Epoch [34/124], Batch [11/125] [#-------------------] 8.8%, Loss: 1.1261Epoch [34/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0306Epoch [34/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2721Epoch [34/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0038Epoch [34/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.1367Epoch [34/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0370Epoch [34/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0108Epoch [34/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1767Epoch [34/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0076Epoch [34/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.5114Epoch [34/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0597Epoch [34/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0926Epoch [34/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1383Epoch [34/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.2405Epoch [34/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0120Epoch [34/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0135Epoch [34/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0020Epoch [34/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0024Epoch [34/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0041Epoch [34/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1128Epoch [34/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0127Epoch [34/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0007Epoch [34/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0098Epoch [34/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0175Epoch [34/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0021Epoch [34/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.2284Epoch [34/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0141Epoch [34/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0786Epoch [34/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1856Epoch [34/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0159Epoch [34/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0641Epoch [34/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0141Epoch [34/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0278Epoch [34/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0054Epoch [34/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.5025Epoch [34/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0652Epoch [34/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0166Epoch [34/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1397Epoch [34/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0271Epoch [34/124], Batch [50/125] [########------------] 40.0%, Loss: 0.2245Epoch [34/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0361Epoch [34/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1759Epoch [34/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0215Epoch [34/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0084Epoch [34/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0734Epoch [34/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0136Epoch [34/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0596Epoch [34/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0102Epoch [34/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2162Epoch [34/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1169Epoch [34/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0159Epoch [34/124], Batch [62/125] [#########-----------] 49.6%, Loss: 1.3656Epoch [34/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.7073Epoch [34/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.3496Epoch [34/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0082Epoch [34/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0464Epoch [34/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0058Epoch [34/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0022Epoch [34/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0143Epoch [34/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.3260Epoch [34/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0069Epoch [34/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0077Epoch [34/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0207Epoch [34/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0664Epoch [34/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0509Epoch [34/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0176Epoch [34/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0010Epoch [34/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0102Epoch [34/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0004Epoch [34/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0376Epoch [34/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0623Epoch [34/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0698Epoch [34/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0144Epoch [34/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0136Epoch [34/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0562Epoch [34/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.9926Epoch [34/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0022Epoch [34/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0219Epoch [34/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0085Epoch [34/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0088Epoch [34/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0086Epoch [34/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0323Epoch [34/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0180Epoch [34/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0128Epoch [34/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0038Epoch [34/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0102Epoch [34/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0059Epoch [34/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0015Epoch [34/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1733Epoch [34/124], Batch [100/125] [################----] 80.0%, Loss: 0.2389Epoch [34/124], Batch [101/125] [################----] 80.8%, Loss: 0.0135Epoch [34/124], Batch [102/125] [################----] 81.6%, Loss: 0.1039Epoch [34/124], Batch [103/125] [################----] 82.4%, Loss: 0.0645Epoch [34/124], Batch [104/125] [################----] 83.2%, Loss: 0.1692Epoch [34/124], Batch [105/125] [################----] 84.0%, Loss: 0.0120Epoch [34/124], Batch [106/125] [################----] 84.8%, Loss: 0.0801Epoch [34/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0273Epoch [34/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0105Epoch [34/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0146Epoch [34/124], Batch [110/125] [#################---] 88.0%, Loss: 0.2150Epoch [34/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0266Epoch [34/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0091Epoch [34/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0247Epoch [34/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0061Epoch [34/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2969Epoch [34/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0171Epoch [34/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0580Epoch [34/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0022Epoch [34/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0054Epoch [34/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0105Epoch [34/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0018Epoch [34/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0070Epoch [34/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0139Epoch [34/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0284Epoch [34/124], Batch [125/125] [####################] 100.0%, Loss: 0.0155
Epoch [34/124] finished. Average Loss: 0.0989
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 34 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [35/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0018Epoch [35/124], Batch [2/125] [--------------------] 1.6%, Loss: 3.5815Epoch [35/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0026Epoch [35/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0125Epoch [35/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0168Epoch [35/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0058Epoch [35/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.2529Epoch [35/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0492Epoch [35/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1957Epoch [35/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0057Epoch [35/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0100Epoch [35/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0203Epoch [35/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2416Epoch [35/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0770Epoch [35/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0411Epoch [35/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0063Epoch [35/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.8117Epoch [35/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0249Epoch [35/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0063Epoch [35/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0283Epoch [35/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1976Epoch [35/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0762Epoch [35/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.2472Epoch [35/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0001Epoch [35/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.4142Epoch [35/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0410Epoch [35/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0089Epoch [35/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0010Epoch [35/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0983Epoch [35/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0123Epoch [35/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0277Epoch [35/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2733Epoch [35/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0062Epoch [35/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0205Epoch [35/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0069Epoch [35/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0581Epoch [35/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.2862Epoch [35/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0993Epoch [35/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0140Epoch [35/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0423Epoch [35/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2202Epoch [35/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0059Epoch [35/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0558Epoch [35/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0079Epoch [35/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0011Epoch [35/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0532Epoch [35/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0642Epoch [35/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2650Epoch [35/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0107Epoch [35/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0221Epoch [35/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0033Epoch [35/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0168Epoch [35/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0046Epoch [35/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0029Epoch [35/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0284Epoch [35/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0343Epoch [35/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0219Epoch [35/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0124Epoch [35/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0154Epoch [35/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0019Epoch [35/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0070Epoch [35/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0251Epoch [35/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0135Epoch [35/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0239Epoch [35/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1255Epoch [35/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0998Epoch [35/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0287Epoch [35/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0777Epoch [35/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1647Epoch [35/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0004Epoch [35/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0559Epoch [35/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0033Epoch [35/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0036Epoch [35/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0125Epoch [35/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0482Epoch [35/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0386Epoch [35/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0154Epoch [35/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0086Epoch [35/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1687Epoch [35/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0359Epoch [35/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0221Epoch [35/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0162Epoch [35/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0238Epoch [35/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.1364Epoch [35/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1844Epoch [35/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0061Epoch [35/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0068Epoch [35/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0108Epoch [35/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0249Epoch [35/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1795Epoch [35/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0118Epoch [35/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0399Epoch [35/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0479Epoch [35/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0386Epoch [35/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0101Epoch [35/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0138Epoch [35/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0012Epoch [35/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.3126Epoch [35/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0020Epoch [35/124], Batch [100/125] [################----] 80.0%, Loss: 0.0022Epoch [35/124], Batch [101/125] [################----] 80.8%, Loss: 0.0064Epoch [35/124], Batch [102/125] [################----] 81.6%, Loss: 0.0055Epoch [35/124], Batch [103/125] [################----] 82.4%, Loss: 0.0507Epoch [35/124], Batch [104/125] [################----] 83.2%, Loss: 0.0096Epoch [35/124], Batch [105/125] [################----] 84.0%, Loss: 0.1729Epoch [35/124], Batch [106/125] [################----] 84.8%, Loss: 0.0136Epoch [35/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0135Epoch [35/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0450Epoch [35/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1120Epoch [35/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0303Epoch [35/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0019Epoch [35/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0017Epoch [35/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0004Epoch [35/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0436Epoch [35/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0071Epoch [35/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0005Epoch [35/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0330Epoch [35/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0034Epoch [35/124], Batch [119/125] [###################-] 95.2%, Loss: 0.2086Epoch [35/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0118Epoch [35/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0574Epoch [35/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0005Epoch [35/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0172Epoch [35/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0057Epoch [35/124], Batch [125/125] [####################] 100.0%, Loss: 0.0168
Epoch [35/124] finished. Average Loss: 0.0887
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 35 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [36/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0128Epoch [36/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0077Epoch [36/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.7067Epoch [36/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0142Epoch [36/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0025Epoch [36/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0088Epoch [36/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0012Epoch [36/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0020Epoch [36/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0118Epoch [36/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.3013Epoch [36/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0025Epoch [36/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0039Epoch [36/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0024Epoch [36/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0059Epoch [36/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0447Epoch [36/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0033Epoch [36/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0010Epoch [36/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1385Epoch [36/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.1371Epoch [36/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0121Epoch [36/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0854Epoch [36/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1233Epoch [36/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0205Epoch [36/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0252Epoch [36/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0052Epoch [36/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0019Epoch [36/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0031Epoch [36/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.4264Epoch [36/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0016Epoch [36/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0728Epoch [36/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0088Epoch [36/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0324Epoch [36/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0008Epoch [36/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0090Epoch [36/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0012Epoch [36/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0013Epoch [36/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0042Epoch [36/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1701Epoch [36/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3765Epoch [36/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0032Epoch [36/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0094Epoch [36/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0142Epoch [36/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0014Epoch [36/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0004Epoch [36/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0022Epoch [36/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0035Epoch [36/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0104Epoch [36/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0370Epoch [36/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0008Epoch [36/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0008Epoch [36/124], Batch [51/125] [########------------] 40.8%, Loss: 0.4900Epoch [36/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1508Epoch [36/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0151Epoch [36/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0005Epoch [36/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0019Epoch [36/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0469Epoch [36/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0017Epoch [36/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0056Epoch [36/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0373Epoch [36/124], Batch [60/125] [#########-----------] 48.0%, Loss: 2.9036Epoch [36/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0037Epoch [36/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0313Epoch [36/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0064Epoch [36/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0191Epoch [36/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.8369Epoch [36/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2250Epoch [36/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0487Epoch [36/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0277Epoch [36/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0016Epoch [36/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0067Epoch [36/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0024Epoch [36/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0077Epoch [36/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0431Epoch [36/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0968Epoch [36/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0203Epoch [36/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0041Epoch [36/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0214Epoch [36/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0450Epoch [36/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0040Epoch [36/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0707Epoch [36/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0628Epoch [36/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0068Epoch [36/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0090Epoch [36/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0096Epoch [36/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0003Epoch [36/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0388Epoch [36/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0064Epoch [36/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0526Epoch [36/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0099Epoch [36/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0002Epoch [36/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0053Epoch [36/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0024Epoch [36/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0054Epoch [36/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0082Epoch [36/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0196Epoch [36/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0114Epoch [36/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0037Epoch [36/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0378Epoch [36/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.6276Epoch [36/124], Batch [100/125] [################----] 80.0%, Loss: 0.0174Epoch [36/124], Batch [101/125] [################----] 80.8%, Loss: 0.6879Epoch [36/124], Batch [102/125] [################----] 81.6%, Loss: 0.0013Epoch [36/124], Batch [103/125] [################----] 82.4%, Loss: 0.0043Epoch [36/124], Batch [104/125] [################----] 83.2%, Loss: 0.0272Epoch [36/124], Batch [105/125] [################----] 84.0%, Loss: 0.0011Epoch [36/124], Batch [106/125] [################----] 84.8%, Loss: 0.0970Epoch [36/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0033Epoch [36/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0773Epoch [36/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0034Epoch [36/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0642Epoch [36/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0244Epoch [36/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0188Epoch [36/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2013Epoch [36/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0720Epoch [36/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0011Epoch [36/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0231Epoch [36/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0124Epoch [36/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0988Epoch [36/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0371Epoch [36/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0053Epoch [36/124], Batch [121/125] [###################-] 96.8%, Loss: 0.4351Epoch [36/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0323Epoch [36/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0585Epoch [36/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0397Epoch [36/124], Batch [125/125] [####################] 100.0%, Loss: 0.0230
Epoch [36/124] finished. Average Loss: 0.0883
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 36 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [37/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0733Epoch [37/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0069Epoch [37/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0150Epoch [37/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0518Epoch [37/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0888Epoch [37/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0426Epoch [37/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0060Epoch [37/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0491Epoch [37/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0051Epoch [37/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.1127Epoch [37/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0066Epoch [37/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0132Epoch [37/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0181Epoch [37/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0056Epoch [37/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.1205Epoch [37/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2277Epoch [37/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1352Epoch [37/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0273Epoch [37/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0046Epoch [37/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0055Epoch [37/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.4430Epoch [37/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0052Epoch [37/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0048Epoch [37/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.6120Epoch [37/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0688Epoch [37/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.6197Epoch [37/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0128Epoch [37/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0795Epoch [37/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2178Epoch [37/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0131Epoch [37/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0111Epoch [37/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0151Epoch [37/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0729Epoch [37/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0199Epoch [37/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0132Epoch [37/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0858Epoch [37/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0067Epoch [37/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1161Epoch [37/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1096Epoch [37/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0060Epoch [37/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0969Epoch [37/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1078Epoch [37/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1322Epoch [37/124], Batch [44/125] [#######-------------] 35.2%, Loss: 1.3411Epoch [37/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.7483Epoch [37/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0585Epoch [37/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0107Epoch [37/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0107Epoch [37/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0626Epoch [37/124], Batch [50/125] [########------------] 40.0%, Loss: 0.4064Epoch [37/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0044Epoch [37/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0046Epoch [37/124], Batch [53/125] [########------------] 42.4%, Loss: 0.7926Epoch [37/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0142Epoch [37/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0127Epoch [37/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0200Epoch [37/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0232Epoch [37/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0607Epoch [37/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0059Epoch [37/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0019Epoch [37/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0111Epoch [37/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0227Epoch [37/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0607Epoch [37/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2984Epoch [37/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.7299Epoch [37/124], Batch [66/125] [##########----------] 52.8%, Loss: 1.3146Epoch [37/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.2374Epoch [37/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0091Epoch [37/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0304Epoch [37/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0428Epoch [37/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.2479Epoch [37/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1504Epoch [37/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.2652Epoch [37/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.4813Epoch [37/124], Batch [75/125] [############--------] 60.0%, Loss: 0.9848Epoch [37/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0606Epoch [37/124], Batch [77/125] [############--------] 61.6%, Loss: 0.3135Epoch [37/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0012Epoch [37/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1517Epoch [37/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0208Epoch [37/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0031Epoch [37/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0172Epoch [37/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0573Epoch [37/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.7714Epoch [37/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0179Epoch [37/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0805Epoch [37/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0263Epoch [37/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1204Epoch [37/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2087Epoch [37/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0418Epoch [37/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1480Epoch [37/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2264Epoch [37/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0109Epoch [37/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.7252Epoch [37/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3831Epoch [37/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0385Epoch [37/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.2755Epoch [37/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.5150Epoch [37/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.4801Epoch [37/124], Batch [100/125] [################----] 80.0%, Loss: 0.1245Epoch [37/124], Batch [101/125] [################----] 80.8%, Loss: 0.0044Epoch [37/124], Batch [102/125] [################----] 81.6%, Loss: 0.0058Epoch [37/124], Batch [103/125] [################----] 82.4%, Loss: 0.4090Epoch [37/124], Batch [104/125] [################----] 83.2%, Loss: 0.0054Epoch [37/124], Batch [105/125] [################----] 84.0%, Loss: 0.9157Epoch [37/124], Batch [106/125] [################----] 84.8%, Loss: 0.0104Epoch [37/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0160Epoch [37/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0283Epoch [37/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0095Epoch [37/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0259Epoch [37/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0129Epoch [37/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0189Epoch [37/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0172Epoch [37/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0737Epoch [37/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1008Epoch [37/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1300Epoch [37/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0551Epoch [37/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0328Epoch [37/124], Batch [119/125] [###################-] 95.2%, Loss: 0.4256Epoch [37/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0125Epoch [37/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0810Epoch [37/124], Batch [122/125] [###################-] 97.6%, Loss: 1.6755Epoch [37/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0292Epoch [37/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0051Epoch [37/124], Batch [125/125] [####################] 100.0%, Loss: 0.5490
Epoch [37/124] finished. Average Loss: 0.1826
Training Accuracy: 98.40%
--- Saving checkpoint for epoch 37 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [38/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0038Epoch [38/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0166Epoch [38/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0097Epoch [38/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0165Epoch [38/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0361Epoch [38/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0232Epoch [38/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0665Epoch [38/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0340Epoch [38/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0124Epoch [38/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0296Epoch [38/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0075Epoch [38/124], Batch [12/125] [#-------------------] 9.6%, Loss: 1.9750Epoch [38/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0046Epoch [38/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0332Epoch [38/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0039Epoch [38/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0067Epoch [38/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0151Epoch [38/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0128Epoch [38/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0286Epoch [38/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1539Epoch [38/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.6631Epoch [38/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1906Epoch [38/124], Batch [23/125] [###-----------------] 18.4%, Loss: 1.2410Epoch [38/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0125Epoch [38/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0044Epoch [38/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0402Epoch [38/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0079Epoch [38/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0601Epoch [38/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1512Epoch [38/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.9396Epoch [38/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.5156Epoch [38/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0669Epoch [38/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0166Epoch [38/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0060Epoch [38/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0019Epoch [38/124], Batch [36/125] [#####---------------] 28.8%, Loss: 1.3610Epoch [38/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0179Epoch [38/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.2649Epoch [38/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3646Epoch [38/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0447Epoch [38/124], Batch [41/125] [######--------------] 32.8%, Loss: 1.4465Epoch [38/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0004Epoch [38/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0175Epoch [38/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0344Epoch [38/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0145Epoch [38/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.2629Epoch [38/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0354Epoch [38/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0787Epoch [38/124], Batch [49/125] [#######-------------] 39.2%, Loss: 1.4713Epoch [38/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0705Epoch [38/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0042Epoch [38/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0038Epoch [38/124], Batch [53/125] [########------------] 42.4%, Loss: 1.6468Epoch [38/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0882Epoch [38/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0337Epoch [38/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0057Epoch [38/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1121Epoch [38/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0178Epoch [38/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0484Epoch [38/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0188Epoch [38/124], Batch [61/125] [#########-----------] 48.8%, Loss: 2.0221Epoch [38/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0149Epoch [38/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.7669Epoch [38/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0043Epoch [38/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0445Epoch [38/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.6744Epoch [38/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.4575Epoch [38/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0188Epoch [38/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0038Epoch [38/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0759Epoch [38/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0248Epoch [38/124], Batch [72/125] [###########---------] 57.6%, Loss: 1.1623Epoch [38/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.6146Epoch [38/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2602Epoch [38/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0247Epoch [38/124], Batch [76/125] [############--------] 60.8%, Loss: 0.3454Epoch [38/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0071Epoch [38/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0246Epoch [38/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1250Epoch [38/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0708Epoch [38/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0070Epoch [38/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0351Epoch [38/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1153Epoch [38/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0112Epoch [38/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.7058Epoch [38/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1733Epoch [38/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0626Epoch [38/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0270Epoch [38/124], Batch [89/125] [##############------] 71.2%, Loss: 1.2663Epoch [38/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1797Epoch [38/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1599Epoch [38/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4339Epoch [38/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2403Epoch [38/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0414Epoch [38/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0639Epoch [38/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0194Epoch [38/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0037Epoch [38/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0239Epoch [38/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.7874Epoch [38/124], Batch [100/125] [################----] 80.0%, Loss: 0.8573Epoch [38/124], Batch [101/125] [################----] 80.8%, Loss: 0.1022Epoch [38/124], Batch [102/125] [################----] 81.6%, Loss: 0.2084Epoch [38/124], Batch [103/125] [################----] 82.4%, Loss: 0.1229Epoch [38/124], Batch [104/125] [################----] 83.2%, Loss: 0.9877Epoch [38/124], Batch [105/125] [################----] 84.0%, Loss: 0.0176Epoch [38/124], Batch [106/125] [################----] 84.8%, Loss: 0.2686Epoch [38/124], Batch [107/125] [#################---] 85.6%, Loss: 0.3402Epoch [38/124], Batch [108/125] [#################---] 86.4%, Loss: 0.4142Epoch [38/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0098Epoch [38/124], Batch [110/125] [#################---] 88.0%, Loss: 0.9945Epoch [38/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1260Epoch [38/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0969Epoch [38/124], Batch [113/125] [##################--] 90.4%, Loss: 0.6374Epoch [38/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1821Epoch [38/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0198Epoch [38/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3574Epoch [38/124], Batch [117/125] [##################--] 93.6%, Loss: 0.3348Epoch [38/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1410Epoch [38/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0419Epoch [38/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1124Epoch [38/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0335Epoch [38/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0327Epoch [38/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0326Epoch [38/124], Batch [124/125] [###################-] 99.2%, Loss: 0.3823Epoch [38/124], Batch [125/125] [####################] 100.0%, Loss: 0.0092
Epoch [38/124] finished. Average Loss: 0.2547
Training Accuracy: 98.00%
--- Saving checkpoint for epoch 38 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [39/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0072Epoch [39/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1832Epoch [39/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.5765Epoch [39/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0301Epoch [39/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0042Epoch [39/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0048Epoch [39/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0358Epoch [39/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.4951Epoch [39/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0399Epoch [39/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0090Epoch [39/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0225Epoch [39/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0230Epoch [39/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.1153Epoch [39/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0305Epoch [39/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0068Epoch [39/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0178Epoch [39/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0076Epoch [39/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0870Epoch [39/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0909Epoch [39/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0693Epoch [39/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.2864Epoch [39/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0181Epoch [39/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0246Epoch [39/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1386Epoch [39/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.7007Epoch [39/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1154Epoch [39/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0301Epoch [39/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0413Epoch [39/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0730Epoch [39/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0041Epoch [39/124], Batch [31/125] [####----------------] 24.8%, Loss: 1.3233Epoch [39/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0216Epoch [39/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0282Epoch [39/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1365Epoch [39/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.2807Epoch [39/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.8571Epoch [39/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0297Epoch [39/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0696Epoch [39/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0405Epoch [39/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1361Epoch [39/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1543Epoch [39/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0016Epoch [39/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0058Epoch [39/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0280Epoch [39/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0382Epoch [39/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0754Epoch [39/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0096Epoch [39/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0521Epoch [39/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0082Epoch [39/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0323Epoch [39/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0388Epoch [39/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0296Epoch [39/124], Batch [53/125] [########------------] 42.4%, Loss: 0.1528Epoch [39/124], Batch [54/125] [########------------] 43.2%, Loss: 0.5143Epoch [39/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0631Epoch [39/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0031Epoch [39/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0658Epoch [39/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.8007Epoch [39/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1463Epoch [39/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0688Epoch [39/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0550Epoch [39/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.5035Epoch [39/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0140Epoch [39/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.6640Epoch [39/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0094Epoch [39/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0821Epoch [39/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0183Epoch [39/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1094Epoch [39/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0242Epoch [39/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1168Epoch [39/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0101Epoch [39/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0105Epoch [39/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.2016Epoch [39/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0294Epoch [39/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0088Epoch [39/124], Batch [76/125] [############--------] 60.8%, Loss: 0.3457Epoch [39/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0508Epoch [39/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0318Epoch [39/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0678Epoch [39/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0111Epoch [39/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1983Epoch [39/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0720Epoch [39/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0297Epoch [39/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0129Epoch [39/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.2322Epoch [39/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.3989Epoch [39/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0474Epoch [39/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0150Epoch [39/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3121Epoch [39/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0490Epoch [39/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0180Epoch [39/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2819Epoch [39/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1024Epoch [39/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0132Epoch [39/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.1494Epoch [39/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0244Epoch [39/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0728Epoch [39/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.1052Epoch [39/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0021Epoch [39/124], Batch [100/125] [################----] 80.0%, Loss: 0.0545Epoch [39/124], Batch [101/125] [################----] 80.8%, Loss: 0.0159Epoch [39/124], Batch [102/125] [################----] 81.6%, Loss: 0.0766Epoch [39/124], Batch [103/125] [################----] 82.4%, Loss: 0.0106Epoch [39/124], Batch [104/125] [################----] 83.2%, Loss: 0.2948Epoch [39/124], Batch [105/125] [################----] 84.0%, Loss: 0.0979Epoch [39/124], Batch [106/125] [################----] 84.8%, Loss: 0.0067Epoch [39/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0041Epoch [39/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0271Epoch [39/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0593Epoch [39/124], Batch [110/125] [#################---] 88.0%, Loss: 0.7269Epoch [39/124], Batch [111/125] [#################---] 88.8%, Loss: 0.7416Epoch [39/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0073Epoch [39/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0077Epoch [39/124], Batch [114/125] [##################--] 91.2%, Loss: 0.3667Epoch [39/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0359Epoch [39/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0355Epoch [39/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0239Epoch [39/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0055Epoch [39/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0766Epoch [39/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0733Epoch [39/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0120Epoch [39/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0158Epoch [39/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0514Epoch [39/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0231Epoch [39/124], Batch [125/125] [####################] 100.0%, Loss: 0.0397
Epoch [39/124] finished. Average Loss: 0.1271
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 39 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [40/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1254Epoch [40/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0558Epoch [40/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0160Epoch [40/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0596Epoch [40/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.4377Epoch [40/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.3328Epoch [40/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0222Epoch [40/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0047Epoch [40/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0900Epoch [40/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0028Epoch [40/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0075Epoch [40/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0003Epoch [40/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0097Epoch [40/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0157Epoch [40/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0053Epoch [40/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0571Epoch [40/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0032Epoch [40/124], Batch [18/125] [##------------------] 14.4%, Loss: 1.0359Epoch [40/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0310Epoch [40/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.2062Epoch [40/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1451Epoch [40/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1240Epoch [40/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.3901Epoch [40/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0041Epoch [40/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3814Epoch [40/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0081Epoch [40/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0430Epoch [40/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0422Epoch [40/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1745Epoch [40/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0097Epoch [40/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0147Epoch [40/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0206Epoch [40/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0074Epoch [40/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0625Epoch [40/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.3225Epoch [40/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.4163Epoch [40/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.6167Epoch [40/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1407Epoch [40/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0996Epoch [40/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0389Epoch [40/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0131Epoch [40/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0109Epoch [40/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0035Epoch [40/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0064Epoch [40/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0290Epoch [40/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1331Epoch [40/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0084Epoch [40/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0266Epoch [40/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.4830Epoch [40/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0031Epoch [40/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0472Epoch [40/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0025Epoch [40/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0108Epoch [40/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1573Epoch [40/124], Batch [55/125] [########------------] 44.0%, Loss: 0.1398Epoch [40/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0025Epoch [40/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0266Epoch [40/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0676Epoch [40/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0084Epoch [40/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0624Epoch [40/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2640Epoch [40/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0007Epoch [40/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.2798Epoch [40/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0105Epoch [40/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0051Epoch [40/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2026Epoch [40/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0010Epoch [40/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0056Epoch [40/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0193Epoch [40/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.7080Epoch [40/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0203Epoch [40/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.3670Epoch [40/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0232Epoch [40/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0077Epoch [40/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0026Epoch [40/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0053Epoch [40/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0193Epoch [40/124], Batch [78/125] [############--------] 62.4%, Loss: 0.4728Epoch [40/124], Batch [79/125] [############--------] 63.2%, Loss: 0.7267Epoch [40/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0609Epoch [40/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0069Epoch [40/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0206Epoch [40/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0071Epoch [40/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0063Epoch [40/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0161Epoch [40/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0387Epoch [40/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0086Epoch [40/124], Batch [88/125] [##############------] 70.4%, Loss: 2.2397Epoch [40/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0226Epoch [40/124], Batch [90/125] [##############------] 72.0%, Loss: 0.6701Epoch [40/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0113Epoch [40/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0630Epoch [40/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0417Epoch [40/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.6921Epoch [40/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0125Epoch [40/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0776Epoch [40/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0206Epoch [40/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0049Epoch [40/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0269Epoch [40/124], Batch [100/125] [################----] 80.0%, Loss: 0.0625Epoch [40/124], Batch [101/125] [################----] 80.8%, Loss: 0.0081Epoch [40/124], Batch [102/125] [################----] 81.6%, Loss: 0.4878Epoch [40/124], Batch [103/125] [################----] 82.4%, Loss: 0.0254Epoch [40/124], Batch [104/125] [################----] 83.2%, Loss: 0.2460Epoch [40/124], Batch [105/125] [################----] 84.0%, Loss: 0.0277Epoch [40/124], Batch [106/125] [################----] 84.8%, Loss: 0.0026Epoch [40/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0186Epoch [40/124], Batch [108/125] [#################---] 86.4%, Loss: 0.6390Epoch [40/124], Batch [109/125] [#################---] 87.2%, Loss: 0.5531Epoch [40/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1074Epoch [40/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0894Epoch [40/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0137Epoch [40/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2786Epoch [40/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0931Epoch [40/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0832Epoch [40/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0129Epoch [40/124], Batch [117/125] [##################--] 93.6%, Loss: 0.2452Epoch [40/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0397Epoch [40/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0614Epoch [40/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0024Epoch [40/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0306Epoch [40/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1297Epoch [40/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0227Epoch [40/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0431Epoch [40/124], Batch [125/125] [####################] 100.0%, Loss: 0.0320
Epoch [40/124] finished. Average Loss: 0.1389
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 40 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [41/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0240Epoch [41/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0107Epoch [41/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.3199Epoch [41/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0046Epoch [41/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0511Epoch [41/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0454Epoch [41/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0092Epoch [41/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0156Epoch [41/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0024Epoch [41/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0224Epoch [41/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0289Epoch [41/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0284Epoch [41/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0658Epoch [41/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.8691Epoch [41/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0518Epoch [41/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0527Epoch [41/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.5079Epoch [41/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1234Epoch [41/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0095Epoch [41/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0211Epoch [41/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0126Epoch [41/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0054Epoch [41/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0180Epoch [41/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.4099Epoch [41/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.6713Epoch [41/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0896Epoch [41/124], Batch [27/125] [####----------------] 21.6%, Loss: 1.1510Epoch [41/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0408Epoch [41/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0020Epoch [41/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0162Epoch [41/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0019Epoch [41/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0618Epoch [41/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.2764Epoch [41/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0123Epoch [41/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.2974Epoch [41/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.8844Epoch [41/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0673Epoch [41/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0011Epoch [41/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0355Epoch [41/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0099Epoch [41/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2161Epoch [41/124], Batch [42/125] [######--------------] 33.6%, Loss: 1.6376Epoch [41/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0026Epoch [41/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0089Epoch [41/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0285Epoch [41/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0985Epoch [41/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0197Epoch [41/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0964Epoch [41/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0295Epoch [41/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0152Epoch [41/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1378Epoch [41/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0217Epoch [41/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0285Epoch [41/124], Batch [54/125] [########------------] 43.2%, Loss: 0.2579Epoch [41/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2362Epoch [41/124], Batch [56/125] [########------------] 44.8%, Loss: 0.3150Epoch [41/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0040Epoch [41/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.3449Epoch [41/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2699Epoch [41/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0088Epoch [41/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0583Epoch [41/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0711Epoch [41/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.3803Epoch [41/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.3084Epoch [41/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1215Epoch [41/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.3646Epoch [41/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1152Epoch [41/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1619Epoch [41/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.9548Epoch [41/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1025Epoch [41/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0205Epoch [41/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1537Epoch [41/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0158Epoch [41/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0510Epoch [41/124], Batch [75/125] [############--------] 60.0%, Loss: 0.2078Epoch [41/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0414Epoch [41/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0081Epoch [41/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0179Epoch [41/124], Batch [79/125] [############--------] 63.2%, Loss: 0.2277Epoch [41/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0083Epoch [41/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0652Epoch [41/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0050Epoch [41/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0070Epoch [41/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0085Epoch [41/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0580Epoch [41/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0014Epoch [41/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0498Epoch [41/124], Batch [88/125] [##############------] 70.4%, Loss: 0.7217Epoch [41/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0639Epoch [41/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1241Epoch [41/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0344Epoch [41/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0325Epoch [41/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0063Epoch [41/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0912Epoch [41/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0178Epoch [41/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0216Epoch [41/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0860Epoch [41/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0087Epoch [41/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0064Epoch [41/124], Batch [100/125] [################----] 80.0%, Loss: 0.0205Epoch [41/124], Batch [101/125] [################----] 80.8%, Loss: 0.0358Epoch [41/124], Batch [102/125] [################----] 81.6%, Loss: 0.0053Epoch [41/124], Batch [103/125] [################----] 82.4%, Loss: 0.0925Epoch [41/124], Batch [104/125] [################----] 83.2%, Loss: 0.0125Epoch [41/124], Batch [105/125] [################----] 84.0%, Loss: 0.0486Epoch [41/124], Batch [106/125] [################----] 84.8%, Loss: 0.0182Epoch [41/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1595Epoch [41/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0040Epoch [41/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0089Epoch [41/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0070Epoch [41/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0088Epoch [41/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0352Epoch [41/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1280Epoch [41/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0157Epoch [41/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0158Epoch [41/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1567Epoch [41/124], Batch [117/125] [##################--] 93.6%, Loss: 1.1128Epoch [41/124], Batch [118/125] [##################--] 94.4%, Loss: 0.6107Epoch [41/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0221Epoch [41/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0302Epoch [41/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0294Epoch [41/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0036Epoch [41/124], Batch [123/125] [###################-] 98.4%, Loss: 0.3934Epoch [41/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0017Epoch [41/124], Batch [125/125] [####################] 100.0%, Loss: 0.0137
Epoch [41/124] finished. Average Loss: 0.1432
Training Accuracy: 99.40%
--- Saving checkpoint for epoch 41 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [42/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0034Epoch [42/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0050Epoch [42/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0002Epoch [42/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.9788Epoch [42/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0026Epoch [42/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0623Epoch [42/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0004Epoch [42/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0018Epoch [42/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0491Epoch [42/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.3884Epoch [42/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0489Epoch [42/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0022Epoch [42/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0123Epoch [42/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0217Epoch [42/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0279Epoch [42/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1316Epoch [42/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0032Epoch [42/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0816Epoch [42/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.1503Epoch [42/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0193Epoch [42/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0018Epoch [42/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1371Epoch [42/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1167Epoch [42/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0306Epoch [42/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0231Epoch [42/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1563Epoch [42/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0345Epoch [42/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0337Epoch [42/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0014Epoch [42/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.5097Epoch [42/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.2708Epoch [42/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.3869Epoch [42/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0252Epoch [42/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0433Epoch [42/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0008Epoch [42/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0075Epoch [42/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0067Epoch [42/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0168Epoch [42/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.9330Epoch [42/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0697Epoch [42/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1950Epoch [42/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0295Epoch [42/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.3853Epoch [42/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.5761Epoch [42/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0014Epoch [42/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0662Epoch [42/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0018Epoch [42/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.3691Epoch [42/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0789Epoch [42/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1211Epoch [42/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0154Epoch [42/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0012Epoch [42/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2150Epoch [42/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0011Epoch [42/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0542Epoch [42/124], Batch [56/125] [########------------] 44.8%, Loss: 0.2534Epoch [42/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0223Epoch [42/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0031Epoch [42/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0680Epoch [42/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0007Epoch [42/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0730Epoch [42/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0119Epoch [42/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0297Epoch [42/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0109Epoch [42/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0526Epoch [42/124], Batch [66/125] [##########----------] 52.8%, Loss: 1.0390Epoch [42/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.5172Epoch [42/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0034Epoch [42/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0518Epoch [42/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1837Epoch [42/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0002Epoch [42/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0602Epoch [42/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0058Epoch [42/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.3977Epoch [42/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0087Epoch [42/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0510Epoch [42/124], Batch [77/125] [############--------] 61.6%, Loss: 0.2044Epoch [42/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0245Epoch [42/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0571Epoch [42/124], Batch [80/125] [############--------] 64.0%, Loss: 0.3635Epoch [42/124], Batch [81/125] [############--------] 64.8%, Loss: 0.2822Epoch [42/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0447Epoch [42/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.5043Epoch [42/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0268Epoch [42/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0121Epoch [42/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0293Epoch [42/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0120Epoch [42/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0154Epoch [42/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0197Epoch [42/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0248Epoch [42/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0043Epoch [42/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0143Epoch [42/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0026Epoch [42/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0056Epoch [42/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2145Epoch [42/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0417Epoch [42/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0105Epoch [42/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.7540Epoch [42/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.3727Epoch [42/124], Batch [100/125] [################----] 80.0%, Loss: 0.0043Epoch [42/124], Batch [101/125] [################----] 80.8%, Loss: 0.0106Epoch [42/124], Batch [102/125] [################----] 81.6%, Loss: 0.0119Epoch [42/124], Batch [103/125] [################----] 82.4%, Loss: 0.1067Epoch [42/124], Batch [104/125] [################----] 83.2%, Loss: 0.1169Epoch [42/124], Batch [105/125] [################----] 84.0%, Loss: 0.1643Epoch [42/124], Batch [106/125] [################----] 84.8%, Loss: 1.0125Epoch [42/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0044Epoch [42/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0856Epoch [42/124], Batch [109/125] [#################---] 87.2%, Loss: 0.5761Epoch [42/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1912Epoch [42/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0089Epoch [42/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0177Epoch [42/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0992Epoch [42/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0663Epoch [42/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0013Epoch [42/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3684Epoch [42/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0086Epoch [42/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0049Epoch [42/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0014Epoch [42/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1783Epoch [42/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0040Epoch [42/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1187Epoch [42/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2636Epoch [42/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0838Epoch [42/124], Batch [125/125] [####################] 100.0%, Loss: 0.1795
Epoch [42/124] finished. Average Loss: 0.1319
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 42 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [43/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0005Epoch [43/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1474Epoch [43/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0219Epoch [43/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0835Epoch [43/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0336Epoch [43/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0138Epoch [43/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0240Epoch [43/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0043Epoch [43/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0059Epoch [43/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0140Epoch [43/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1755Epoch [43/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0980Epoch [43/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0056Epoch [43/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0020Epoch [43/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0148Epoch [43/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0121Epoch [43/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0022Epoch [43/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0109Epoch [43/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0020Epoch [43/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0683Epoch [43/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.5397Epoch [43/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0084Epoch [43/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.6202Epoch [43/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0057Epoch [43/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0110Epoch [43/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0529Epoch [43/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0002Epoch [43/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0457Epoch [43/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0296Epoch [43/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0182Epoch [43/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0055Epoch [43/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0065Epoch [43/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0744Epoch [43/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0016Epoch [43/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0579Epoch [43/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0232Epoch [43/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.5603Epoch [43/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0070Epoch [43/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0030Epoch [43/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.3370Epoch [43/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0401Epoch [43/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0259Epoch [43/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0528Epoch [43/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0013Epoch [43/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0134Epoch [43/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0019Epoch [43/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.6517Epoch [43/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0059Epoch [43/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2910Epoch [43/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0071Epoch [43/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0179Epoch [43/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0042Epoch [43/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0267Epoch [43/124], Batch [54/125] [########------------] 43.2%, Loss: 0.3409Epoch [43/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0075Epoch [43/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1033Epoch [43/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0068Epoch [43/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0065Epoch [43/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0188Epoch [43/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0250Epoch [43/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0376Epoch [43/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0516Epoch [43/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0059Epoch [43/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0022Epoch [43/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.2284Epoch [43/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.4463Epoch [43/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0863Epoch [43/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0042Epoch [43/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0445Epoch [43/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0178Epoch [43/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0327Epoch [43/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0058Epoch [43/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0099Epoch [43/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0009Epoch [43/124], Batch [75/125] [############--------] 60.0%, Loss: 1.3235Epoch [43/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0144Epoch [43/124], Batch [77/125] [############--------] 61.6%, Loss: 0.4233Epoch [43/124], Batch [78/125] [############--------] 62.4%, Loss: 0.2899Epoch [43/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1423Epoch [43/124], Batch [80/125] [############--------] 64.0%, Loss: 0.2311Epoch [43/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0357Epoch [43/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0022Epoch [43/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0282Epoch [43/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0014Epoch [43/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1578Epoch [43/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0328Epoch [43/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0011Epoch [43/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1101Epoch [43/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0008Epoch [43/124], Batch [90/125] [##############------] 72.0%, Loss: 1.0245Epoch [43/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0476Epoch [43/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0010Epoch [43/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0053Epoch [43/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0148Epoch [43/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.1387Epoch [43/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0130Epoch [43/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1314Epoch [43/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0071Epoch [43/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0018Epoch [43/124], Batch [100/125] [################----] 80.0%, Loss: 0.3052Epoch [43/124], Batch [101/125] [################----] 80.8%, Loss: 0.0263Epoch [43/124], Batch [102/125] [################----] 81.6%, Loss: 0.1274Epoch [43/124], Batch [103/125] [################----] 82.4%, Loss: 0.1663Epoch [43/124], Batch [104/125] [################----] 83.2%, Loss: 0.0160Epoch [43/124], Batch [105/125] [################----] 84.0%, Loss: 0.0068Epoch [43/124], Batch [106/125] [################----] 84.8%, Loss: 0.1453Epoch [43/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1874Epoch [43/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2792Epoch [43/124], Batch [109/125] [#################---] 87.2%, Loss: 0.6043Epoch [43/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0392Epoch [43/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0809Epoch [43/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0318Epoch [43/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0008Epoch [43/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4873Epoch [43/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0504Epoch [43/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0651Epoch [43/124], Batch [117/125] [##################--] 93.6%, Loss: 0.4089Epoch [43/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0477Epoch [43/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0193Epoch [43/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0255Epoch [43/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0195Epoch [43/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1389Epoch [43/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1218Epoch [43/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0027Epoch [43/124], Batch [125/125] [####################] 100.0%, Loss: 0.0194
Epoch [43/124] finished. Average Loss: 0.1070
Training Accuracy: 97.80%
--- Saving checkpoint for epoch 43 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [44/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0233Epoch [44/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1893Epoch [44/124], Batch [3/125] [--------------------] 2.4%, Loss: 2.8407Epoch [44/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0191Epoch [44/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0648Epoch [44/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.1311Epoch [44/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0920Epoch [44/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0197Epoch [44/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.3672Epoch [44/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0277Epoch [44/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0361Epoch [44/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0315Epoch [44/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0624Epoch [44/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0441Epoch [44/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.1214Epoch [44/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.3569Epoch [44/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0046Epoch [44/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0156Epoch [44/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0058Epoch [44/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.6947Epoch [44/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0061Epoch [44/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0697Epoch [44/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0765Epoch [44/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0173Epoch [44/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0095Epoch [44/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0093Epoch [44/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0083Epoch [44/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0321Epoch [44/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0983Epoch [44/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0084Epoch [44/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0822Epoch [44/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0125Epoch [44/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0794Epoch [44/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.3896Epoch [44/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.4419Epoch [44/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1064Epoch [44/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0270Epoch [44/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0027Epoch [44/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3018Epoch [44/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.3798Epoch [44/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0055Epoch [44/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0028Epoch [44/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0541Epoch [44/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0068Epoch [44/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0012Epoch [44/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0698Epoch [44/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0820Epoch [44/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0446Epoch [44/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0360Epoch [44/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0752Epoch [44/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0002Epoch [44/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0246Epoch [44/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0404Epoch [44/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0003Epoch [44/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0074Epoch [44/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0083Epoch [44/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0007Epoch [44/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0010Epoch [44/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0040Epoch [44/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0082Epoch [44/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.1171Epoch [44/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0296Epoch [44/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0132Epoch [44/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0108Epoch [44/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0007Epoch [44/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0651Epoch [44/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0029Epoch [44/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0303Epoch [44/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0035Epoch [44/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0276Epoch [44/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0080Epoch [44/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0009Epoch [44/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.1963Epoch [44/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0163Epoch [44/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1573Epoch [44/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0031Epoch [44/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0016Epoch [44/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0003Epoch [44/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0799Epoch [44/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0164Epoch [44/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1195Epoch [44/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0009Epoch [44/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0476Epoch [44/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0032Epoch [44/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0179Epoch [44/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1555Epoch [44/124], Batch [87/125] [#############-------] 69.6%, Loss: 1.2315Epoch [44/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0770Epoch [44/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3667Epoch [44/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0371Epoch [44/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0051Epoch [44/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0033Epoch [44/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0461Epoch [44/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0143Epoch [44/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.4233Epoch [44/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0374Epoch [44/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0062Epoch [44/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.5256Epoch [44/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0768Epoch [44/124], Batch [100/125] [################----] 80.0%, Loss: 0.3404Epoch [44/124], Batch [101/125] [################----] 80.8%, Loss: 0.0075Epoch [44/124], Batch [102/125] [################----] 81.6%, Loss: 0.0538Epoch [44/124], Batch [103/125] [################----] 82.4%, Loss: 0.0308Epoch [44/124], Batch [104/125] [################----] 83.2%, Loss: 0.0091Epoch [44/124], Batch [105/125] [################----] 84.0%, Loss: 0.0087Epoch [44/124], Batch [106/125] [################----] 84.8%, Loss: 0.0017Epoch [44/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0022Epoch [44/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0492Epoch [44/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0113Epoch [44/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0157Epoch [44/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0295Epoch [44/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0019Epoch [44/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0841Epoch [44/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0062Epoch [44/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0051Epoch [44/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0028Epoch [44/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0892Epoch [44/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1163Epoch [44/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0475Epoch [44/124], Batch [120/125] [###################-] 96.0%, Loss: 1.3074Epoch [44/124], Batch [121/125] [###################-] 96.8%, Loss: 1.3479Epoch [44/124], Batch [122/125] [###################-] 97.6%, Loss: 0.8935Epoch [44/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0346Epoch [44/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1076Epoch [44/124], Batch [125/125] [####################] 100.0%, Loss: 0.0033
Epoch [44/124] finished. Average Loss: 0.1309
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 44 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [45/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0642Epoch [45/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0119Epoch [45/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0056Epoch [45/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0383Epoch [45/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0002Epoch [45/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0077Epoch [45/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0046Epoch [45/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0084Epoch [45/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0677Epoch [45/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0006Epoch [45/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0390Epoch [45/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0429Epoch [45/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0059Epoch [45/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [45/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0051Epoch [45/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0104Epoch [45/124], Batch [17/125] [##------------------] 13.6%, Loss: 2.1477Epoch [45/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0133Epoch [45/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0428Epoch [45/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0348Epoch [45/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1593Epoch [45/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2164Epoch [45/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0618Epoch [45/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0197Epoch [45/124], Batch [25/125] [####----------------] 20.0%, Loss: 1.7705Epoch [45/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0210Epoch [45/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0151Epoch [45/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0172Epoch [45/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0011Epoch [45/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0101Epoch [45/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0086Epoch [45/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0483Epoch [45/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0005Epoch [45/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0459Epoch [45/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0259Epoch [45/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0034Epoch [45/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1189Epoch [45/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1276Epoch [45/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0110Epoch [45/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1674Epoch [45/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0017Epoch [45/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0037Epoch [45/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0093Epoch [45/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0098Epoch [45/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0235Epoch [45/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.4759Epoch [45/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.3137Epoch [45/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0072Epoch [45/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0133Epoch [45/124], Batch [50/125] [########------------] 40.0%, Loss: 0.7062Epoch [45/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0431Epoch [45/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0460Epoch [45/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0139Epoch [45/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0354Epoch [45/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0029Epoch [45/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0310Epoch [45/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0369Epoch [45/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0273Epoch [45/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0112Epoch [45/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0023Epoch [45/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.3716Epoch [45/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1594Epoch [45/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.2734Epoch [45/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0442Epoch [45/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0727Epoch [45/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2020Epoch [45/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0332Epoch [45/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0436Epoch [45/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0196Epoch [45/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.4269Epoch [45/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0288Epoch [45/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0032Epoch [45/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0138Epoch [45/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0007Epoch [45/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1144Epoch [45/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2084Epoch [45/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0090Epoch [45/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0127Epoch [45/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0056Epoch [45/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0123Epoch [45/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0626Epoch [45/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0029Epoch [45/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0166Epoch [45/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.5380Epoch [45/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1738Epoch [45/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1786Epoch [45/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0122Epoch [45/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0140Epoch [45/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0123Epoch [45/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0035Epoch [45/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0417Epoch [45/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0048Epoch [45/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0015Epoch [45/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0044Epoch [45/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0088Epoch [45/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0194Epoch [45/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0046Epoch [45/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0116Epoch [45/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2097Epoch [45/124], Batch [100/125] [################----] 80.0%, Loss: 0.0091Epoch [45/124], Batch [101/125] [################----] 80.8%, Loss: 0.3448Epoch [45/124], Batch [102/125] [################----] 81.6%, Loss: 0.0147Epoch [45/124], Batch [103/125] [################----] 82.4%, Loss: 0.0015Epoch [45/124], Batch [104/125] [################----] 83.2%, Loss: 0.0030Epoch [45/124], Batch [105/125] [################----] 84.0%, Loss: 0.0620Epoch [45/124], Batch [106/125] [################----] 84.8%, Loss: 0.0144Epoch [45/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0291Epoch [45/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0262Epoch [45/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0269Epoch [45/124], Batch [110/125] [#################---] 88.0%, Loss: 0.3437Epoch [45/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0406Epoch [45/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0346Epoch [45/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0264Epoch [45/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2144Epoch [45/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0247Epoch [45/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0147Epoch [45/124], Batch [117/125] [##################--] 93.6%, Loss: 0.3003Epoch [45/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1734Epoch [45/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0359Epoch [45/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0055Epoch [45/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0019Epoch [45/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0380Epoch [45/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0068Epoch [45/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0024Epoch [45/124], Batch [125/125] [####################] 100.0%, Loss: 0.0155
Epoch [45/124] finished. Average Loss: 0.0992
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 45 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [46/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0723Epoch [46/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1321Epoch [46/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0083Epoch [46/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0779Epoch [46/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0078Epoch [46/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0025Epoch [46/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0071Epoch [46/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0065Epoch [46/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0023Epoch [46/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0735Epoch [46/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1129Epoch [46/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0754Epoch [46/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0086Epoch [46/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0012Epoch [46/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0424Epoch [46/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0013Epoch [46/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0061Epoch [46/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0080Epoch [46/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0211Epoch [46/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0031Epoch [46/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0024Epoch [46/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0240Epoch [46/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1185Epoch [46/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0012Epoch [46/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0039Epoch [46/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0780Epoch [46/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0242Epoch [46/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0030Epoch [46/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0043Epoch [46/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0016Epoch [46/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0022Epoch [46/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0017Epoch [46/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0102Epoch [46/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0479Epoch [46/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0213Epoch [46/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.2594Epoch [46/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0011Epoch [46/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0476Epoch [46/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0045Epoch [46/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0253Epoch [46/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0137Epoch [46/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0082Epoch [46/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0034Epoch [46/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.1473Epoch [46/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0015Epoch [46/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0023Epoch [46/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0769Epoch [46/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0260Epoch [46/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0189Epoch [46/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0007Epoch [46/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0012Epoch [46/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0005Epoch [46/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2926Epoch [46/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0051Epoch [46/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0157Epoch [46/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0019Epoch [46/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0021Epoch [46/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0007Epoch [46/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0097Epoch [46/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0004Epoch [46/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0174Epoch [46/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0243Epoch [46/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0010Epoch [46/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0042Epoch [46/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0181Epoch [46/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0058Epoch [46/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0041Epoch [46/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1714Epoch [46/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0108Epoch [46/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0001Epoch [46/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0086Epoch [46/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0083Epoch [46/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0015Epoch [46/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0124Epoch [46/124], Batch [75/125] [############--------] 60.0%, Loss: 1.0103Epoch [46/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0053Epoch [46/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0009Epoch [46/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0023Epoch [46/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0019Epoch [46/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0787Epoch [46/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0004Epoch [46/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0011Epoch [46/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0009Epoch [46/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0012Epoch [46/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0458Epoch [46/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0018Epoch [46/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0044Epoch [46/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0002Epoch [46/124], Batch [89/125] [##############------] 71.2%, Loss: 0.9589Epoch [46/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0619Epoch [46/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0053Epoch [46/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0903Epoch [46/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0013Epoch [46/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1555Epoch [46/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0542Epoch [46/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0110Epoch [46/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1068Epoch [46/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0155Epoch [46/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0378Epoch [46/124], Batch [100/125] [################----] 80.0%, Loss: 0.0168Epoch [46/124], Batch [101/125] [################----] 80.8%, Loss: 0.0011Epoch [46/124], Batch [102/125] [################----] 81.6%, Loss: 0.0244Epoch [46/124], Batch [103/125] [################----] 82.4%, Loss: 0.0031Epoch [46/124], Batch [104/125] [################----] 83.2%, Loss: 0.0067Epoch [46/124], Batch [105/125] [################----] 84.0%, Loss: 0.1579Epoch [46/124], Batch [106/125] [################----] 84.8%, Loss: 0.4918Epoch [46/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0092Epoch [46/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0083Epoch [46/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1115Epoch [46/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0117Epoch [46/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0062Epoch [46/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0141Epoch [46/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0141Epoch [46/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1059Epoch [46/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0063Epoch [46/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0007Epoch [46/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0038Epoch [46/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0007Epoch [46/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0040Epoch [46/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0060Epoch [46/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0436Epoch [46/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0373Epoch [46/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0011Epoch [46/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0087Epoch [46/124], Batch [125/125] [####################] 100.0%, Loss: 0.0381
Epoch [46/124] finished. Average Loss: 0.0485
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 46 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [47/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0488Epoch [47/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0047Epoch [47/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0441Epoch [47/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0195Epoch [47/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0093Epoch [47/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0013Epoch [47/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1969Epoch [47/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.3393Epoch [47/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0006Epoch [47/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0077Epoch [47/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0104Epoch [47/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0024Epoch [47/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0077Epoch [47/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [47/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0017Epoch [47/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0196Epoch [47/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0022Epoch [47/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0004Epoch [47/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0029Epoch [47/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0565Epoch [47/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0392Epoch [47/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0042Epoch [47/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0078Epoch [47/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0014Epoch [47/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0030Epoch [47/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0021Epoch [47/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0475Epoch [47/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0038Epoch [47/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0073Epoch [47/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0092Epoch [47/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0168Epoch [47/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0035Epoch [47/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1394Epoch [47/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0080Epoch [47/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.2184Epoch [47/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0086Epoch [47/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0051Epoch [47/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0472Epoch [47/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0001Epoch [47/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0029Epoch [47/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0002Epoch [47/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0007Epoch [47/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0144Epoch [47/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0021Epoch [47/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0069Epoch [47/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0014Epoch [47/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.3808Epoch [47/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0210Epoch [47/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0029Epoch [47/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0008Epoch [47/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0063Epoch [47/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0002Epoch [47/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0008Epoch [47/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0006Epoch [47/124], Batch [55/125] [########------------] 44.0%, Loss: 1.9037Epoch [47/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0226Epoch [47/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0425Epoch [47/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0000Epoch [47/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0103Epoch [47/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0583Epoch [47/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0439Epoch [47/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0334Epoch [47/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0313Epoch [47/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0110Epoch [47/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0006Epoch [47/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0648Epoch [47/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0039Epoch [47/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0005Epoch [47/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0215Epoch [47/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0002Epoch [47/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0333Epoch [47/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0342Epoch [47/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.3119Epoch [47/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0091Epoch [47/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0013Epoch [47/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0033Epoch [47/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0017Epoch [47/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0014Epoch [47/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0363Epoch [47/124], Batch [80/125] [############--------] 64.0%, Loss: 0.4608Epoch [47/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0010Epoch [47/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0127Epoch [47/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0151Epoch [47/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0041Epoch [47/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0107Epoch [47/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0023Epoch [47/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0088Epoch [47/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0266Epoch [47/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0020Epoch [47/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1881Epoch [47/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0030Epoch [47/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0365Epoch [47/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0003Epoch [47/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0007Epoch [47/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0033Epoch [47/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0007Epoch [47/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0023Epoch [47/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0082Epoch [47/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0006Epoch [47/124], Batch [100/125] [################----] 80.0%, Loss: 0.0330Epoch [47/124], Batch [101/125] [################----] 80.8%, Loss: 0.0007Epoch [47/124], Batch [102/125] [################----] 81.6%, Loss: 0.0014Epoch [47/124], Batch [103/125] [################----] 82.4%, Loss: 0.0554Epoch [47/124], Batch [104/125] [################----] 83.2%, Loss: 0.0049Epoch [47/124], Batch [105/125] [################----] 84.0%, Loss: 0.0003Epoch [47/124], Batch [106/125] [################----] 84.8%, Loss: 0.0114Epoch [47/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0403Epoch [47/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0050Epoch [47/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0836Epoch [47/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0017Epoch [47/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0006Epoch [47/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0368Epoch [47/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0002Epoch [47/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0007Epoch [47/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0304Epoch [47/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0608Epoch [47/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0894Epoch [47/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0036Epoch [47/124], Batch [119/125] [###################-] 95.2%, Loss: 0.1387Epoch [47/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0009Epoch [47/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0008Epoch [47/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0571Epoch [47/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0792Epoch [47/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0007Epoch [47/124], Batch [125/125] [####################] 100.0%, Loss: 0.0057
Epoch [47/124] finished. Average Loss: 0.0480
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 47 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [48/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0033Epoch [48/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0026Epoch [48/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0215Epoch [48/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0004Epoch [48/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0009Epoch [48/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0011Epoch [48/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0041Epoch [48/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0012Epoch [48/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0009Epoch [48/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0087Epoch [48/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0007Epoch [48/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0002Epoch [48/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0046Epoch [48/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [48/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0197Epoch [48/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0004Epoch [48/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0034Epoch [48/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0644Epoch [48/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0002Epoch [48/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0212Epoch [48/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0158Epoch [48/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0135Epoch [48/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0018Epoch [48/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0370Epoch [48/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0005Epoch [48/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0485Epoch [48/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0059Epoch [48/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0324Epoch [48/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0009Epoch [48/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0685Epoch [48/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.5326Epoch [48/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0261Epoch [48/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0003Epoch [48/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0242Epoch [48/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0002Epoch [48/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0007Epoch [48/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0078Epoch [48/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0156Epoch [48/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0003Epoch [48/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0131Epoch [48/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0016Epoch [48/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1652Epoch [48/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0331Epoch [48/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.2498Epoch [48/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0056Epoch [48/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0035Epoch [48/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0010Epoch [48/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0065Epoch [48/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0030Epoch [48/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0126Epoch [48/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0028Epoch [48/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0038Epoch [48/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0003Epoch [48/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0025Epoch [48/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0084Epoch [48/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1315Epoch [48/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0058Epoch [48/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0006Epoch [48/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0050Epoch [48/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0126Epoch [48/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0006Epoch [48/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0001Epoch [48/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0079Epoch [48/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0213Epoch [48/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0007Epoch [48/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0134Epoch [48/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0033Epoch [48/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0398Epoch [48/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0009Epoch [48/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0333Epoch [48/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0026Epoch [48/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0038Epoch [48/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0010Epoch [48/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0834Epoch [48/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0006Epoch [48/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0082Epoch [48/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0104Epoch [48/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0017Epoch [48/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0111Epoch [48/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0038Epoch [48/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0081Epoch [48/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0020Epoch [48/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0002Epoch [48/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0041Epoch [48/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0070Epoch [48/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0052Epoch [48/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0137Epoch [48/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0018Epoch [48/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0224Epoch [48/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0024Epoch [48/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0027Epoch [48/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0708Epoch [48/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0008Epoch [48/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0442Epoch [48/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.9130Epoch [48/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0138Epoch [48/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0256Epoch [48/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0180Epoch [48/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0020Epoch [48/124], Batch [100/125] [################----] 80.0%, Loss: 0.1556Epoch [48/124], Batch [101/125] [################----] 80.8%, Loss: 0.0062Epoch [48/124], Batch [102/125] [################----] 81.6%, Loss: 0.0016Epoch [48/124], Batch [103/125] [################----] 82.4%, Loss: 0.0012Epoch [48/124], Batch [104/125] [################----] 83.2%, Loss: 0.0002Epoch [48/124], Batch [105/125] [################----] 84.0%, Loss: 0.0001Epoch [48/124], Batch [106/125] [################----] 84.8%, Loss: 0.0057Epoch [48/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0731Epoch [48/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0036Epoch [48/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0038Epoch [48/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0088Epoch [48/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0612Epoch [48/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0004Epoch [48/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0002Epoch [48/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0466Epoch [48/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0037Epoch [48/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0010Epoch [48/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0120Epoch [48/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0133Epoch [48/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0002Epoch [48/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0042Epoch [48/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0357Epoch [48/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0317Epoch [48/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0012Epoch [48/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0041Epoch [48/124], Batch [125/125] [####################] 100.0%, Loss: 0.0009
Epoch [48/124] finished. Average Loss: 0.0283
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 48 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [49/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0108Epoch [49/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0181Epoch [49/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0048Epoch [49/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0077Epoch [49/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0023Epoch [49/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0005Epoch [49/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0045Epoch [49/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0041Epoch [49/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0001Epoch [49/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.4238Epoch [49/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0032Epoch [49/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0005Epoch [49/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0349Epoch [49/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0063Epoch [49/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0026Epoch [49/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0005Epoch [49/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0083Epoch [49/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0029Epoch [49/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0027Epoch [49/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0020Epoch [49/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1100Epoch [49/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0022Epoch [49/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0044Epoch [49/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0024Epoch [49/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0910Epoch [49/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0007Epoch [49/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0004Epoch [49/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0007Epoch [49/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0037Epoch [49/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0819Epoch [49/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0118Epoch [49/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0088Epoch [49/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0011Epoch [49/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0013Epoch [49/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0020Epoch [49/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.4686Epoch [49/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0564Epoch [49/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0419Epoch [49/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0327Epoch [49/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0887Epoch [49/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0004Epoch [49/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0003Epoch [49/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0469Epoch [49/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0007Epoch [49/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0713Epoch [49/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0006Epoch [49/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0262Epoch [49/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0005Epoch [49/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0076Epoch [49/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0013Epoch [49/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0020Epoch [49/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0007Epoch [49/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0029Epoch [49/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0842Epoch [49/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0009Epoch [49/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0048Epoch [49/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0034Epoch [49/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0004Epoch [49/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0005Epoch [49/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0025Epoch [49/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.6648Epoch [49/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0006Epoch [49/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0039Epoch [49/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0086Epoch [49/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0051Epoch [49/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0059Epoch [49/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0004Epoch [49/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0000Epoch [49/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0269Epoch [49/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0177Epoch [49/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0002Epoch [49/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0002Epoch [49/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0001Epoch [49/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.3195Epoch [49/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0114Epoch [49/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0008Epoch [49/124], Batch [77/125] [############--------] 61.6%, Loss: 0.2344Epoch [49/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0002Epoch [49/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0023Epoch [49/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0087Epoch [49/124], Batch [81/125] [############--------] 64.8%, Loss: 0.3935Epoch [49/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0448Epoch [49/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0043Epoch [49/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0130Epoch [49/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.6485Epoch [49/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0020Epoch [49/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0141Epoch [49/124], Batch [88/125] [##############------] 70.4%, Loss: 0.4795Epoch [49/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0032Epoch [49/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0022Epoch [49/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0503Epoch [49/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0005Epoch [49/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0095Epoch [49/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1348Epoch [49/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0061Epoch [49/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0018Epoch [49/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0381Epoch [49/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0018Epoch [49/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0029Epoch [49/124], Batch [100/125] [################----] 80.0%, Loss: 0.0049Epoch [49/124], Batch [101/125] [################----] 80.8%, Loss: 0.0033Epoch [49/124], Batch [102/125] [################----] 81.6%, Loss: 0.0116Epoch [49/124], Batch [103/125] [################----] 82.4%, Loss: 0.0117Epoch [49/124], Batch [104/125] [################----] 83.2%, Loss: 0.0018Epoch [49/124], Batch [105/125] [################----] 84.0%, Loss: 0.0004Epoch [49/124], Batch [106/125] [################----] 84.8%, Loss: 0.0072Epoch [49/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0016Epoch [49/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0053Epoch [49/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0007Epoch [49/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0003Epoch [49/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0092Epoch [49/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0211Epoch [49/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0092Epoch [49/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0888Epoch [49/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0013Epoch [49/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0005Epoch [49/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0311Epoch [49/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0033Epoch [49/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0491Epoch [49/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0072Epoch [49/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0103Epoch [49/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0004Epoch [49/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2294Epoch [49/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0543Epoch [49/124], Batch [125/125] [####################] 100.0%, Loss: 0.0238
Epoch [49/124] finished. Average Loss: 0.0445
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 49 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [50/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0009Epoch [50/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0922Epoch [50/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.4180Epoch [50/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0076Epoch [50/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0027Epoch [50/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0113Epoch [50/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0240Epoch [50/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0048Epoch [50/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0031Epoch [50/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0032Epoch [50/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1296Epoch [50/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0236Epoch [50/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3709Epoch [50/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0039Epoch [50/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0122Epoch [50/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1940Epoch [50/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0065Epoch [50/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0062Epoch [50/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0111Epoch [50/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0006Epoch [50/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0008Epoch [50/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0825Epoch [50/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0009Epoch [50/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0014Epoch [50/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0068Epoch [50/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0353Epoch [50/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0063Epoch [50/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0475Epoch [50/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0065Epoch [50/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0014Epoch [50/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0277Epoch [50/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0039Epoch [50/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0640Epoch [50/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0075Epoch [50/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0847Epoch [50/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0015Epoch [50/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0141Epoch [50/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0040Epoch [50/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1632Epoch [50/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0077Epoch [50/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0929Epoch [50/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0890Epoch [50/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0196Epoch [50/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0014Epoch [50/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.4478Epoch [50/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0080Epoch [50/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0007Epoch [50/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0016Epoch [50/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0047Epoch [50/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0099Epoch [50/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0079Epoch [50/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0162Epoch [50/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0003Epoch [50/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1060Epoch [50/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0282Epoch [50/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0020Epoch [50/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0035Epoch [50/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0054Epoch [50/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0028Epoch [50/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0480Epoch [50/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0020Epoch [50/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0159Epoch [50/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0686Epoch [50/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0023Epoch [50/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0121Epoch [50/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0051Epoch [50/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0058Epoch [50/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0592Epoch [50/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0030Epoch [50/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0021Epoch [50/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0015Epoch [50/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0042Epoch [50/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0013Epoch [50/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0046Epoch [50/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0005Epoch [50/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0041Epoch [50/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0584Epoch [50/124], Batch [78/125] [############--------] 62.4%, Loss: 1.6571Epoch [50/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0007Epoch [50/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0206Epoch [50/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0041Epoch [50/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0056Epoch [50/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0050Epoch [50/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0052Epoch [50/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0007Epoch [50/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0424Epoch [50/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0041Epoch [50/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0920Epoch [50/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0047Epoch [50/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0025Epoch [50/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0053Epoch [50/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0111Epoch [50/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0167Epoch [50/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1381Epoch [50/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0456Epoch [50/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0013Epoch [50/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0141Epoch [50/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0013Epoch [50/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0010Epoch [50/124], Batch [100/125] [################----] 80.0%, Loss: 0.1566Epoch [50/124], Batch [101/125] [################----] 80.8%, Loss: 0.0014Epoch [50/124], Batch [102/125] [################----] 81.6%, Loss: 0.0611Epoch [50/124], Batch [103/125] [################----] 82.4%, Loss: 0.0032Epoch [50/124], Batch [104/125] [################----] 83.2%, Loss: 0.0066Epoch [50/124], Batch [105/125] [################----] 84.0%, Loss: 0.0085Epoch [50/124], Batch [106/125] [################----] 84.8%, Loss: 0.0018Epoch [50/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0080Epoch [50/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0016Epoch [50/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0005Epoch [50/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0679Epoch [50/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0003Epoch [50/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0005Epoch [50/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0040Epoch [50/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0027Epoch [50/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0007Epoch [50/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0324Epoch [50/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0006Epoch [50/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0001Epoch [50/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0003Epoch [50/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0106Epoch [50/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0003Epoch [50/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0095Epoch [50/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0013Epoch [50/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0017Epoch [50/124], Batch [125/125] [####################] 100.0%, Loss: 0.0143
Epoch [50/124] finished. Average Loss: 0.0441
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 50 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [51/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0097Epoch [51/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0043Epoch [51/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0259Epoch [51/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0011Epoch [51/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0012Epoch [51/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.2948Epoch [51/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0002Epoch [51/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0147Epoch [51/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0018Epoch [51/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0052Epoch [51/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0011Epoch [51/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0016Epoch [51/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3089Epoch [51/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0071Epoch [51/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0096Epoch [51/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.4148Epoch [51/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0720Epoch [51/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0001Epoch [51/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0038Epoch [51/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0098Epoch [51/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0023Epoch [51/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0008Epoch [51/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0013Epoch [51/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0002Epoch [51/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0829Epoch [51/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0110Epoch [51/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0066Epoch [51/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0036Epoch [51/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.3258Epoch [51/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0262Epoch [51/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0710Epoch [51/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.6427Epoch [51/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1598Epoch [51/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0785Epoch [51/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0007Epoch [51/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0013Epoch [51/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0018Epoch [51/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0090Epoch [51/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0003Epoch [51/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0164Epoch [51/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0019Epoch [51/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0152Epoch [51/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.5304Epoch [51/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0188Epoch [51/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1123Epoch [51/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0041Epoch [51/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0316Epoch [51/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0000Epoch [51/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0035Epoch [51/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0290Epoch [51/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0332Epoch [51/124], Batch [52/125] [########------------] 41.6%, Loss: 0.4068Epoch [51/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2930Epoch [51/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0043Epoch [51/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0032Epoch [51/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0033Epoch [51/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0004Epoch [51/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0054Epoch [51/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0133Epoch [51/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0464Epoch [51/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0019Epoch [51/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0090Epoch [51/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.2568Epoch [51/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.1345Epoch [51/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0477Epoch [51/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0103Epoch [51/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0072Epoch [51/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0084Epoch [51/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.2819Epoch [51/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1199Epoch [51/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0011Epoch [51/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0200Epoch [51/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.5350Epoch [51/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0490Epoch [51/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1964Epoch [51/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0204Epoch [51/124], Batch [77/125] [############--------] 61.6%, Loss: 0.8355Epoch [51/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0091Epoch [51/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0088Epoch [51/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0185Epoch [51/124], Batch [81/125] [############--------] 64.8%, Loss: 0.5537Epoch [51/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0135Epoch [51/124], Batch [83/125] [#############-------] 66.4%, Loss: 1.3183Epoch [51/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0138Epoch [51/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.7228Epoch [51/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0251Epoch [51/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0562Epoch [51/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1154Epoch [51/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0155Epoch [51/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1253Epoch [51/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0533Epoch [51/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2026Epoch [51/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0392Epoch [51/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1618Epoch [51/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0008Epoch [51/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0085Epoch [51/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0172Epoch [51/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0079Epoch [51/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2020Epoch [51/124], Batch [100/125] [################----] 80.0%, Loss: 0.0043Epoch [51/124], Batch [101/125] [################----] 80.8%, Loss: 0.0376Epoch [51/124], Batch [102/125] [################----] 81.6%, Loss: 0.0964Epoch [51/124], Batch [103/125] [################----] 82.4%, Loss: 0.0395Epoch [51/124], Batch [104/125] [################----] 83.2%, Loss: 0.5005Epoch [51/124], Batch [105/125] [################----] 84.0%, Loss: 0.2572Epoch [51/124], Batch [106/125] [################----] 84.8%, Loss: 0.5638Epoch [51/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0203Epoch [51/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1435Epoch [51/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1231Epoch [51/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0016Epoch [51/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0074Epoch [51/124], Batch [112/125] [#################---] 89.6%, Loss: 0.4274Epoch [51/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1102Epoch [51/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0077Epoch [51/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0411Epoch [51/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0527Epoch [51/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1384Epoch [51/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1081Epoch [51/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0914Epoch [51/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0651Epoch [51/124], Batch [121/125] [###################-] 96.8%, Loss: 0.6579Epoch [51/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1211Epoch [51/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0201Epoch [51/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0090Epoch [51/124], Batch [125/125] [####################] 100.0%, Loss: 0.0072
Epoch [51/124] finished. Average Loss: 0.1125
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 51 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [52/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0160Epoch [52/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1105Epoch [52/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0046Epoch [52/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0105Epoch [52/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0023Epoch [52/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0112Epoch [52/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1993Epoch [52/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0780Epoch [52/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0451Epoch [52/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.2372Epoch [52/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0259Epoch [52/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0159Epoch [52/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0601Epoch [52/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.2576Epoch [52/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.7943Epoch [52/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1345Epoch [52/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0140Epoch [52/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0026Epoch [52/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0356Epoch [52/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0012Epoch [52/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.3718Epoch [52/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0135Epoch [52/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.4724Epoch [52/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0084Epoch [52/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0046Epoch [52/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0628Epoch [52/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.9129Epoch [52/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0144Epoch [52/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0136Epoch [52/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0066Epoch [52/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1095Epoch [52/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0015Epoch [52/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0025Epoch [52/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1463Epoch [52/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0145Epoch [52/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1550Epoch [52/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0286Epoch [52/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0626Epoch [52/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0657Epoch [52/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0004Epoch [52/124], Batch [41/125] [######--------------] 32.8%, Loss: 2.1968Epoch [52/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0228Epoch [52/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0708Epoch [52/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0411Epoch [52/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0124Epoch [52/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0283Epoch [52/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0052Epoch [52/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1102Epoch [52/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.7425Epoch [52/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0166Epoch [52/124], Batch [51/125] [########------------] 40.8%, Loss: 1.2610Epoch [52/124], Batch [52/125] [########------------] 41.6%, Loss: 0.5408Epoch [52/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0031Epoch [52/124], Batch [54/125] [########------------] 43.2%, Loss: 1.1929Epoch [52/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2207Epoch [52/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0042Epoch [52/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0499Epoch [52/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0229Epoch [52/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1096Epoch [52/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0817Epoch [52/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.3627Epoch [52/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0010Epoch [52/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0647Epoch [52/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0413Epoch [52/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0008Epoch [52/124], Batch [66/125] [##########----------] 52.8%, Loss: 1.7364Epoch [52/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.7679Epoch [52/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0820Epoch [52/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.7113Epoch [52/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0362Epoch [52/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.2527Epoch [52/124], Batch [72/125] [###########---------] 57.6%, Loss: 1.2431Epoch [52/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0760Epoch [52/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0026Epoch [52/124], Batch [75/125] [############--------] 60.0%, Loss: 0.4681Epoch [52/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0324Epoch [52/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0375Epoch [52/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0756Epoch [52/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0926Epoch [52/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1628Epoch [52/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0450Epoch [52/124], Batch [82/125] [#############-------] 65.6%, Loss: 2.0642Epoch [52/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0348Epoch [52/124], Batch [84/125] [#############-------] 67.2%, Loss: 1.1234Epoch [52/124], Batch [85/125] [#############-------] 68.0%, Loss: 1.0721Epoch [52/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.2224Epoch [52/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1135Epoch [52/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0267Epoch [52/124], Batch [89/125] [##############------] 71.2%, Loss: 1.7435Epoch [52/124], Batch [90/125] [##############------] 72.0%, Loss: 1.3807Epoch [52/124], Batch [91/125] [##############------] 72.8%, Loss: 0.6435Epoch [52/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0062Epoch [52/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0516Epoch [52/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1611Epoch [52/124], Batch [95/125] [###############-----] 76.0%, Loss: 1.7959Epoch [52/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0657Epoch [52/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0258Epoch [52/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.9327Epoch [52/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2717Epoch [52/124], Batch [100/125] [################----] 80.0%, Loss: 0.0448Epoch [52/124], Batch [101/125] [################----] 80.8%, Loss: 0.1246Epoch [52/124], Batch [102/125] [################----] 81.6%, Loss: 0.5442Epoch [52/124], Batch [103/125] [################----] 82.4%, Loss: 0.0528Epoch [52/124], Batch [104/125] [################----] 83.2%, Loss: 0.3503Epoch [52/124], Batch [105/125] [################----] 84.0%, Loss: 0.1208Epoch [52/124], Batch [106/125] [################----] 84.8%, Loss: 0.2636Epoch [52/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1284Epoch [52/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2973Epoch [52/124], Batch [109/125] [#################---] 87.2%, Loss: 0.5953Epoch [52/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1261Epoch [52/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1299Epoch [52/124], Batch [112/125] [#################---] 89.6%, Loss: 0.5244Epoch [52/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1196Epoch [52/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2981Epoch [52/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2571Epoch [52/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1043Epoch [52/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0708Epoch [52/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0377Epoch [52/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0914Epoch [52/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0380Epoch [52/124], Batch [121/125] [###################-] 96.8%, Loss: 1.1903Epoch [52/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2448Epoch [52/124], Batch [123/125] [###################-] 98.4%, Loss: 0.4452Epoch [52/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0816Epoch [52/124], Batch [125/125] [####################] 100.0%, Loss: 0.9580
Epoch [52/124] finished. Average Loss: 0.2922
Training Accuracy: 95.00%
--- Saving checkpoint for epoch 52 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [53/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1015Epoch [53/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0988Epoch [53/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0077Epoch [53/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.9603Epoch [53/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1249Epoch [53/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0736Epoch [53/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1378Epoch [53/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1170Epoch [53/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0186Epoch [53/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0502Epoch [53/124], Batch [11/125] [#-------------------] 8.8%, Loss: 2.0159Epoch [53/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0230Epoch [53/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0965Epoch [53/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0065Epoch [53/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.3971Epoch [53/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2475Epoch [53/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0764Epoch [53/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.4500Epoch [53/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0507Epoch [53/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.4910Epoch [53/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0559Epoch [53/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.3200Epoch [53/124], Batch [23/125] [###-----------------] 18.4%, Loss: 2.3562Epoch [53/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1043Epoch [53/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0008Epoch [53/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0019Epoch [53/124], Batch [27/125] [####----------------] 21.6%, Loss: 1.3467Epoch [53/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0100Epoch [53/124], Batch [29/125] [####----------------] 23.2%, Loss: 1.8474Epoch [53/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.2431Epoch [53/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.4020Epoch [53/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0991Epoch [53/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0082Epoch [53/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.2007Epoch [53/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.4908Epoch [53/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0434Epoch [53/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.4986Epoch [53/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0877Epoch [53/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.2220Epoch [53/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1020Epoch [53/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.5064Epoch [53/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0963Epoch [53/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.3445Epoch [53/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.9968Epoch [53/124], Batch [45/125] [#######-------------] 36.0%, Loss: 1.1039Epoch [53/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1348Epoch [53/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.3812Epoch [53/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2673Epoch [53/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.1835Epoch [53/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0721Epoch [53/124], Batch [51/125] [########------------] 40.8%, Loss: 0.2597Epoch [53/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0441Epoch [53/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0163Epoch [53/124], Batch [54/125] [########------------] 43.2%, Loss: 0.4533Epoch [53/124], Batch [55/125] [########------------] 44.0%, Loss: 0.1873Epoch [53/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0235Epoch [53/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0676Epoch [53/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.7351Epoch [53/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0888Epoch [53/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0165Epoch [53/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.3452Epoch [53/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1099Epoch [53/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.2074Epoch [53/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.6039Epoch [53/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1105Epoch [53/124], Batch [66/125] [##########----------] 52.8%, Loss: 2.7734Epoch [53/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.2626Epoch [53/124], Batch [68/125] [##########----------] 54.4%, Loss: 1.6894Epoch [53/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0147Epoch [53/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.4193Epoch [53/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.1603Epoch [53/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0021Epoch [53/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.7053Epoch [53/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1229Epoch [53/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0629Epoch [53/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2139Epoch [53/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0065Epoch [53/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0567Epoch [53/124], Batch [79/125] [############--------] 63.2%, Loss: 0.7241Epoch [53/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1091Epoch [53/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0477Epoch [53/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1697Epoch [53/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0088Epoch [53/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.1410Epoch [53/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0289Epoch [53/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0532Epoch [53/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0663Epoch [53/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1690Epoch [53/124], Batch [89/125] [##############------] 71.2%, Loss: 1.5368Epoch [53/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0579Epoch [53/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0068Epoch [53/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0016Epoch [53/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2318Epoch [53/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.3005Epoch [53/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0642Epoch [53/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.3711Epoch [53/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.9625Epoch [53/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.3586Epoch [53/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0245Epoch [53/124], Batch [100/125] [################----] 80.0%, Loss: 0.0879Epoch [53/124], Batch [101/125] [################----] 80.8%, Loss: 0.0336Epoch [53/124], Batch [102/125] [################----] 81.6%, Loss: 0.1263Epoch [53/124], Batch [103/125] [################----] 82.4%, Loss: 0.0053Epoch [53/124], Batch [104/125] [################----] 83.2%, Loss: 0.5922Epoch [53/124], Batch [105/125] [################----] 84.0%, Loss: 0.0031Epoch [53/124], Batch [106/125] [################----] 84.8%, Loss: 0.0022Epoch [53/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0558Epoch [53/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0143Epoch [53/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0627Epoch [53/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0145Epoch [53/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0667Epoch [53/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0143Epoch [53/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0911Epoch [53/124], Batch [114/125] [##################--] 91.2%, Loss: 0.6869Epoch [53/124], Batch [115/125] [##################--] 92.0%, Loss: 0.3204Epoch [53/124], Batch [116/125] [##################--] 92.8%, Loss: 0.2159Epoch [53/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1695Epoch [53/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0855Epoch [53/124], Batch [119/125] [###################-] 95.2%, Loss: 0.2186Epoch [53/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0077Epoch [53/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0136Epoch [53/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0355Epoch [53/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1799Epoch [53/124], Batch [124/125] [###################-] 99.2%, Loss: 3.8787Epoch [53/124], Batch [125/125] [####################] 100.0%, Loss: 0.1402
Epoch [53/124] finished. Average Loss: 0.3391
Training Accuracy: 96.80%
--- Saving checkpoint for epoch 53 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [54/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.5884Epoch [54/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0026Epoch [54/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.1006Epoch [54/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0069Epoch [54/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1862Epoch [54/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0057Epoch [54/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0598Epoch [54/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0079Epoch [54/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0092Epoch [54/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.1506Epoch [54/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0051Epoch [54/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0098Epoch [54/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0625Epoch [54/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0078Epoch [54/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0007Epoch [54/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0072Epoch [54/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3472Epoch [54/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.6341Epoch [54/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0243Epoch [54/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0551Epoch [54/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0333Epoch [54/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.3584Epoch [54/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0877Epoch [54/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0247Epoch [54/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.4764Epoch [54/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0028Epoch [54/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0799Epoch [54/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0926Epoch [54/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0019Epoch [54/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0456Epoch [54/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1276Epoch [54/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0491Epoch [54/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.3298Epoch [54/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.2955Epoch [54/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0472Epoch [54/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0003Epoch [54/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.5164Epoch [54/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1512Epoch [54/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1205Epoch [54/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0060Epoch [54/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1216Epoch [54/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0657Epoch [54/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2141Epoch [54/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0221Epoch [54/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0255Epoch [54/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.2235Epoch [54/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1202Epoch [54/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.2727Epoch [54/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2563Epoch [54/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0286Epoch [54/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1156Epoch [54/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0001Epoch [54/124], Batch [53/125] [########------------] 42.4%, Loss: 0.5242Epoch [54/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0140Epoch [54/124], Batch [55/125] [########------------] 44.0%, Loss: 0.3856Epoch [54/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0009Epoch [54/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0513Epoch [54/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0555Epoch [54/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.6165Epoch [54/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.5559Epoch [54/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0199Epoch [54/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0305Epoch [54/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0188Epoch [54/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0116Epoch [54/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0009Epoch [54/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.4105Epoch [54/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0458Epoch [54/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0233Epoch [54/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0309Epoch [54/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1519Epoch [54/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0019Epoch [54/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.2447Epoch [54/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.8307Epoch [54/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0164Epoch [54/124], Batch [75/125] [############--------] 60.0%, Loss: 0.2660Epoch [54/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0790Epoch [54/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0062Epoch [54/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0422Epoch [54/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0035Epoch [54/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0248Epoch [54/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1415Epoch [54/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0389Epoch [54/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0012Epoch [54/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.3743Epoch [54/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.3894Epoch [54/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0048Epoch [54/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.6252Epoch [54/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0006Epoch [54/124], Batch [89/125] [##############------] 71.2%, Loss: 0.1055Epoch [54/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0441Epoch [54/124], Batch [91/125] [##############------] 72.8%, Loss: 0.3944Epoch [54/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0135Epoch [54/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0070Epoch [54/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0945Epoch [54/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.7012Epoch [54/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0083Epoch [54/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0133Epoch [54/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0846Epoch [54/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1104Epoch [54/124], Batch [100/125] [################----] 80.0%, Loss: 0.0260Epoch [54/124], Batch [101/125] [################----] 80.8%, Loss: 0.0733Epoch [54/124], Batch [102/125] [################----] 81.6%, Loss: 0.0212Epoch [54/124], Batch [103/125] [################----] 82.4%, Loss: 0.1835Epoch [54/124], Batch [104/125] [################----] 83.2%, Loss: 0.1458Epoch [54/124], Batch [105/125] [################----] 84.0%, Loss: 0.0051Epoch [54/124], Batch [106/125] [################----] 84.8%, Loss: 0.1514Epoch [54/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0109Epoch [54/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0021Epoch [54/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0067Epoch [54/124], Batch [110/125] [#################---] 88.0%, Loss: 0.4439Epoch [54/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0111Epoch [54/124], Batch [112/125] [#################---] 89.6%, Loss: 0.3109Epoch [54/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0368Epoch [54/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1776Epoch [54/124], Batch [115/125] [##################--] 92.0%, Loss: 0.3097Epoch [54/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0044Epoch [54/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1264Epoch [54/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0660Epoch [54/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0533Epoch [54/124], Batch [120/125] [###################-] 96.0%, Loss: 0.6844Epoch [54/124], Batch [121/125] [###################-] 96.8%, Loss: 0.7883Epoch [54/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0331Epoch [54/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2035Epoch [54/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0843Epoch [54/124], Batch [125/125] [####################] 100.0%, Loss: 0.1566
Epoch [54/124] finished. Average Loss: 0.1465
Training Accuracy: 98.40%
--- Saving checkpoint for epoch 54 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [55/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0075Epoch [55/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0406Epoch [55/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0073Epoch [55/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.2636Epoch [55/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0025Epoch [55/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0443Epoch [55/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.4347Epoch [55/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0059Epoch [55/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.3405Epoch [55/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0018Epoch [55/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0026Epoch [55/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0070Epoch [55/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3466Epoch [55/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0456Epoch [55/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.5010Epoch [55/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0030Epoch [55/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1551Epoch [55/124], Batch [18/125] [##------------------] 14.4%, Loss: 1.5182Epoch [55/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0088Epoch [55/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0050Epoch [55/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1276Epoch [55/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0544Epoch [55/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0247Epoch [55/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1356Epoch [55/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1533Epoch [55/124], Batch [26/125] [####----------------] 20.8%, Loss: 1.2481Epoch [55/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0033Epoch [55/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0015Epoch [55/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0029Epoch [55/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0002Epoch [55/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0219Epoch [55/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0216Epoch [55/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1903Epoch [55/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.2360Epoch [55/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0203Epoch [55/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0018Epoch [55/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0785Epoch [55/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0782Epoch [55/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0886Epoch [55/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.2600Epoch [55/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0256Epoch [55/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0187Epoch [55/124], Batch [43/125] [######--------------] 34.4%, Loss: 1.6038Epoch [55/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.1179Epoch [55/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1709Epoch [55/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0054Epoch [55/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.6251Epoch [55/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0018Epoch [55/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0096Epoch [55/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0369Epoch [55/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0025Epoch [55/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1678Epoch [55/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0025Epoch [55/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0003Epoch [55/124], Batch [55/125] [########------------] 44.0%, Loss: 0.7743Epoch [55/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0027Epoch [55/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1589Epoch [55/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.4377Epoch [55/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1175Epoch [55/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0064Epoch [55/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.2097Epoch [55/124], Batch [62/125] [#########-----------] 49.6%, Loss: 1.3267Epoch [55/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0067Epoch [55/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0039Epoch [55/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1358Epoch [55/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0575Epoch [55/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1131Epoch [55/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.4560Epoch [55/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0084Epoch [55/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1409Epoch [55/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0018Epoch [55/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0158Epoch [55/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0451Epoch [55/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0150Epoch [55/124], Batch [75/125] [############--------] 60.0%, Loss: 0.6367Epoch [55/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0469Epoch [55/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0201Epoch [55/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0240Epoch [55/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0266Epoch [55/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0455Epoch [55/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0176Epoch [55/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1453Epoch [55/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0348Epoch [55/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0417Epoch [55/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0647Epoch [55/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0131Epoch [55/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1117Epoch [55/124], Batch [88/125] [##############------] 70.4%, Loss: 0.5281Epoch [55/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0531Epoch [55/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0011Epoch [55/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1057Epoch [55/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0078Epoch [55/124], Batch [93/125] [##############------] 74.4%, Loss: 0.4069Epoch [55/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0393Epoch [55/124], Batch [95/125] [###############-----] 76.0%, Loss: 1.0539Epoch [55/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.5577Epoch [55/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1120Epoch [55/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0223Epoch [55/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.7022Epoch [55/124], Batch [100/125] [################----] 80.0%, Loss: 0.0065Epoch [55/124], Batch [101/125] [################----] 80.8%, Loss: 0.0046Epoch [55/124], Batch [102/125] [################----] 81.6%, Loss: 0.3409Epoch [55/124], Batch [103/125] [################----] 82.4%, Loss: 0.0180Epoch [55/124], Batch [104/125] [################----] 83.2%, Loss: 0.0584Epoch [55/124], Batch [105/125] [################----] 84.0%, Loss: 0.1345Epoch [55/124], Batch [106/125] [################----] 84.8%, Loss: 0.3535Epoch [55/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0059Epoch [55/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0665Epoch [55/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2017Epoch [55/124], Batch [110/125] [#################---] 88.0%, Loss: 0.1390Epoch [55/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0027Epoch [55/124], Batch [112/125] [#################---] 89.6%, Loss: 0.4126Epoch [55/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0472Epoch [55/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0834Epoch [55/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0043Epoch [55/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0052Epoch [55/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0024Epoch [55/124], Batch [118/125] [##################--] 94.4%, Loss: 0.8399Epoch [55/124], Batch [119/125] [###################-] 95.2%, Loss: 1.8022Epoch [55/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0098Epoch [55/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0049Epoch [55/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0062Epoch [55/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0463Epoch [55/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0307Epoch [55/124], Batch [125/125] [####################] 100.0%, Loss: 0.0016
Epoch [55/124] finished. Average Loss: 0.1821
Training Accuracy: 97.20%
--- Saving checkpoint for epoch 55 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [56/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0273Epoch [56/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1282Epoch [56/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0430Epoch [56/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0689Epoch [56/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0029Epoch [56/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0095Epoch [56/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.9251Epoch [56/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1862Epoch [56/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0274Epoch [56/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0267Epoch [56/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2458Epoch [56/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0094Epoch [56/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0080Epoch [56/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.5539Epoch [56/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.4539Epoch [56/124], Batch [16/125] [##------------------] 12.8%, Loss: 1.5999Epoch [56/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0034Epoch [56/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1255Epoch [56/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0122Epoch [56/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0052Epoch [56/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.5404Epoch [56/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0426Epoch [56/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0675Epoch [56/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0629Epoch [56/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.2112Epoch [56/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0389Epoch [56/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0008Epoch [56/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0909Epoch [56/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.4974Epoch [56/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.2616Epoch [56/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.3341Epoch [56/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2153Epoch [56/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0709Epoch [56/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.3919Epoch [56/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0833Epoch [56/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0118Epoch [56/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.3932Epoch [56/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0013Epoch [56/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0229Epoch [56/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0139Epoch [56/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1084Epoch [56/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.3880Epoch [56/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0008Epoch [56/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0146Epoch [56/124], Batch [45/125] [#######-------------] 36.0%, Loss: 1.2558Epoch [56/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0044Epoch [56/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0447Epoch [56/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0319Epoch [56/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.4109Epoch [56/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0273Epoch [56/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0395Epoch [56/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0004Epoch [56/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0435Epoch [56/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0281Epoch [56/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0020Epoch [56/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0028Epoch [56/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.7347Epoch [56/124], Batch [58/125] [#########-----------] 46.4%, Loss: 1.3198Epoch [56/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0017Epoch [56/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0224Epoch [56/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0436Epoch [56/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0191Epoch [56/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0330Epoch [56/124], Batch [64/125] [##########----------] 51.2%, Loss: 1.2947Epoch [56/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0352Epoch [56/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.3629Epoch [56/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.3506Epoch [56/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0335Epoch [56/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0021Epoch [56/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0045Epoch [56/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0137Epoch [56/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.5482Epoch [56/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.5178Epoch [56/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.3798Epoch [56/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1062Epoch [56/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1622Epoch [56/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0831Epoch [56/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0117Epoch [56/124], Batch [79/125] [############--------] 63.2%, Loss: 0.3118Epoch [56/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0062Epoch [56/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0137Epoch [56/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0202Epoch [56/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0115Epoch [56/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0227Epoch [56/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0267Epoch [56/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.7536Epoch [56/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0599Epoch [56/124], Batch [88/125] [##############------] 70.4%, Loss: 0.2295Epoch [56/124], Batch [89/125] [##############------] 71.2%, Loss: 0.1553Epoch [56/124], Batch [90/125] [##############------] 72.0%, Loss: 0.8164Epoch [56/124], Batch [91/125] [##############------] 72.8%, Loss: 0.2076Epoch [56/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0078Epoch [56/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1219Epoch [56/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0009Epoch [56/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0010Epoch [56/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.2219Epoch [56/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0226Epoch [56/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0474Epoch [56/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0133Epoch [56/124], Batch [100/125] [################----] 80.0%, Loss: 0.0388Epoch [56/124], Batch [101/125] [################----] 80.8%, Loss: 0.0045Epoch [56/124], Batch [102/125] [################----] 81.6%, Loss: 0.0051Epoch [56/124], Batch [103/125] [################----] 82.4%, Loss: 1.2382Epoch [56/124], Batch [104/125] [################----] 83.2%, Loss: 0.0008Epoch [56/124], Batch [105/125] [################----] 84.0%, Loss: 0.0055Epoch [56/124], Batch [106/125] [################----] 84.8%, Loss: 0.2987Epoch [56/124], Batch [107/125] [#################---] 85.6%, Loss: 0.5584Epoch [56/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2250Epoch [56/124], Batch [109/125] [#################---] 87.2%, Loss: 0.6187Epoch [56/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0112Epoch [56/124], Batch [111/125] [#################---] 88.8%, Loss: 0.2436Epoch [56/124], Batch [112/125] [#################---] 89.6%, Loss: 1.4739Epoch [56/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2977Epoch [56/124], Batch [114/125] [##################--] 91.2%, Loss: 0.9180Epoch [56/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0084Epoch [56/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1318Epoch [56/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0175Epoch [56/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0202Epoch [56/124], Batch [119/125] [###################-] 95.2%, Loss: 0.4093Epoch [56/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1784Epoch [56/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0055Epoch [56/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0556Epoch [56/124], Batch [123/125] [###################-] 98.4%, Loss: 0.3377Epoch [56/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0281Epoch [56/124], Batch [125/125] [####################] 100.0%, Loss: 0.0262
Epoch [56/124] finished. Average Loss: 0.2122
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 56 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [57/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0818Epoch [57/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1715Epoch [57/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0580Epoch [57/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0376Epoch [57/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0057Epoch [57/124], Batch [6/125] [--------------------] 4.8%, Loss: 1.1674Epoch [57/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0440Epoch [57/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0776Epoch [57/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2114Epoch [57/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0984Epoch [57/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0121Epoch [57/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0735Epoch [57/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0186Epoch [57/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.2693Epoch [57/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.4529Epoch [57/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0154Epoch [57/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0560Epoch [57/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0048Epoch [57/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0048Epoch [57/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0285Epoch [57/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.4432Epoch [57/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0105Epoch [57/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0168Epoch [57/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0611Epoch [57/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0405Epoch [57/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.4116Epoch [57/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0949Epoch [57/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0346Epoch [57/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0024Epoch [57/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0003Epoch [57/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.2977Epoch [57/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.3160Epoch [57/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1598Epoch [57/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0028Epoch [57/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0226Epoch [57/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0040Epoch [57/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0009Epoch [57/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1789Epoch [57/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1383Epoch [57/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0699Epoch [57/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0138Epoch [57/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.4009Epoch [57/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2580Epoch [57/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0899Epoch [57/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0244Epoch [57/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0544Epoch [57/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0036Epoch [57/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0339Epoch [57/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0088Epoch [57/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0076Epoch [57/124], Batch [51/125] [########------------] 40.8%, Loss: 0.2062Epoch [57/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1294Epoch [57/124], Batch [53/125] [########------------] 42.4%, Loss: 0.2273Epoch [57/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0016Epoch [57/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0543Epoch [57/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0106Epoch [57/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.2070Epoch [57/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.5127Epoch [57/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0220Epoch [57/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0509Epoch [57/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0607Epoch [57/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0143Epoch [57/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0023Epoch [57/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.4849Epoch [57/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0008Epoch [57/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0004Epoch [57/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0050Epoch [57/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0326Epoch [57/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0004Epoch [57/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.2533Epoch [57/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.2992Epoch [57/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1806Epoch [57/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0252Epoch [57/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0142Epoch [57/124], Batch [75/125] [############--------] 60.0%, Loss: 1.3848Epoch [57/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0059Epoch [57/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0611Epoch [57/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1296Epoch [57/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0632Epoch [57/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0022Epoch [57/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0071Epoch [57/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.2761Epoch [57/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0233Epoch [57/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0721Epoch [57/124], Batch [85/125] [#############-------] 68.0%, Loss: 1.1325Epoch [57/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0168Epoch [57/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0029Epoch [57/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0012Epoch [57/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0598Epoch [57/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0950Epoch [57/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0119Epoch [57/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0020Epoch [57/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0092Epoch [57/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0821Epoch [57/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0076Epoch [57/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0230Epoch [57/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0034Epoch [57/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0036Epoch [57/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0187Epoch [57/124], Batch [100/125] [################----] 80.0%, Loss: 0.0027Epoch [57/124], Batch [101/125] [################----] 80.8%, Loss: 0.0328Epoch [57/124], Batch [102/125] [################----] 81.6%, Loss: 0.0125Epoch [57/124], Batch [103/125] [################----] 82.4%, Loss: 0.0602Epoch [57/124], Batch [104/125] [################----] 83.2%, Loss: 0.0141Epoch [57/124], Batch [105/125] [################----] 84.0%, Loss: 0.0005Epoch [57/124], Batch [106/125] [################----] 84.8%, Loss: 0.0014Epoch [57/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1578Epoch [57/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1835Epoch [57/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1047Epoch [57/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0153Epoch [57/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0122Epoch [57/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0027Epoch [57/124], Batch [113/125] [##################--] 90.4%, Loss: 1.4878Epoch [57/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0135Epoch [57/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0206Epoch [57/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0180Epoch [57/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1473Epoch [57/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1796Epoch [57/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0017Epoch [57/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2956Epoch [57/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0038Epoch [57/124], Batch [122/125] [###################-] 97.6%, Loss: 0.5706Epoch [57/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0098Epoch [57/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0004Epoch [57/124], Batch [125/125] [####################] 100.0%, Loss: 0.0310
Epoch [57/124] finished. Average Loss: 0.1261
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 57 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [58/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0635Epoch [58/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0004Epoch [58/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.1306Epoch [58/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0046Epoch [58/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0008Epoch [58/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0005Epoch [58/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0734Epoch [58/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0025Epoch [58/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.7705Epoch [58/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0016Epoch [58/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.4992Epoch [58/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0959Epoch [58/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0049Epoch [58/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0056Epoch [58/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0110Epoch [58/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0004Epoch [58/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0079Epoch [58/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0469Epoch [58/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0013Epoch [58/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0010Epoch [58/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0008Epoch [58/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0043Epoch [58/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0004Epoch [58/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0273Epoch [58/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0126Epoch [58/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1218Epoch [58/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0160Epoch [58/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0333Epoch [58/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0043Epoch [58/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0123Epoch [58/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0014Epoch [58/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0046Epoch [58/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.8045Epoch [58/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0230Epoch [58/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0135Epoch [58/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0018Epoch [58/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0013Epoch [58/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0705Epoch [58/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0009Epoch [58/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0166Epoch [58/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0062Epoch [58/124], Batch [42/125] [######--------------] 33.6%, Loss: 1.3929Epoch [58/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0064Epoch [58/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0438Epoch [58/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.3348Epoch [58/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0152Epoch [58/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0008Epoch [58/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0276Epoch [58/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0234Epoch [58/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0023Epoch [58/124], Batch [51/125] [########------------] 40.8%, Loss: 0.3257Epoch [58/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0157Epoch [58/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0215Epoch [58/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0186Epoch [58/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0352Epoch [58/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0281Epoch [58/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0063Epoch [58/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0608Epoch [58/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2086Epoch [58/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0010Epoch [58/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0160Epoch [58/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0224Epoch [58/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0053Epoch [58/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0064Epoch [58/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0242Epoch [58/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2457Epoch [58/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0099Epoch [58/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0015Epoch [58/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0153Epoch [58/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0416Epoch [58/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0117Epoch [58/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0295Epoch [58/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0033Epoch [58/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0403Epoch [58/124], Batch [75/125] [############--------] 60.0%, Loss: 1.5386Epoch [58/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0058Epoch [58/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0307Epoch [58/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0164Epoch [58/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0014Epoch [58/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0096Epoch [58/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0067Epoch [58/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0034Epoch [58/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1136Epoch [58/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0898Epoch [58/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0045Epoch [58/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0006Epoch [58/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0009Epoch [58/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0008Epoch [58/124], Batch [89/125] [##############------] 71.2%, Loss: 0.1666Epoch [58/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0476Epoch [58/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0066Epoch [58/124], Batch [92/125] [##############------] 73.6%, Loss: 0.3812Epoch [58/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0799Epoch [58/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0186Epoch [58/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0032Epoch [58/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0099Epoch [58/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0058Epoch [58/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0040Epoch [58/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0049Epoch [58/124], Batch [100/125] [################----] 80.0%, Loss: 0.0085Epoch [58/124], Batch [101/125] [################----] 80.8%, Loss: 0.0202Epoch [58/124], Batch [102/125] [################----] 81.6%, Loss: 0.0010Epoch [58/124], Batch [103/125] [################----] 82.4%, Loss: 0.3725Epoch [58/124], Batch [104/125] [################----] 83.2%, Loss: 0.0001Epoch [58/124], Batch [105/125] [################----] 84.0%, Loss: 0.0293Epoch [58/124], Batch [106/125] [################----] 84.8%, Loss: 0.0005Epoch [58/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0072Epoch [58/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0933Epoch [58/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0088Epoch [58/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0048Epoch [58/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0001Epoch [58/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0003Epoch [58/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2467Epoch [58/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0061Epoch [58/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0004Epoch [58/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0371Epoch [58/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0101Epoch [58/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0218Epoch [58/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0297Epoch [58/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0633Epoch [58/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0135Epoch [58/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0119Epoch [58/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0341Epoch [58/124], Batch [124/125] [###################-] 99.2%, Loss: 0.8182Epoch [58/124], Batch [125/125] [####################] 100.0%, Loss: 0.0359
Epoch [58/124] finished. Average Loss: 0.0829
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 58 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [59/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0003Epoch [59/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0028Epoch [59/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.1691Epoch [59/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0578Epoch [59/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1484Epoch [59/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0494Epoch [59/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0134Epoch [59/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0002Epoch [59/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0006Epoch [59/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0003Epoch [59/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0003Epoch [59/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0008Epoch [59/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0814Epoch [59/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0144Epoch [59/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.3038Epoch [59/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0034Epoch [59/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0017Epoch [59/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0029Epoch [59/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0114Epoch [59/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0233Epoch [59/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0026Epoch [59/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0084Epoch [59/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0823Epoch [59/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0037Epoch [59/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1478Epoch [59/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0128Epoch [59/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0259Epoch [59/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0070Epoch [59/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0039Epoch [59/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0101Epoch [59/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0067Epoch [59/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0008Epoch [59/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0730Epoch [59/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0001Epoch [59/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0489Epoch [59/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0176Epoch [59/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0165Epoch [59/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0254Epoch [59/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0082Epoch [59/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0157Epoch [59/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0197Epoch [59/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0075Epoch [59/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0047Epoch [59/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0006Epoch [59/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0631Epoch [59/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1129Epoch [59/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.3151Epoch [59/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0032Epoch [59/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0002Epoch [59/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0027Epoch [59/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0439Epoch [59/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0129Epoch [59/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0055Epoch [59/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0014Epoch [59/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0646Epoch [59/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0016Epoch [59/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0011Epoch [59/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0033Epoch [59/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0015Epoch [59/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0000Epoch [59/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0047Epoch [59/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0004Epoch [59/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0010Epoch [59/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0154Epoch [59/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0138Epoch [59/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0015Epoch [59/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0012Epoch [59/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0696Epoch [59/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0046Epoch [59/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0022Epoch [59/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0033Epoch [59/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0647Epoch [59/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0021Epoch [59/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0093Epoch [59/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0033Epoch [59/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0010Epoch [59/124], Batch [77/125] [############--------] 61.6%, Loss: 0.3469Epoch [59/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0009Epoch [59/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0010Epoch [59/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0177Epoch [59/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0102Epoch [59/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0017Epoch [59/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0175Epoch [59/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0002Epoch [59/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0492Epoch [59/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0008Epoch [59/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0019Epoch [59/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0012Epoch [59/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0014Epoch [59/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0002Epoch [59/124], Batch [91/125] [##############------] 72.8%, Loss: 1.2823Epoch [59/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0030Epoch [59/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0246Epoch [59/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0027Epoch [59/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0055Epoch [59/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1263Epoch [59/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0079Epoch [59/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0004Epoch [59/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0078Epoch [59/124], Batch [100/125] [################----] 80.0%, Loss: 0.0124Epoch [59/124], Batch [101/125] [################----] 80.8%, Loss: 0.0003Epoch [59/124], Batch [102/125] [################----] 81.6%, Loss: 0.0016Epoch [59/124], Batch [103/125] [################----] 82.4%, Loss: 0.0012Epoch [59/124], Batch [104/125] [################----] 83.2%, Loss: 0.0034Epoch [59/124], Batch [105/125] [################----] 84.0%, Loss: 0.0006Epoch [59/124], Batch [106/125] [################----] 84.8%, Loss: 0.0019Epoch [59/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0001Epoch [59/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0129Epoch [59/124], Batch [109/125] [#################---] 87.2%, Loss: 0.9537Epoch [59/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0124Epoch [59/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0243Epoch [59/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0015Epoch [59/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0117Epoch [59/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0009Epoch [59/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0036Epoch [59/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0121Epoch [59/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0177Epoch [59/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0229Epoch [59/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0134Epoch [59/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0135Epoch [59/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0041Epoch [59/124], Batch [122/125] [###################-] 97.6%, Loss: 0.3883Epoch [59/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0109Epoch [59/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0006Epoch [59/124], Batch [125/125] [####################] 100.0%, Loss: 0.0049
Epoch [59/124] finished. Average Loss: 0.0457
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 59 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [60/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0100Epoch [60/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0180Epoch [60/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0020Epoch [60/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0004Epoch [60/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0186Epoch [60/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0104Epoch [60/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0032Epoch [60/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0015Epoch [60/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0003Epoch [60/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.3446Epoch [60/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.4367Epoch [60/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0174Epoch [60/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0183Epoch [60/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0003Epoch [60/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0099Epoch [60/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0032Epoch [60/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0012Epoch [60/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0302Epoch [60/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0048Epoch [60/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0287Epoch [60/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0087Epoch [60/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0019Epoch [60/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0027Epoch [60/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0042Epoch [60/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0116Epoch [60/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0076Epoch [60/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0020Epoch [60/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0005Epoch [60/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0096Epoch [60/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0169Epoch [60/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0008Epoch [60/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0001Epoch [60/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0047Epoch [60/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0006Epoch [60/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0035Epoch [60/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0133Epoch [60/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0006Epoch [60/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0006Epoch [60/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0213Epoch [60/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0012Epoch [60/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0011Epoch [60/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.2652Epoch [60/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0120Epoch [60/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0002Epoch [60/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0012Epoch [60/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0001Epoch [60/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0038Epoch [60/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0059Epoch [60/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0059Epoch [60/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0269Epoch [60/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0753Epoch [60/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0006Epoch [60/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0045Epoch [60/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0074Epoch [60/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0037Epoch [60/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0122Epoch [60/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0005Epoch [60/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0010Epoch [60/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0001Epoch [60/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0144Epoch [60/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0021Epoch [60/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0005Epoch [60/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0057Epoch [60/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0096Epoch [60/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0073Epoch [60/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0001Epoch [60/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0053Epoch [60/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0009Epoch [60/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0038Epoch [60/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0068Epoch [60/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0272Epoch [60/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0586Epoch [60/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0003Epoch [60/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2122Epoch [60/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0004Epoch [60/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0066Epoch [60/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0055Epoch [60/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0018Epoch [60/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0262Epoch [60/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0030Epoch [60/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0013Epoch [60/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0007Epoch [60/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0006Epoch [60/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0002Epoch [60/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0123Epoch [60/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0018Epoch [60/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0091Epoch [60/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0011Epoch [60/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0115Epoch [60/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0969Epoch [60/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0011Epoch [60/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0003Epoch [60/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0037Epoch [60/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0101Epoch [60/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0083Epoch [60/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0002Epoch [60/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0074Epoch [60/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0118Epoch [60/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0086Epoch [60/124], Batch [100/125] [################----] 80.0%, Loss: 0.0075Epoch [60/124], Batch [101/125] [################----] 80.8%, Loss: 0.6367Epoch [60/124], Batch [102/125] [################----] 81.6%, Loss: 0.0166Epoch [60/124], Batch [103/125] [################----] 82.4%, Loss: 0.0133Epoch [60/124], Batch [104/125] [################----] 83.2%, Loss: 0.0216Epoch [60/124], Batch [105/125] [################----] 84.0%, Loss: 0.1099Epoch [60/124], Batch [106/125] [################----] 84.8%, Loss: 0.0058Epoch [60/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0760Epoch [60/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0047Epoch [60/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0131Epoch [60/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0155Epoch [60/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0216Epoch [60/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0009Epoch [60/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0006Epoch [60/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0631Epoch [60/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0001Epoch [60/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0032Epoch [60/124], Batch [117/125] [##################--] 93.6%, Loss: 0.2577Epoch [60/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0050Epoch [60/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0054Epoch [60/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0027Epoch [60/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0007Epoch [60/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0017Epoch [60/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0010Epoch [60/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0077Epoch [60/124], Batch [125/125] [####################] 100.0%, Loss: 0.0034
Epoch [60/124] finished. Average Loss: 0.0270
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 60 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [61/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0027Epoch [61/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0009Epoch [61/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0002Epoch [61/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0015Epoch [61/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0267Epoch [61/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0059Epoch [61/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0051Epoch [61/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0019Epoch [61/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0055Epoch [61/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0051Epoch [61/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0008Epoch [61/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0061Epoch [61/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0022Epoch [61/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [61/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.9123Epoch [61/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0068Epoch [61/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0003Epoch [61/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0010Epoch [61/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0161Epoch [61/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0030Epoch [61/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0102Epoch [61/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0014Epoch [61/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0011Epoch [61/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0004Epoch [61/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0009Epoch [61/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0059Epoch [61/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0018Epoch [61/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0746Epoch [61/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0001Epoch [61/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0054Epoch [61/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0002Epoch [61/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0005Epoch [61/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0198Epoch [61/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0023Epoch [61/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0017Epoch [61/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.5276Epoch [61/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0031Epoch [61/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0682Epoch [61/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0003Epoch [61/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0014Epoch [61/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0010Epoch [61/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0011Epoch [61/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0038Epoch [61/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.3044Epoch [61/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0047Epoch [61/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0009Epoch [61/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0125Epoch [61/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.7012Epoch [61/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0051Epoch [61/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0010Epoch [61/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0444Epoch [61/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0018Epoch [61/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0007Epoch [61/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0873Epoch [61/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0070Epoch [61/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1760Epoch [61/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0014Epoch [61/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0022Epoch [61/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0761Epoch [61/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0066Epoch [61/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.1573Epoch [61/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0025Epoch [61/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0069Epoch [61/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0080Epoch [61/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0259Epoch [61/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0051Epoch [61/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0111Epoch [61/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0015Epoch [61/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0006Epoch [61/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1433Epoch [61/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0013Epoch [61/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0016Epoch [61/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0016Epoch [61/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.3338Epoch [61/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0080Epoch [61/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0099Epoch [61/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0005Epoch [61/124], Batch [78/125] [############--------] 62.4%, Loss: 0.2677Epoch [61/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0003Epoch [61/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0033Epoch [61/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0070Epoch [61/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0513Epoch [61/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0056Epoch [61/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0617Epoch [61/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0019Epoch [61/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0175Epoch [61/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0002Epoch [61/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0035Epoch [61/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0045Epoch [61/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0140Epoch [61/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0086Epoch [61/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1511Epoch [61/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1396Epoch [61/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0736Epoch [61/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0127Epoch [61/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0037Epoch [61/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0022Epoch [61/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0097Epoch [61/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0058Epoch [61/124], Batch [100/125] [################----] 80.0%, Loss: 0.0055Epoch [61/124], Batch [101/125] [################----] 80.8%, Loss: 0.5387Epoch [61/124], Batch [102/125] [################----] 81.6%, Loss: 0.0012Epoch [61/124], Batch [103/125] [################----] 82.4%, Loss: 0.0721Epoch [61/124], Batch [104/125] [################----] 83.2%, Loss: 0.0029Epoch [61/124], Batch [105/125] [################----] 84.0%, Loss: 0.0002Epoch [61/124], Batch [106/125] [################----] 84.8%, Loss: 0.0009Epoch [61/124], Batch [107/125] [#################---] 85.6%, Loss: 0.7412Epoch [61/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0041Epoch [61/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0285Epoch [61/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0020Epoch [61/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0027Epoch [61/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0062Epoch [61/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0007Epoch [61/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4633Epoch [61/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0059Epoch [61/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0782Epoch [61/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0024Epoch [61/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0188Epoch [61/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0058Epoch [61/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0071Epoch [61/124], Batch [121/125] [###################-] 96.8%, Loss: 0.1240Epoch [61/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0068Epoch [61/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0891Epoch [61/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0119Epoch [61/124], Batch [125/125] [####################] 100.0%, Loss: 0.0109
Epoch [61/124] finished. Average Loss: 0.0557
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 61 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [62/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0007Epoch [62/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0029Epoch [62/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0828Epoch [62/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0433Epoch [62/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.2001Epoch [62/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0018Epoch [62/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0497Epoch [62/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0012Epoch [62/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0033Epoch [62/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0003Epoch [62/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.5383Epoch [62/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.8846Epoch [62/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0002Epoch [62/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0068Epoch [62/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0020Epoch [62/124], Batch [16/125] [##------------------] 12.8%, Loss: 1.2522Epoch [62/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0005Epoch [62/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.2262Epoch [62/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0056Epoch [62/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0005Epoch [62/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0005Epoch [62/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0419Epoch [62/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0002Epoch [62/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0244Epoch [62/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.5886Epoch [62/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0168Epoch [62/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.8820Epoch [62/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0033Epoch [62/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0527Epoch [62/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0013Epoch [62/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0019Epoch [62/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0266Epoch [62/124], Batch [33/125] [#####---------------] 26.4%, Loss: 1.4976Epoch [62/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0005Epoch [62/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0049Epoch [62/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1399Epoch [62/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0062Epoch [62/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.5094Epoch [62/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0900Epoch [62/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0259Epoch [62/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0347Epoch [62/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0005Epoch [62/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0518Epoch [62/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0123Epoch [62/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0234Epoch [62/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.5043Epoch [62/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0054Epoch [62/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0672Epoch [62/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.1229Epoch [62/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0014Epoch [62/124], Batch [51/125] [########------------] 40.8%, Loss: 0.2112Epoch [62/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0086Epoch [62/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0024Epoch [62/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0746Epoch [62/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0035Epoch [62/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0044Epoch [62/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0146Epoch [62/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1375Epoch [62/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0091Epoch [62/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0010Epoch [62/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0613Epoch [62/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0140Epoch [62/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0079Epoch [62/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2796Epoch [62/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0167Epoch [62/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0005Epoch [62/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0130Epoch [62/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0747Epoch [62/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1311Epoch [62/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0016Epoch [62/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0006Epoch [62/124], Batch [72/125] [###########---------] 57.6%, Loss: 1.3525Epoch [62/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0386Epoch [62/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0226Epoch [62/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0204Epoch [62/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0121Epoch [62/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0009Epoch [62/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0041Epoch [62/124], Batch [79/125] [############--------] 63.2%, Loss: 0.5731Epoch [62/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0522Epoch [62/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0503Epoch [62/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1030Epoch [62/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0799Epoch [62/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0604Epoch [62/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0123Epoch [62/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0345Epoch [62/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0589Epoch [62/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1172Epoch [62/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0035Epoch [62/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0057Epoch [62/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0631Epoch [62/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0379Epoch [62/124], Batch [93/125] [##############------] 74.4%, Loss: 0.8033Epoch [62/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1257Epoch [62/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3859Epoch [62/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0067Epoch [62/124], Batch [97/125] [###############-----] 77.6%, Loss: 1.0667Epoch [62/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0079Epoch [62/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0092Epoch [62/124], Batch [100/125] [################----] 80.0%, Loss: 0.0457Epoch [62/124], Batch [101/125] [################----] 80.8%, Loss: 0.6334Epoch [62/124], Batch [102/125] [################----] 81.6%, Loss: 0.0293Epoch [62/124], Batch [103/125] [################----] 82.4%, Loss: 0.0357Epoch [62/124], Batch [104/125] [################----] 83.2%, Loss: 0.0236Epoch [62/124], Batch [105/125] [################----] 84.0%, Loss: 0.0021Epoch [62/124], Batch [106/125] [################----] 84.8%, Loss: 0.6314Epoch [62/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0415Epoch [62/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0459Epoch [62/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0041Epoch [62/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0095Epoch [62/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0241Epoch [62/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0058Epoch [62/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0349Epoch [62/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0036Epoch [62/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0004Epoch [62/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0873Epoch [62/124], Batch [117/125] [##################--] 93.6%, Loss: 0.3400Epoch [62/124], Batch [118/125] [##################--] 94.4%, Loss: 2.0297Epoch [62/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0326Epoch [62/124], Batch [120/125] [###################-] 96.0%, Loss: 0.3712Epoch [62/124], Batch [121/125] [###################-] 96.8%, Loss: 0.4948Epoch [62/124], Batch [122/125] [###################-] 97.6%, Loss: 1.2381Epoch [62/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0899Epoch [62/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0052Epoch [62/124], Batch [125/125] [####################] 100.0%, Loss: 0.0027
Epoch [62/124] finished. Average Loss: 0.1638
Training Accuracy: 95.20%
--- Saving checkpoint for epoch 62 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [63/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0105Epoch [63/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0475Epoch [63/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0008Epoch [63/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0417Epoch [63/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1586Epoch [63/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0212Epoch [63/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0672Epoch [63/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0491Epoch [63/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1304Epoch [63/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0988Epoch [63/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0012Epoch [63/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0107Epoch [63/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.4307Epoch [63/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0812Epoch [63/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0030Epoch [63/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.5116Epoch [63/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1245Epoch [63/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0009Epoch [63/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0429Epoch [63/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0018Epoch [63/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0217Epoch [63/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0405Epoch [63/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.3027Epoch [63/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0120Epoch [63/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3716Epoch [63/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0259Epoch [63/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0020Epoch [63/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0148Epoch [63/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0021Epoch [63/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1791Epoch [63/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0142Epoch [63/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0357Epoch [63/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0135Epoch [63/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0283Epoch [63/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.8369Epoch [63/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0569Epoch [63/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0419Epoch [63/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0147Epoch [63/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0473Epoch [63/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.2573Epoch [63/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0387Epoch [63/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0127Epoch [63/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0020Epoch [63/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0547Epoch [63/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0837Epoch [63/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1644Epoch [63/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0501Epoch [63/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0133Epoch [63/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0066Epoch [63/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0959Epoch [63/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0087Epoch [63/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0329Epoch [63/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0465Epoch [63/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0877Epoch [63/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0042Epoch [63/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0022Epoch [63/124], Batch [57/125] [#########-----------] 45.6%, Loss: 1.2889Epoch [63/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0006Epoch [63/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2644Epoch [63/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.5726Epoch [63/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0168Epoch [63/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0024Epoch [63/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0861Epoch [63/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0102Epoch [63/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0005Epoch [63/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0031Epoch [63/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1386Epoch [63/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0104Epoch [63/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0024Epoch [63/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0346Epoch [63/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0008Epoch [63/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0187Epoch [63/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0094Epoch [63/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0337Epoch [63/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0390Epoch [63/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0361Epoch [63/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0023Epoch [63/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0060Epoch [63/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0708Epoch [63/124], Batch [80/125] [############--------] 64.0%, Loss: 0.2673Epoch [63/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1032Epoch [63/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.4382Epoch [63/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0005Epoch [63/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0241Epoch [63/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1561Epoch [63/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0015Epoch [63/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0064Epoch [63/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0386Epoch [63/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0040Epoch [63/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0687Epoch [63/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0032Epoch [63/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0013Epoch [63/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0245Epoch [63/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0059Epoch [63/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0543Epoch [63/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0755Epoch [63/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0368Epoch [63/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0679Epoch [63/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0021Epoch [63/124], Batch [100/125] [################----] 80.0%, Loss: 0.0291Epoch [63/124], Batch [101/125] [################----] 80.8%, Loss: 0.0012Epoch [63/124], Batch [102/125] [################----] 81.6%, Loss: 0.0002Epoch [63/124], Batch [103/125] [################----] 82.4%, Loss: 0.0040Epoch [63/124], Batch [104/125] [################----] 83.2%, Loss: 0.0692Epoch [63/124], Batch [105/125] [################----] 84.0%, Loss: 0.1171Epoch [63/124], Batch [106/125] [################----] 84.8%, Loss: 0.0082Epoch [63/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1600Epoch [63/124], Batch [108/125] [#################---] 86.4%, Loss: 0.6342Epoch [63/124], Batch [109/125] [#################---] 87.2%, Loss: 0.4889Epoch [63/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0008Epoch [63/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0005Epoch [63/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0069Epoch [63/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1681Epoch [63/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0407Epoch [63/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0011Epoch [63/124], Batch [116/125] [##################--] 92.8%, Loss: 0.5572Epoch [63/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0088Epoch [63/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0247Epoch [63/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0089Epoch [63/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0007Epoch [63/124], Batch [121/125] [###################-] 96.8%, Loss: 0.1281Epoch [63/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0006Epoch [63/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0023Epoch [63/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0020Epoch [63/124], Batch [125/125] [####################] 100.0%, Loss: 0.0144
Epoch [63/124] finished. Average Loss: 0.0909
Training Accuracy: 98.00%
--- Saving checkpoint for epoch 63 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [64/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0029Epoch [64/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.2760Epoch [64/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.6371Epoch [64/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0009Epoch [64/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0006Epoch [64/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0009Epoch [64/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0032Epoch [64/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0022Epoch [64/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1077Epoch [64/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0009Epoch [64/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0188Epoch [64/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0008Epoch [64/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0041Epoch [64/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0844Epoch [64/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0084Epoch [64/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0005Epoch [64/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0029Epoch [64/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0132Epoch [64/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0066Epoch [64/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0077Epoch [64/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0007Epoch [64/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0208Epoch [64/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0713Epoch [64/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0021Epoch [64/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.1623Epoch [64/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0058Epoch [64/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0049Epoch [64/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0014Epoch [64/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0536Epoch [64/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0037Epoch [64/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0022Epoch [64/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0074Epoch [64/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0078Epoch [64/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0012Epoch [64/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0031Epoch [64/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0367Epoch [64/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0073Epoch [64/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0009Epoch [64/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0021Epoch [64/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0541Epoch [64/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0642Epoch [64/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0007Epoch [64/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0020Epoch [64/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0001Epoch [64/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0028Epoch [64/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0014Epoch [64/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0299Epoch [64/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0004Epoch [64/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0026Epoch [64/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0031Epoch [64/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0110Epoch [64/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0074Epoch [64/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0011Epoch [64/124], Batch [54/125] [########------------] 43.2%, Loss: 1.0489Epoch [64/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0254Epoch [64/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0032Epoch [64/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0003Epoch [64/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0067Epoch [64/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.3207Epoch [64/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0090Epoch [64/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0015Epoch [64/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0042Epoch [64/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0094Epoch [64/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0103Epoch [64/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0100Epoch [64/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0008Epoch [64/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0019Epoch [64/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0542Epoch [64/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0068Epoch [64/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0043Epoch [64/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0012Epoch [64/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0001Epoch [64/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.1030Epoch [64/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0144Epoch [64/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0494Epoch [64/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0008Epoch [64/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0024Epoch [64/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0102Epoch [64/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0025Epoch [64/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0106Epoch [64/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0102Epoch [64/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0108Epoch [64/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0002Epoch [64/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0010Epoch [64/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0001Epoch [64/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0008Epoch [64/124], Batch [87/125] [#############-------] 69.6%, Loss: 1.2900Epoch [64/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0353Epoch [64/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0048Epoch [64/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0422Epoch [64/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0036Epoch [64/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0063Epoch [64/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0055Epoch [64/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0029Epoch [64/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0136Epoch [64/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0625Epoch [64/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0075Epoch [64/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0063Epoch [64/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0029Epoch [64/124], Batch [100/125] [################----] 80.0%, Loss: 0.9882Epoch [64/124], Batch [101/125] [################----] 80.8%, Loss: 0.0184Epoch [64/124], Batch [102/125] [################----] 81.6%, Loss: 0.0064Epoch [64/124], Batch [103/125] [################----] 82.4%, Loss: 0.0025Epoch [64/124], Batch [104/125] [################----] 83.2%, Loss: 0.0189Epoch [64/124], Batch [105/125] [################----] 84.0%, Loss: 0.0004Epoch [64/124], Batch [106/125] [################----] 84.8%, Loss: 0.0004Epoch [64/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0174Epoch [64/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0003Epoch [64/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0010Epoch [64/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0010Epoch [64/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0007Epoch [64/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0001Epoch [64/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0144Epoch [64/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0035Epoch [64/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0296Epoch [64/124], Batch [116/125] [##################--] 92.8%, Loss: 0.4907Epoch [64/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0103Epoch [64/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0114Epoch [64/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0028Epoch [64/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0114Epoch [64/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0337Epoch [64/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0066Epoch [64/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0003Epoch [64/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0002Epoch [64/124], Batch [125/125] [####################] 100.0%, Loss: 0.0209
Epoch [64/124] finished. Average Loss: 0.0533
Training Accuracy: 99.40%
--- Saving checkpoint for epoch 64 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [65/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0046Epoch [65/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0026Epoch [65/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0073Epoch [65/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0002Epoch [65/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0393Epoch [65/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0209Epoch [65/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0088Epoch [65/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0023Epoch [65/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0057Epoch [65/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.2878Epoch [65/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0077Epoch [65/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0019Epoch [65/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0031Epoch [65/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0031Epoch [65/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0033Epoch [65/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0007Epoch [65/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3737Epoch [65/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0008Epoch [65/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.2104Epoch [65/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0030Epoch [65/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0003Epoch [65/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0005Epoch [65/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0071Epoch [65/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.4191Epoch [65/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0409Epoch [65/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0049Epoch [65/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0044Epoch [65/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0198Epoch [65/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0328Epoch [65/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0025Epoch [65/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0024Epoch [65/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0051Epoch [65/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0003Epoch [65/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0193Epoch [65/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0041Epoch [65/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0760Epoch [65/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.2013Epoch [65/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0197Epoch [65/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0059Epoch [65/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0251Epoch [65/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0090Epoch [65/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0047Epoch [65/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0016Epoch [65/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0187Epoch [65/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0080Epoch [65/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0015Epoch [65/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0709Epoch [65/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0086Epoch [65/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0030Epoch [65/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0050Epoch [65/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0004Epoch [65/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0002Epoch [65/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0066Epoch [65/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0152Epoch [65/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0004Epoch [65/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0113Epoch [65/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0208Epoch [65/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0068Epoch [65/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0071Epoch [65/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0042Epoch [65/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0101Epoch [65/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0114Epoch [65/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0041Epoch [65/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0030Epoch [65/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0126Epoch [65/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0221Epoch [65/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0002Epoch [65/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0048Epoch [65/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0692Epoch [65/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0007Epoch [65/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0008Epoch [65/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0010Epoch [65/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0003Epoch [65/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0050Epoch [65/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0005Epoch [65/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1019Epoch [65/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0016Epoch [65/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1023Epoch [65/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1549Epoch [65/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0046Epoch [65/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0160Epoch [65/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0012Epoch [65/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0142Epoch [65/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0047Epoch [65/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0001Epoch [65/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0025Epoch [65/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0939Epoch [65/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0052Epoch [65/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0535Epoch [65/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0023Epoch [65/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0005Epoch [65/124], Batch [92/125] [##############------] 73.6%, Loss: 0.5056Epoch [65/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0038Epoch [65/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0005Epoch [65/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0018Epoch [65/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.2692Epoch [65/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0027Epoch [65/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0003Epoch [65/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0007Epoch [65/124], Batch [100/125] [################----] 80.0%, Loss: 0.0866Epoch [65/124], Batch [101/125] [################----] 80.8%, Loss: 0.1089Epoch [65/124], Batch [102/125] [################----] 81.6%, Loss: 0.0018Epoch [65/124], Batch [103/125] [################----] 82.4%, Loss: 0.0149Epoch [65/124], Batch [104/125] [################----] 83.2%, Loss: 0.0013Epoch [65/124], Batch [105/125] [################----] 84.0%, Loss: 1.4088Epoch [65/124], Batch [106/125] [################----] 84.8%, Loss: 0.0018Epoch [65/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1485Epoch [65/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0003Epoch [65/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0023Epoch [65/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0052Epoch [65/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0033Epoch [65/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0394Epoch [65/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0006Epoch [65/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0382Epoch [65/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0450Epoch [65/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0009Epoch [65/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0002Epoch [65/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0000Epoch [65/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0034Epoch [65/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0020Epoch [65/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0015Epoch [65/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0153Epoch [65/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0007Epoch [65/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0031Epoch [65/124], Batch [125/125] [####################] 100.0%, Loss: 0.0001
Epoch [65/124] finished. Average Loss: 0.0441
Training Accuracy: 98.60%
--- Saving checkpoint for epoch 65 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [66/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0013Epoch [66/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0072Epoch [66/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0009Epoch [66/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0036Epoch [66/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0126Epoch [66/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0003Epoch [66/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0515Epoch [66/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0036Epoch [66/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0045Epoch [66/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0024Epoch [66/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0309Epoch [66/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0799Epoch [66/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.1411Epoch [66/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0012Epoch [66/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.2990Epoch [66/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.5947Epoch [66/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0006Epoch [66/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0026Epoch [66/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0433Epoch [66/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.2260Epoch [66/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0063Epoch [66/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0014Epoch [66/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.2358Epoch [66/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0004Epoch [66/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0012Epoch [66/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0256Epoch [66/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0021Epoch [66/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0146Epoch [66/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0019Epoch [66/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0354Epoch [66/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0001Epoch [66/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0005Epoch [66/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0002Epoch [66/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0013Epoch [66/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0033Epoch [66/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.7767Epoch [66/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0119Epoch [66/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0002Epoch [66/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.7899Epoch [66/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0120Epoch [66/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0011Epoch [66/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0133Epoch [66/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0164Epoch [66/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0059Epoch [66/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0413Epoch [66/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0013Epoch [66/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0047Epoch [66/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0876Epoch [66/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2408Epoch [66/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0587Epoch [66/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0038Epoch [66/124], Batch [52/125] [########------------] 41.6%, Loss: 0.2159Epoch [66/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0111Epoch [66/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0046Epoch [66/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0022Epoch [66/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0073Epoch [66/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0003Epoch [66/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0062Epoch [66/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0152Epoch [66/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0088Epoch [66/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0055Epoch [66/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0003Epoch [66/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0098Epoch [66/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0124Epoch [66/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0030Epoch [66/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2234Epoch [66/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0258Epoch [66/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0045Epoch [66/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1390Epoch [66/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0015Epoch [66/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0076Epoch [66/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0391Epoch [66/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0205Epoch [66/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0896Epoch [66/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0032Epoch [66/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0051Epoch [66/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0192Epoch [66/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0184Epoch [66/124], Batch [79/125] [############--------] 63.2%, Loss: 0.7653Epoch [66/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0089Epoch [66/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0149Epoch [66/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0005Epoch [66/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0082Epoch [66/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0087Epoch [66/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0050Epoch [66/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0054Epoch [66/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.2666Epoch [66/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0131Epoch [66/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0050Epoch [66/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0230Epoch [66/124], Batch [91/125] [##############------] 72.8%, Loss: 0.5834Epoch [66/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0009Epoch [66/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0012Epoch [66/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1633Epoch [66/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0005Epoch [66/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0013Epoch [66/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1686Epoch [66/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0086Epoch [66/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0251Epoch [66/124], Batch [100/125] [################----] 80.0%, Loss: 0.0011Epoch [66/124], Batch [101/125] [################----] 80.8%, Loss: 0.0035Epoch [66/124], Batch [102/125] [################----] 81.6%, Loss: 0.0046Epoch [66/124], Batch [103/125] [################----] 82.4%, Loss: 0.0077Epoch [66/124], Batch [104/125] [################----] 83.2%, Loss: 0.0110Epoch [66/124], Batch [105/125] [################----] 84.0%, Loss: 0.0663Epoch [66/124], Batch [106/125] [################----] 84.8%, Loss: 0.0147Epoch [66/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0015Epoch [66/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0142Epoch [66/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0198Epoch [66/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0666Epoch [66/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0244Epoch [66/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0028Epoch [66/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0037Epoch [66/124], Batch [114/125] [##################--] 91.2%, Loss: 1.3353Epoch [66/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0758Epoch [66/124], Batch [116/125] [##################--] 92.8%, Loss: 0.2755Epoch [66/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0015Epoch [66/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0491Epoch [66/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0058Epoch [66/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0132Epoch [66/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0042Epoch [66/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0003Epoch [66/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0238Epoch [66/124], Batch [124/125] [###################-] 99.2%, Loss: 0.2312Epoch [66/124], Batch [125/125] [####################] 100.0%, Loss: 0.0056
Epoch [66/124] finished. Average Loss: 0.0731
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 66 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [67/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0864Epoch [67/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0333Epoch [67/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0640Epoch [67/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0041Epoch [67/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0436Epoch [67/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0077Epoch [67/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0027Epoch [67/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0013Epoch [67/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0258Epoch [67/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0256Epoch [67/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0049Epoch [67/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0279Epoch [67/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0010Epoch [67/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0146Epoch [67/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0028Epoch [67/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0042Epoch [67/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1567Epoch [67/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0501Epoch [67/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0003Epoch [67/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0019Epoch [67/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0022Epoch [67/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0088Epoch [67/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0032Epoch [67/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0488Epoch [67/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0062Epoch [67/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0155Epoch [67/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0048Epoch [67/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0698Epoch [67/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0096Epoch [67/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0007Epoch [67/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0429Epoch [67/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0749Epoch [67/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0007Epoch [67/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0068Epoch [67/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0999Epoch [67/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0002Epoch [67/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0794Epoch [67/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.1047Epoch [67/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0217Epoch [67/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0026Epoch [67/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0166Epoch [67/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0019Epoch [67/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0069Epoch [67/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0043Epoch [67/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0001Epoch [67/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0014Epoch [67/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0014Epoch [67/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0002Epoch [67/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0245Epoch [67/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0258Epoch [67/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0796Epoch [67/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0011Epoch [67/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0001Epoch [67/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0987Epoch [67/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0186Epoch [67/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0101Epoch [67/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0789Epoch [67/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0070Epoch [67/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0007Epoch [67/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0032Epoch [67/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0013Epoch [67/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0003Epoch [67/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0007Epoch [67/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0005Epoch [67/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0072Epoch [67/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1802Epoch [67/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0099Epoch [67/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1182Epoch [67/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0001Epoch [67/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0058Epoch [67/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0081Epoch [67/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0017Epoch [67/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.6826Epoch [67/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0035Epoch [67/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0046Epoch [67/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0004Epoch [67/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0110Epoch [67/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0292Epoch [67/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1441Epoch [67/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0885Epoch [67/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0039Epoch [67/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0041Epoch [67/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0025Epoch [67/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0003Epoch [67/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0008Epoch [67/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0002Epoch [67/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0009Epoch [67/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0402Epoch [67/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0008Epoch [67/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0083Epoch [67/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0010Epoch [67/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0132Epoch [67/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0082Epoch [67/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0007Epoch [67/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0964Epoch [67/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0046Epoch [67/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0179Epoch [67/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0139Epoch [67/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0068Epoch [67/124], Batch [100/125] [################----] 80.0%, Loss: 0.2112Epoch [67/124], Batch [101/125] [################----] 80.8%, Loss: 0.0010Epoch [67/124], Batch [102/125] [################----] 81.6%, Loss: 0.0072Epoch [67/124], Batch [103/125] [################----] 82.4%, Loss: 0.2205Epoch [67/124], Batch [104/125] [################----] 83.2%, Loss: 0.3337Epoch [67/124], Batch [105/125] [################----] 84.0%, Loss: 0.0030Epoch [67/124], Batch [106/125] [################----] 84.8%, Loss: 0.0819Epoch [67/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0003Epoch [67/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0630Epoch [67/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0053Epoch [67/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0002Epoch [67/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0020Epoch [67/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1236Epoch [67/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0016Epoch [67/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0008Epoch [67/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0012Epoch [67/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0136Epoch [67/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0023Epoch [67/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0544Epoch [67/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0261Epoch [67/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0004Epoch [67/124], Batch [121/125] [###################-] 96.8%, Loss: 0.7446Epoch [67/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0183Epoch [67/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0039Epoch [67/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0164Epoch [67/124], Batch [125/125] [####################] 100.0%, Loss: 0.0033
Epoch [67/124] finished. Average Loss: 0.0400
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 67 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [68/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0061Epoch [68/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0058Epoch [68/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0001Epoch [68/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0266Epoch [68/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0004Epoch [68/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0004Epoch [68/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.4952Epoch [68/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0001Epoch [68/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0003Epoch [68/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0362Epoch [68/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0002Epoch [68/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0112Epoch [68/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2143Epoch [68/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0007Epoch [68/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0359Epoch [68/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0620Epoch [68/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0006Epoch [68/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0106Epoch [68/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0037Epoch [68/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0032Epoch [68/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0032Epoch [68/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0039Epoch [68/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1117Epoch [68/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0042Epoch [68/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0779Epoch [68/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0647Epoch [68/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0002Epoch [68/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0078Epoch [68/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0436Epoch [68/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0047Epoch [68/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0017Epoch [68/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0001Epoch [68/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0024Epoch [68/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0007Epoch [68/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0048Epoch [68/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0007Epoch [68/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1486Epoch [68/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.5143Epoch [68/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0004Epoch [68/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0003Epoch [68/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0217Epoch [68/124], Batch [42/125] [######--------------] 33.6%, Loss: 2.0631Epoch [68/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0176Epoch [68/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0009Epoch [68/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0377Epoch [68/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.3570Epoch [68/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1856Epoch [68/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0007Epoch [68/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0128Epoch [68/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1782Epoch [68/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0125Epoch [68/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0007Epoch [68/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0070Epoch [68/124], Batch [54/125] [########------------] 43.2%, Loss: 0.4322Epoch [68/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0207Epoch [68/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0004Epoch [68/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0643Epoch [68/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0225Epoch [68/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0061Epoch [68/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1272Epoch [68/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0040Epoch [68/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0041Epoch [68/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0084Epoch [68/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0015Epoch [68/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0001Epoch [68/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0445Epoch [68/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0104Epoch [68/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0032Epoch [68/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0059Epoch [68/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0242Epoch [68/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0031Epoch [68/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0077Epoch [68/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.3926Epoch [68/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0051Epoch [68/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0006Epoch [68/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0000Epoch [68/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0041Epoch [68/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0560Epoch [68/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0029Epoch [68/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0039Epoch [68/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0048Epoch [68/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0671Epoch [68/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0003Epoch [68/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.2439Epoch [68/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0025Epoch [68/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0592Epoch [68/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0004Epoch [68/124], Batch [88/125] [##############------] 70.4%, Loss: 0.2155Epoch [68/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0471Epoch [68/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0002Epoch [68/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0036Epoch [68/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0008Epoch [68/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0493Epoch [68/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0937Epoch [68/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0058Epoch [68/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0321Epoch [68/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0321Epoch [68/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0016Epoch [68/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0530Epoch [68/124], Batch [100/125] [################----] 80.0%, Loss: 0.0028Epoch [68/124], Batch [101/125] [################----] 80.8%, Loss: 0.3688Epoch [68/124], Batch [102/125] [################----] 81.6%, Loss: 0.0249Epoch [68/124], Batch [103/125] [################----] 82.4%, Loss: 1.0835Epoch [68/124], Batch [104/125] [################----] 83.2%, Loss: 0.0003Epoch [68/124], Batch [105/125] [################----] 84.0%, Loss: 0.0097Epoch [68/124], Batch [106/125] [################----] 84.8%, Loss: 0.0178Epoch [68/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0026Epoch [68/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0064Epoch [68/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0210Epoch [68/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0016Epoch [68/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0095Epoch [68/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0007Epoch [68/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0977Epoch [68/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2558Epoch [68/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0032Epoch [68/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0215Epoch [68/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0002Epoch [68/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0044Epoch [68/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0010Epoch [68/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0038Epoch [68/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0012Epoch [68/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0017Epoch [68/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0377Epoch [68/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0485Epoch [68/124], Batch [125/125] [####################] 100.0%, Loss: 0.1394
Epoch [68/124] finished. Average Loss: 0.0731
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 68 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [69/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0000Epoch [69/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0020Epoch [69/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0008Epoch [69/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.2837Epoch [69/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0020Epoch [69/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0020Epoch [69/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0096Epoch [69/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1046Epoch [69/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0025Epoch [69/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0010Epoch [69/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0104Epoch [69/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0002Epoch [69/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0017Epoch [69/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0112Epoch [69/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0007Epoch [69/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0870Epoch [69/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0555Epoch [69/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0041Epoch [69/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0260Epoch [69/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0001Epoch [69/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0008Epoch [69/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0502Epoch [69/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0051Epoch [69/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0347Epoch [69/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0046Epoch [69/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0085Epoch [69/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0003Epoch [69/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0027Epoch [69/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.4351Epoch [69/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0056Epoch [69/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.2227Epoch [69/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0027Epoch [69/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1540Epoch [69/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0009Epoch [69/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.1198Epoch [69/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0017Epoch [69/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0098Epoch [69/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0216Epoch [69/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0014Epoch [69/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0105Epoch [69/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2203Epoch [69/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1888Epoch [69/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0045Epoch [69/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0235Epoch [69/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0165Epoch [69/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0002Epoch [69/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0047Epoch [69/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0010Epoch [69/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0003Epoch [69/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0026Epoch [69/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1961Epoch [69/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0076Epoch [69/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0005Epoch [69/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0006Epoch [69/124], Batch [55/125] [########------------] 44.0%, Loss: 0.1850Epoch [69/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0035Epoch [69/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0019Epoch [69/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0164Epoch [69/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0981Epoch [69/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0067Epoch [69/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0004Epoch [69/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0044Epoch [69/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0406Epoch [69/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0264Epoch [69/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0005Epoch [69/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.7396Epoch [69/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0056Epoch [69/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0007Epoch [69/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0946Epoch [69/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0408Epoch [69/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0928Epoch [69/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0016Epoch [69/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0207Epoch [69/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0097Epoch [69/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0012Epoch [69/124], Batch [76/125] [############--------] 60.8%, Loss: 0.5133Epoch [69/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0002Epoch [69/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0006Epoch [69/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0020Epoch [69/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0013Epoch [69/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0008Epoch [69/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0081Epoch [69/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0027Epoch [69/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0130Epoch [69/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1837Epoch [69/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0003Epoch [69/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0002Epoch [69/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0008Epoch [69/124], Batch [89/125] [##############------] 71.2%, Loss: 0.1655Epoch [69/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0046Epoch [69/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1589Epoch [69/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1490Epoch [69/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0002Epoch [69/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0090Epoch [69/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0044Epoch [69/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0392Epoch [69/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0959Epoch [69/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0004Epoch [69/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0671Epoch [69/124], Batch [100/125] [################----] 80.0%, Loss: 0.0288Epoch [69/124], Batch [101/125] [################----] 80.8%, Loss: 0.0014Epoch [69/124], Batch [102/125] [################----] 81.6%, Loss: 0.0047Epoch [69/124], Batch [103/125] [################----] 82.4%, Loss: 0.0059Epoch [69/124], Batch [104/125] [################----] 83.2%, Loss: 0.0430Epoch [69/124], Batch [105/125] [################----] 84.0%, Loss: 0.0030Epoch [69/124], Batch [106/125] [################----] 84.8%, Loss: 0.5633Epoch [69/124], Batch [107/125] [#################---] 85.6%, Loss: 0.6367Epoch [69/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1203Epoch [69/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0018Epoch [69/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0022Epoch [69/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0016Epoch [69/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1098Epoch [69/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0057Epoch [69/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0600Epoch [69/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2655Epoch [69/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0155Epoch [69/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0024Epoch [69/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0227Epoch [69/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0025Epoch [69/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0028Epoch [69/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0011Epoch [69/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0047Epoch [69/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0093Epoch [69/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0860Epoch [69/124], Batch [125/125] [####################] 100.0%, Loss: 0.0013
Epoch [69/124] finished. Average Loss: 0.0574
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 69 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [70/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0116Epoch [70/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0474Epoch [70/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0608Epoch [70/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0682Epoch [70/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0323Epoch [70/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0041Epoch [70/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.2949Epoch [70/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0040Epoch [70/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0084Epoch [70/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0041Epoch [70/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0091Epoch [70/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0068Epoch [70/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0287Epoch [70/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0172Epoch [70/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0024Epoch [70/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0162Epoch [70/124], Batch [17/125] [##------------------] 13.6%, Loss: 1.2482Epoch [70/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0018Epoch [70/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0031Epoch [70/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0091Epoch [70/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1167Epoch [70/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0039Epoch [70/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0549Epoch [70/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0008Epoch [70/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.5668Epoch [70/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0006Epoch [70/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0009Epoch [70/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0004Epoch [70/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2230Epoch [70/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0067Epoch [70/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0195Epoch [70/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0025Epoch [70/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0095Epoch [70/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0188Epoch [70/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0201Epoch [70/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0543Epoch [70/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0125Epoch [70/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0110Epoch [70/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0516Epoch [70/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0042Epoch [70/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0043Epoch [70/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1879Epoch [70/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0442Epoch [70/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.4716Epoch [70/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.2034Epoch [70/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.2304Epoch [70/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0039Epoch [70/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0029Epoch [70/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0123Epoch [70/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0837Epoch [70/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0001Epoch [70/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0604Epoch [70/124], Batch [53/125] [########------------] 42.4%, Loss: 0.7457Epoch [70/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0081Epoch [70/124], Batch [55/125] [########------------] 44.0%, Loss: 0.6283Epoch [70/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0113Epoch [70/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0193Epoch [70/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0002Epoch [70/124], Batch [59/125] [#########-----------] 47.2%, Loss: 1.4336Epoch [70/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0300Epoch [70/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0039Epoch [70/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0014Epoch [70/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1021Epoch [70/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0001Epoch [70/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0444Epoch [70/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2451Epoch [70/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0092Epoch [70/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1195Epoch [70/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1863Epoch [70/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.4581Epoch [70/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0126Epoch [70/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0124Epoch [70/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0331Epoch [70/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0021Epoch [70/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0055Epoch [70/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0013Epoch [70/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0090Epoch [70/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0029Epoch [70/124], Batch [79/125] [############--------] 63.2%, Loss: 0.4771Epoch [70/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1343Epoch [70/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0191Epoch [70/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1378Epoch [70/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1500Epoch [70/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0168Epoch [70/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0013Epoch [70/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.5267Epoch [70/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1144Epoch [70/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1274Epoch [70/124], Batch [89/125] [##############------] 71.2%, Loss: 1.2818Epoch [70/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1090Epoch [70/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0089Epoch [70/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4623Epoch [70/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0377Epoch [70/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0106Epoch [70/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0324Epoch [70/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0025Epoch [70/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0556Epoch [70/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0219Epoch [70/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0019Epoch [70/124], Batch [100/125] [################----] 80.0%, Loss: 0.0717Epoch [70/124], Batch [101/125] [################----] 80.8%, Loss: 0.0140Epoch [70/124], Batch [102/125] [################----] 81.6%, Loss: 0.4785Epoch [70/124], Batch [103/125] [################----] 82.4%, Loss: 0.5789Epoch [70/124], Batch [104/125] [################----] 83.2%, Loss: 0.6919Epoch [70/124], Batch [105/125] [################----] 84.0%, Loss: 0.3639Epoch [70/124], Batch [106/125] [################----] 84.8%, Loss: 0.0119Epoch [70/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0253Epoch [70/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0016Epoch [70/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0070Epoch [70/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0017Epoch [70/124], Batch [111/125] [#################---] 88.8%, Loss: 0.2342Epoch [70/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0041Epoch [70/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0825Epoch [70/124], Batch [114/125] [##################--] 91.2%, Loss: 0.5818Epoch [70/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0974Epoch [70/124], Batch [116/125] [##################--] 92.8%, Loss: 0.2616Epoch [70/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1107Epoch [70/124], Batch [118/125] [##################--] 94.4%, Loss: 0.3918Epoch [70/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0014Epoch [70/124], Batch [120/125] [###################-] 96.0%, Loss: 2.2412Epoch [70/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0163Epoch [70/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0959Epoch [70/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0831Epoch [70/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0140Epoch [70/124], Batch [125/125] [####################] 100.0%, Loss: 0.0328
Epoch [70/124] finished. Average Loss: 0.1497
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 70 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [71/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.4426Epoch [71/124], Batch [2/125] [--------------------] 1.6%, Loss: 1.3782Epoch [71/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0105Epoch [71/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0002Epoch [71/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0027Epoch [71/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0028Epoch [71/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.2307Epoch [71/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1915Epoch [71/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0597Epoch [71/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.1221Epoch [71/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0191Epoch [71/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0073Epoch [71/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2387Epoch [71/124], Batch [14/125] [##------------------] 11.2%, Loss: 1.0798Epoch [71/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0111Epoch [71/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.4074Epoch [71/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.8697Epoch [71/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0578Epoch [71/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0253Epoch [71/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0579Epoch [71/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.1097Epoch [71/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0522Epoch [71/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0158Epoch [71/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1912Epoch [71/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0039Epoch [71/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0007Epoch [71/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0120Epoch [71/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0041Epoch [71/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0532Epoch [71/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0966Epoch [71/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0037Epoch [71/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0135Epoch [71/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.4433Epoch [71/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1168Epoch [71/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0012Epoch [71/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0077Epoch [71/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.5402Epoch [71/124], Batch [38/125] [######--------------] 30.4%, Loss: 1.0630Epoch [71/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0091Epoch [71/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0200Epoch [71/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.2628Epoch [71/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0178Epoch [71/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.4035Epoch [71/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0178Epoch [71/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.3508Epoch [71/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.2317Epoch [71/124], Batch [47/125] [#######-------------] 37.6%, Loss: 1.0287Epoch [71/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0052Epoch [71/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.3528Epoch [71/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0344Epoch [71/124], Batch [51/125] [########------------] 40.8%, Loss: 0.5401Epoch [71/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0494Epoch [71/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0732Epoch [71/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1116Epoch [71/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0477Epoch [71/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1583Epoch [71/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.5228Epoch [71/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0060Epoch [71/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.7245Epoch [71/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0707Epoch [71/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0027Epoch [71/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.2660Epoch [71/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1043Epoch [71/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0185Epoch [71/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0279Epoch [71/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0152Epoch [71/124], Batch [67/125] [##########----------] 53.6%, Loss: 1.4007Epoch [71/124], Batch [68/125] [##########----------] 54.4%, Loss: 1.3225Epoch [71/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0103Epoch [71/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.2954Epoch [71/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.2940Epoch [71/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1848Epoch [71/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.4952Epoch [71/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.6209Epoch [71/124], Batch [75/125] [############--------] 60.0%, Loss: 0.1379Epoch [71/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0531Epoch [71/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1331Epoch [71/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1852Epoch [71/124], Batch [79/125] [############--------] 63.2%, Loss: 0.2884Epoch [71/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0296Epoch [71/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0607Epoch [71/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0293Epoch [71/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0010Epoch [71/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0171Epoch [71/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0719Epoch [71/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1333Epoch [71/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1106Epoch [71/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0601Epoch [71/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2703Epoch [71/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0302Epoch [71/124], Batch [91/125] [##############------] 72.8%, Loss: 0.4897Epoch [71/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0059Epoch [71/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0398Epoch [71/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.4461Epoch [71/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0742Epoch [71/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0025Epoch [71/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0214Epoch [71/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.7434Epoch [71/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0243Epoch [71/124], Batch [100/125] [################----] 80.0%, Loss: 0.0160Epoch [71/124], Batch [101/125] [################----] 80.8%, Loss: 0.0390Epoch [71/124], Batch [102/125] [################----] 81.6%, Loss: 0.1874Epoch [71/124], Batch [103/125] [################----] 82.4%, Loss: 0.1017Epoch [71/124], Batch [104/125] [################----] 83.2%, Loss: 0.7297Epoch [71/124], Batch [105/125] [################----] 84.0%, Loss: 0.0130Epoch [71/124], Batch [106/125] [################----] 84.8%, Loss: 1.3125Epoch [71/124], Batch [107/125] [#################---] 85.6%, Loss: 0.5861Epoch [71/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0655Epoch [71/124], Batch [109/125] [#################---] 87.2%, Loss: 0.3381Epoch [71/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0130Epoch [71/124], Batch [111/125] [#################---] 88.8%, Loss: 1.1227Epoch [71/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1736Epoch [71/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1774Epoch [71/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0014Epoch [71/124], Batch [115/125] [##################--] 92.0%, Loss: 0.3737Epoch [71/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0998Epoch [71/124], Batch [117/125] [##################--] 93.6%, Loss: 1.2685Epoch [71/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1286Epoch [71/124], Batch [119/125] [###################-] 95.2%, Loss: 0.6035Epoch [71/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0231Epoch [71/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0685Epoch [71/124], Batch [122/125] [###################-] 97.6%, Loss: 0.1383Epoch [71/124], Batch [123/125] [###################-] 98.4%, Loss: 2.7844Epoch [71/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0472Epoch [71/124], Batch [125/125] [####################] 100.0%, Loss: 0.7262
Epoch [71/124] finished. Average Loss: 0.2691
Training Accuracy: 96.20%
--- Saving checkpoint for epoch 71 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [72/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0056Epoch [72/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0111Epoch [72/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0067Epoch [72/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.5979Epoch [72/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1556Epoch [72/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.8200Epoch [72/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0243Epoch [72/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.1857Epoch [72/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0773Epoch [72/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0103Epoch [72/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0162Epoch [72/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0074Epoch [72/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.6319Epoch [72/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.2467Epoch [72/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.3958Epoch [72/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.3486Epoch [72/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0291Epoch [72/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0099Epoch [72/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.5404Epoch [72/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0018Epoch [72/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0858Epoch [72/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0204Epoch [72/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0519Epoch [72/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1071Epoch [72/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0313Epoch [72/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.2993Epoch [72/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.5277Epoch [72/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0236Epoch [72/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0026Epoch [72/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.8261Epoch [72/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0121Epoch [72/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0147Epoch [72/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1499Epoch [72/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.2898Epoch [72/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0032Epoch [72/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0603Epoch [72/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0105Epoch [72/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0086Epoch [72/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.7003Epoch [72/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0269Epoch [72/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0025Epoch [72/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0066Epoch [72/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.3893Epoch [72/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0033Epoch [72/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1235Epoch [72/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0087Epoch [72/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0100Epoch [72/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.4208Epoch [72/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0320Epoch [72/124], Batch [50/125] [########------------] 40.0%, Loss: 1.2297Epoch [72/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0409Epoch [72/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0136Epoch [72/124], Batch [53/125] [########------------] 42.4%, Loss: 0.4427Epoch [72/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0715Epoch [72/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0343Epoch [72/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0037Epoch [72/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0090Epoch [72/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0315Epoch [72/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0268Epoch [72/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0062Epoch [72/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0156Epoch [72/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0348Epoch [72/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0640Epoch [72/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0042Epoch [72/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0618Epoch [72/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.3923Epoch [72/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0261Epoch [72/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0221Epoch [72/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0329Epoch [72/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0052Epoch [72/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0062Epoch [72/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.2943Epoch [72/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.3148Epoch [72/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1584Epoch [72/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0260Epoch [72/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1971Epoch [72/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0354Epoch [72/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1224Epoch [72/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0286Epoch [72/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0023Epoch [72/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0025Epoch [72/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0007Epoch [72/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0036Epoch [72/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0019Epoch [72/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.9047Epoch [72/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.3218Epoch [72/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1264Epoch [72/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1912Epoch [72/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0611Epoch [72/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0615Epoch [72/124], Batch [91/125] [##############------] 72.8%, Loss: 0.2193Epoch [72/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0701Epoch [72/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0392Epoch [72/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0277Epoch [72/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0092Epoch [72/124], Batch [96/125] [###############-----] 76.8%, Loss: 1.1255Epoch [72/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1742Epoch [72/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0420Epoch [72/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0021Epoch [72/124], Batch [100/125] [################----] 80.0%, Loss: 0.0799Epoch [72/124], Batch [101/125] [################----] 80.8%, Loss: 0.0039Epoch [72/124], Batch [102/125] [################----] 81.6%, Loss: 0.0468Epoch [72/124], Batch [103/125] [################----] 82.4%, Loss: 0.0568Epoch [72/124], Batch [104/125] [################----] 83.2%, Loss: 0.0084Epoch [72/124], Batch [105/125] [################----] 84.0%, Loss: 0.3811Epoch [72/124], Batch [106/125] [################----] 84.8%, Loss: 0.0057Epoch [72/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0098Epoch [72/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0651Epoch [72/124], Batch [109/125] [#################---] 87.2%, Loss: 0.4866Epoch [72/124], Batch [110/125] [#################---] 88.0%, Loss: 0.2997Epoch [72/124], Batch [111/125] [#################---] 88.8%, Loss: 0.3343Epoch [72/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0038Epoch [72/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0037Epoch [72/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0314Epoch [72/124], Batch [115/125] [##################--] 92.0%, Loss: 0.5901Epoch [72/124], Batch [116/125] [##################--] 92.8%, Loss: 0.6002Epoch [72/124], Batch [117/125] [##################--] 93.6%, Loss: 1.2686Epoch [72/124], Batch [118/125] [##################--] 94.4%, Loss: 0.2745Epoch [72/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0250Epoch [72/124], Batch [120/125] [###################-] 96.0%, Loss: 1.1674Epoch [72/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0497Epoch [72/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0070Epoch [72/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2558Epoch [72/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0149Epoch [72/124], Batch [125/125] [####################] 100.0%, Loss: 0.0654
Epoch [72/124] finished. Average Loss: 0.1732
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 72 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [73/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0051Epoch [73/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1864Epoch [73/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0121Epoch [73/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0015Epoch [73/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1892Epoch [73/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.1134Epoch [73/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1506Epoch [73/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0071Epoch [73/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0943Epoch [73/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0021Epoch [73/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0629Epoch [73/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0169Epoch [73/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.1629Epoch [73/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0009Epoch [73/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0758Epoch [73/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0411Epoch [73/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0206Epoch [73/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1038Epoch [73/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0736Epoch [73/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0153Epoch [73/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0003Epoch [73/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0151Epoch [73/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0027Epoch [73/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0227Epoch [73/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0005Epoch [73/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.6529Epoch [73/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.4201Epoch [73/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0018Epoch [73/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0030Epoch [73/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0166Epoch [73/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0432Epoch [73/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0013Epoch [73/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0279Epoch [73/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0423Epoch [73/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0004Epoch [73/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0328Epoch [73/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0060Epoch [73/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0464Epoch [73/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3697Epoch [73/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1929Epoch [73/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0062Epoch [73/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0207Epoch [73/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0134Epoch [73/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0051Epoch [73/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.1551Epoch [73/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0168Epoch [73/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.3498Epoch [73/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0090Epoch [73/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0057Epoch [73/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0171Epoch [73/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0034Epoch [73/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0007Epoch [73/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0012Epoch [73/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1679Epoch [73/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0000Epoch [73/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1255Epoch [73/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0536Epoch [73/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0358Epoch [73/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0170Epoch [73/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1424Epoch [73/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0494Epoch [73/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.7466Epoch [73/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1089Epoch [73/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0181Epoch [73/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0451Epoch [73/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0657Epoch [73/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0206Epoch [73/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0011Epoch [73/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1090Epoch [73/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0043Epoch [73/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.1647Epoch [73/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0050Epoch [73/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.2305Epoch [73/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0030Epoch [73/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0069Epoch [73/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0046Epoch [73/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0129Epoch [73/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0001Epoch [73/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0072Epoch [73/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0062Epoch [73/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0230Epoch [73/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.5342Epoch [73/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0043Epoch [73/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0019Epoch [73/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0033Epoch [73/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.5682Epoch [73/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0521Epoch [73/124], Batch [88/125] [##############------] 70.4%, Loss: 0.2239Epoch [73/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0358Epoch [73/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0033Epoch [73/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0256Epoch [73/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0211Epoch [73/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0038Epoch [73/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0448Epoch [73/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.9116Epoch [73/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0001Epoch [73/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1353Epoch [73/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0031Epoch [73/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.3775Epoch [73/124], Batch [100/125] [################----] 80.0%, Loss: 0.2912Epoch [73/124], Batch [101/125] [################----] 80.8%, Loss: 0.0040Epoch [73/124], Batch [102/125] [################----] 81.6%, Loss: 0.0035Epoch [73/124], Batch [103/125] [################----] 82.4%, Loss: 0.2340Epoch [73/124], Batch [104/125] [################----] 83.2%, Loss: 0.0673Epoch [73/124], Batch [105/125] [################----] 84.0%, Loss: 0.0007Epoch [73/124], Batch [106/125] [################----] 84.8%, Loss: 0.0024Epoch [73/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0020Epoch [73/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0044Epoch [73/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0121Epoch [73/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0040Epoch [73/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0549Epoch [73/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0168Epoch [73/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0106Epoch [73/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0033Epoch [73/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0061Epoch [73/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0163Epoch [73/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0330Epoch [73/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0491Epoch [73/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0072Epoch [73/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0371Epoch [73/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0048Epoch [73/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0525Epoch [73/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0026Epoch [73/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0032Epoch [73/124], Batch [125/125] [####################] 100.0%, Loss: 0.0024
Epoch [73/124] finished. Average Loss: 0.0791
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 73 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [74/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0015Epoch [74/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0069Epoch [74/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0571Epoch [74/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0001Epoch [74/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0025Epoch [74/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0002Epoch [74/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0050Epoch [74/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.3965Epoch [74/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0007Epoch [74/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0235Epoch [74/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0050Epoch [74/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0006Epoch [74/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0037Epoch [74/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [74/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0430Epoch [74/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2251Epoch [74/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.2691Epoch [74/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0008Epoch [74/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0061Epoch [74/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0043Epoch [74/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0008Epoch [74/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0027Epoch [74/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0014Epoch [74/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0056Epoch [74/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0015Epoch [74/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0345Epoch [74/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0001Epoch [74/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0207Epoch [74/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0184Epoch [74/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0165Epoch [74/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0013Epoch [74/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.1558Epoch [74/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0022Epoch [74/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.4638Epoch [74/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0620Epoch [74/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0260Epoch [74/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0034Epoch [74/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0042Epoch [74/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0098Epoch [74/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0060Epoch [74/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0048Epoch [74/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0365Epoch [74/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1338Epoch [74/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0632Epoch [74/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0016Epoch [74/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0019Epoch [74/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1368Epoch [74/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0094Epoch [74/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0020Epoch [74/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0097Epoch [74/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0017Epoch [74/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0069Epoch [74/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0113Epoch [74/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1117Epoch [74/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0008Epoch [74/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0021Epoch [74/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0619Epoch [74/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0019Epoch [74/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0250Epoch [74/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0013Epoch [74/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0018Epoch [74/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.2091Epoch [74/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0008Epoch [74/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2357Epoch [74/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0000Epoch [74/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2574Epoch [74/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0021Epoch [74/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0078Epoch [74/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0102Epoch [74/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0004Epoch [74/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0025Epoch [74/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0152Epoch [74/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0147Epoch [74/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0040Epoch [74/124], Batch [75/125] [############--------] 60.0%, Loss: 0.5190Epoch [74/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0010Epoch [74/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0003Epoch [74/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0004Epoch [74/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0008Epoch [74/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0065Epoch [74/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0086Epoch [74/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0031Epoch [74/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0042Epoch [74/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0038Epoch [74/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0426Epoch [74/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0006Epoch [74/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1167Epoch [74/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0319Epoch [74/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0039Epoch [74/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0006Epoch [74/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0231Epoch [74/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0174Epoch [74/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0082Epoch [74/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0000Epoch [74/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3071Epoch [74/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0102Epoch [74/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0498Epoch [74/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0052Epoch [74/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.6259Epoch [74/124], Batch [100/125] [################----] 80.0%, Loss: 0.0023Epoch [74/124], Batch [101/125] [################----] 80.8%, Loss: 0.0028Epoch [74/124], Batch [102/125] [################----] 81.6%, Loss: 0.0029Epoch [74/124], Batch [103/125] [################----] 82.4%, Loss: 0.0015Epoch [74/124], Batch [104/125] [################----] 83.2%, Loss: 0.0017Epoch [74/124], Batch [105/125] [################----] 84.0%, Loss: 0.0110Epoch [74/124], Batch [106/125] [################----] 84.8%, Loss: 0.0113Epoch [74/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0008Epoch [74/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0012Epoch [74/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0039Epoch [74/124], Batch [110/125] [#################---] 88.0%, Loss: 0.3402Epoch [74/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0006Epoch [74/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0115Epoch [74/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0083Epoch [74/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0253Epoch [74/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0008Epoch [74/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1516Epoch [74/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0382Epoch [74/124], Batch [118/125] [##################--] 94.4%, Loss: 0.2405Epoch [74/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0005Epoch [74/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0568Epoch [74/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0369Epoch [74/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0044Epoch [74/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0001Epoch [74/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0337Epoch [74/124], Batch [125/125] [####################] 100.0%, Loss: 0.0031
Epoch [74/124] finished. Average Loss: 0.0485
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 74 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [75/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0004Epoch [75/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0106Epoch [75/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0085Epoch [75/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0045Epoch [75/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0398Epoch [75/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0267Epoch [75/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0006Epoch [75/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0071Epoch [75/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2083Epoch [75/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0235Epoch [75/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0472Epoch [75/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0001Epoch [75/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0355Epoch [75/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0051Epoch [75/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0065Epoch [75/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0011Epoch [75/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0158Epoch [75/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0011Epoch [75/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0575Epoch [75/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0008Epoch [75/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0013Epoch [75/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0015Epoch [75/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0778Epoch [75/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0024Epoch [75/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0012Epoch [75/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0142Epoch [75/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0157Epoch [75/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0243Epoch [75/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0050Epoch [75/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1340Epoch [75/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0199Epoch [75/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0019Epoch [75/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0019Epoch [75/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0107Epoch [75/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0581Epoch [75/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0037Epoch [75/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0503Epoch [75/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0065Epoch [75/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.4685Epoch [75/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0027Epoch [75/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0021Epoch [75/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0051Epoch [75/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0338Epoch [75/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0493Epoch [75/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0035Epoch [75/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0011Epoch [75/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0011Epoch [75/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0172Epoch [75/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0001Epoch [75/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0042Epoch [75/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0012Epoch [75/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0002Epoch [75/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0211Epoch [75/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0003Epoch [75/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0077Epoch [75/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0032Epoch [75/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0020Epoch [75/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0004Epoch [75/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0025Epoch [75/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0007Epoch [75/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0006Epoch [75/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0001Epoch [75/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0911Epoch [75/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0042Epoch [75/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0010Epoch [75/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0001Epoch [75/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0008Epoch [75/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0001Epoch [75/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0029Epoch [75/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.5312Epoch [75/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0024Epoch [75/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0474Epoch [75/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0214Epoch [75/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2561Epoch [75/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0045Epoch [75/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0051Epoch [75/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0001Epoch [75/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0348Epoch [75/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0162Epoch [75/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0005Epoch [75/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0890Epoch [75/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0002Epoch [75/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0024Epoch [75/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0230Epoch [75/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0001Epoch [75/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0029Epoch [75/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0036Epoch [75/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0227Epoch [75/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0005Epoch [75/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0019Epoch [75/124], Batch [91/125] [##############------] 72.8%, Loss: 0.2742Epoch [75/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0002Epoch [75/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2115Epoch [75/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0010Epoch [75/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0013Epoch [75/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0148Epoch [75/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0256Epoch [75/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0001Epoch [75/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0085Epoch [75/124], Batch [100/125] [################----] 80.0%, Loss: 0.0004Epoch [75/124], Batch [101/125] [################----] 80.8%, Loss: 0.0066Epoch [75/124], Batch [102/125] [################----] 81.6%, Loss: 0.0217Epoch [75/124], Batch [103/125] [################----] 82.4%, Loss: 0.0192Epoch [75/124], Batch [104/125] [################----] 83.2%, Loss: 0.0016Epoch [75/124], Batch [105/125] [################----] 84.0%, Loss: 0.0055Epoch [75/124], Batch [106/125] [################----] 84.8%, Loss: 0.0007Epoch [75/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0019Epoch [75/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0013Epoch [75/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0225Epoch [75/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0383Epoch [75/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0060Epoch [75/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0095Epoch [75/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1395Epoch [75/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0092Epoch [75/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1852Epoch [75/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0008Epoch [75/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0018Epoch [75/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0001Epoch [75/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0003Epoch [75/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0005Epoch [75/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0074Epoch [75/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0032Epoch [75/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0051Epoch [75/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0002Epoch [75/124], Batch [125/125] [####################] 100.0%, Loss: 0.0079
Epoch [75/124] finished. Average Loss: 0.0301
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 75 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [76/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0008Epoch [76/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0004Epoch [76/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0038Epoch [76/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0006Epoch [76/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0012Epoch [76/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0015Epoch [76/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0027Epoch [76/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0198Epoch [76/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0004Epoch [76/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0198Epoch [76/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0090Epoch [76/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0171Epoch [76/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0088Epoch [76/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0133Epoch [76/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0207Epoch [76/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0022Epoch [76/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0041Epoch [76/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1209Epoch [76/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0044Epoch [76/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0023Epoch [76/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0061Epoch [76/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0004Epoch [76/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0001Epoch [76/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0033Epoch [76/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0021Epoch [76/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0047Epoch [76/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0069Epoch [76/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0024Epoch [76/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0957Epoch [76/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0034Epoch [76/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0169Epoch [76/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0002Epoch [76/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0097Epoch [76/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0154Epoch [76/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0011Epoch [76/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0522Epoch [76/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0003Epoch [76/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0068Epoch [76/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1449Epoch [76/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0264Epoch [76/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0011Epoch [76/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0063Epoch [76/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0003Epoch [76/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0042Epoch [76/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0048Epoch [76/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0000Epoch [76/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0030Epoch [76/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0261Epoch [76/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0024Epoch [76/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0405Epoch [76/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0029Epoch [76/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0121Epoch [76/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0024Epoch [76/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0004Epoch [76/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0003Epoch [76/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0040Epoch [76/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0007Epoch [76/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0001Epoch [76/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0001Epoch [76/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0003Epoch [76/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0661Epoch [76/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0006Epoch [76/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0006Epoch [76/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.4500Epoch [76/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0020Epoch [76/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0011Epoch [76/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0000Epoch [76/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0026Epoch [76/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0010Epoch [76/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0019Epoch [76/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0010Epoch [76/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0110Epoch [76/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.4340Epoch [76/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0018Epoch [76/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0045Epoch [76/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0041Epoch [76/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0119Epoch [76/124], Batch [78/125] [############--------] 62.4%, Loss: 0.3810Epoch [76/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0003Epoch [76/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0001Epoch [76/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0000Epoch [76/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0234Epoch [76/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0012Epoch [76/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0000Epoch [76/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0073Epoch [76/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0074Epoch [76/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0000Epoch [76/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0005Epoch [76/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0030Epoch [76/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0001Epoch [76/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0055Epoch [76/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0118Epoch [76/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0015Epoch [76/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0002Epoch [76/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0011Epoch [76/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0402Epoch [76/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0000Epoch [76/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0001Epoch [76/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0008Epoch [76/124], Batch [100/125] [################----] 80.0%, Loss: 0.1020Epoch [76/124], Batch [101/125] [################----] 80.8%, Loss: 0.0001Epoch [76/124], Batch [102/125] [################----] 81.6%, Loss: 0.0021Epoch [76/124], Batch [103/125] [################----] 82.4%, Loss: 0.0015Epoch [76/124], Batch [104/125] [################----] 83.2%, Loss: 0.0016Epoch [76/124], Batch [105/125] [################----] 84.0%, Loss: 0.0008Epoch [76/124], Batch [106/125] [################----] 84.8%, Loss: 0.0002Epoch [76/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0002Epoch [76/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0233Epoch [76/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0008Epoch [76/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0026Epoch [76/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0054Epoch [76/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0013Epoch [76/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0003Epoch [76/124], Batch [114/125] [##################--] 91.2%, Loss: 0.9855Epoch [76/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0838Epoch [76/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0111Epoch [76/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0040Epoch [76/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0910Epoch [76/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0267Epoch [76/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0050Epoch [76/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0013Epoch [76/124], Batch [122/125] [###################-] 97.6%, Loss: 0.3822Epoch [76/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0006Epoch [76/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0439Epoch [76/124], Batch [125/125] [####################] 100.0%, Loss: 0.0007
Epoch [76/124] finished. Average Loss: 0.0322
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 76 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [77/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0050Epoch [77/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0027Epoch [77/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0012Epoch [77/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0001Epoch [77/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0013Epoch [77/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0021Epoch [77/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0002Epoch [77/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0039Epoch [77/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0002Epoch [77/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0154Epoch [77/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0071Epoch [77/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0013Epoch [77/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0001Epoch [77/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0139Epoch [77/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0058Epoch [77/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2335Epoch [77/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0045Epoch [77/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0064Epoch [77/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0010Epoch [77/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0000Epoch [77/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0007Epoch [77/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0003Epoch [77/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0450Epoch [77/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0249Epoch [77/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0113Epoch [77/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0002Epoch [77/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0010Epoch [77/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0319Epoch [77/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0001Epoch [77/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0007Epoch [77/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0004Epoch [77/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0354Epoch [77/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0004Epoch [77/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0001Epoch [77/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0144Epoch [77/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0001Epoch [77/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0030Epoch [77/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0344Epoch [77/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0004Epoch [77/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0037Epoch [77/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0302Epoch [77/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0671Epoch [77/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0058Epoch [77/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0005Epoch [77/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0038Epoch [77/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0166Epoch [77/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0016Epoch [77/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0003Epoch [77/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0031Epoch [77/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0015Epoch [77/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0077Epoch [77/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0005Epoch [77/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0475Epoch [77/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0089Epoch [77/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0010Epoch [77/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0012Epoch [77/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0007Epoch [77/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0003Epoch [77/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0018Epoch [77/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1512Epoch [77/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0285Epoch [77/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0043Epoch [77/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0119Epoch [77/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0003Epoch [77/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0086Epoch [77/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0005Epoch [77/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0010Epoch [77/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0002Epoch [77/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0025Epoch [77/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0041Epoch [77/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0023Epoch [77/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0004Epoch [77/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0000Epoch [77/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1173Epoch [77/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0005Epoch [77/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0002Epoch [77/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0019Epoch [77/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0173Epoch [77/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0002Epoch [77/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0017Epoch [77/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0000Epoch [77/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0009Epoch [77/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0006Epoch [77/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0194Epoch [77/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0005Epoch [77/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0002Epoch [77/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0010Epoch [77/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0005Epoch [77/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0148Epoch [77/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0006Epoch [77/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0001Epoch [77/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0029Epoch [77/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0000Epoch [77/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.5405Epoch [77/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0043Epoch [77/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0011Epoch [77/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0008Epoch [77/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0047Epoch [77/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0489Epoch [77/124], Batch [100/125] [################----] 80.0%, Loss: 0.0020Epoch [77/124], Batch [101/125] [################----] 80.8%, Loss: 0.0077Epoch [77/124], Batch [102/125] [################----] 81.6%, Loss: 0.0367Epoch [77/124], Batch [103/125] [################----] 82.4%, Loss: 0.0026Epoch [77/124], Batch [104/125] [################----] 83.2%, Loss: 0.0003Epoch [77/124], Batch [105/125] [################----] 84.0%, Loss: 0.0231Epoch [77/124], Batch [106/125] [################----] 84.8%, Loss: 0.0019Epoch [77/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0048Epoch [77/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0024Epoch [77/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0019Epoch [77/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0001Epoch [77/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0002Epoch [77/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0046Epoch [77/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0044Epoch [77/124], Batch [114/125] [##################--] 91.2%, Loss: 0.3144Epoch [77/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0014Epoch [77/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0002Epoch [77/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0028Epoch [77/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0143Epoch [77/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0068Epoch [77/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0014Epoch [77/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0007Epoch [77/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0026Epoch [77/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0017Epoch [77/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0005Epoch [77/124], Batch [125/125] [####################] 100.0%, Loss: 0.0037
Epoch [77/124] finished. Average Loss: 0.0172
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 77 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [78/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0008Epoch [78/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.4435Epoch [78/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0004Epoch [78/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0029Epoch [78/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0002Epoch [78/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0000Epoch [78/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0009Epoch [78/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.7101Epoch [78/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0036Epoch [78/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0045Epoch [78/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0050Epoch [78/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0005Epoch [78/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0010Epoch [78/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0628Epoch [78/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0018Epoch [78/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0064Epoch [78/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0114Epoch [78/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.3534Epoch [78/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0009Epoch [78/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0004Epoch [78/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0003Epoch [78/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0140Epoch [78/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0754Epoch [78/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0003Epoch [78/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0046Epoch [78/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0002Epoch [78/124], Batch [27/125] [####----------------] 21.6%, Loss: 1.0691Epoch [78/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0165Epoch [78/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0001Epoch [78/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0008Epoch [78/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0008Epoch [78/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0440Epoch [78/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0086Epoch [78/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0069Epoch [78/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0022Epoch [78/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0000Epoch [78/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0045Epoch [78/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0005Epoch [78/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0004Epoch [78/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0068Epoch [78/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0455Epoch [78/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0010Epoch [78/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0034Epoch [78/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0027Epoch [78/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0001Epoch [78/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0259Epoch [78/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0051Epoch [78/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0010Epoch [78/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0006Epoch [78/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0676Epoch [78/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0000Epoch [78/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0014Epoch [78/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0047Epoch [78/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0353Epoch [78/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0039Epoch [78/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0051Epoch [78/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0191Epoch [78/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0184Epoch [78/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0099Epoch [78/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.2799Epoch [78/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.7847Epoch [78/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0103Epoch [78/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0405Epoch [78/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0018Epoch [78/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0028Epoch [78/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0001Epoch [78/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0095Epoch [78/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0998Epoch [78/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0324Epoch [78/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.1354Epoch [78/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0478Epoch [78/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0113Epoch [78/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0009Epoch [78/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.4994Epoch [78/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0235Epoch [78/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0013Epoch [78/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0094Epoch [78/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0052Epoch [78/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0002Epoch [78/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0112Epoch [78/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0003Epoch [78/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0039Epoch [78/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0001Epoch [78/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0769Epoch [78/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0345Epoch [78/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0036Epoch [78/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0004Epoch [78/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0233Epoch [78/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0450Epoch [78/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0250Epoch [78/124], Batch [91/125] [##############------] 72.8%, Loss: 0.1368Epoch [78/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1348Epoch [78/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0039Epoch [78/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0020Epoch [78/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0004Epoch [78/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0087Epoch [78/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0400Epoch [78/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0001Epoch [78/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0022Epoch [78/124], Batch [100/125] [################----] 80.0%, Loss: 0.0005Epoch [78/124], Batch [101/125] [################----] 80.8%, Loss: 0.3318Epoch [78/124], Batch [102/125] [################----] 81.6%, Loss: 0.0005Epoch [78/124], Batch [103/125] [################----] 82.4%, Loss: 0.0015Epoch [78/124], Batch [104/125] [################----] 83.2%, Loss: 0.0071Epoch [78/124], Batch [105/125] [################----] 84.0%, Loss: 0.1471Epoch [78/124], Batch [106/125] [################----] 84.8%, Loss: 0.1360Epoch [78/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0005Epoch [78/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0084Epoch [78/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0022Epoch [78/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0011Epoch [78/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0001Epoch [78/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0003Epoch [78/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0465Epoch [78/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0001Epoch [78/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0059Epoch [78/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0173Epoch [78/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0070Epoch [78/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0049Epoch [78/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0022Epoch [78/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1402Epoch [78/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0025Epoch [78/124], Batch [122/125] [###################-] 97.6%, Loss: 0.5318Epoch [78/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0020Epoch [78/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0011Epoch [78/124], Batch [125/125] [####################] 100.0%, Loss: 0.9956
Epoch [78/124] finished. Average Loss: 0.0645
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 78 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [79/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0244Epoch [79/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0017Epoch [79/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0307Epoch [79/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0189Epoch [79/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0069Epoch [79/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0012Epoch [79/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0000Epoch [79/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0062Epoch [79/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0002Epoch [79/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0042Epoch [79/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0001Epoch [79/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0645Epoch [79/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0027Epoch [79/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0002Epoch [79/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0007Epoch [79/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0100Epoch [79/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0634Epoch [79/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0003Epoch [79/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0064Epoch [79/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0024Epoch [79/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0204Epoch [79/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.1439Epoch [79/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0204Epoch [79/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0004Epoch [79/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0000Epoch [79/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0051Epoch [79/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0021Epoch [79/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0005Epoch [79/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0511Epoch [79/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0009Epoch [79/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0001Epoch [79/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2383Epoch [79/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0085Epoch [79/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0010Epoch [79/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0013Epoch [79/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0051Epoch [79/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0000Epoch [79/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0004Epoch [79/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0023Epoch [79/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0012Epoch [79/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0839Epoch [79/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0907Epoch [79/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0034Epoch [79/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0055Epoch [79/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0005Epoch [79/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0238Epoch [79/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0033Epoch [79/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0005Epoch [79/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0003Epoch [79/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0005Epoch [79/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0140Epoch [79/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0015Epoch [79/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0005Epoch [79/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0001Epoch [79/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0034Epoch [79/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0004Epoch [79/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0025Epoch [79/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0217Epoch [79/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0017Epoch [79/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0014Epoch [79/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0034Epoch [79/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0000Epoch [79/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0006Epoch [79/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0007Epoch [79/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1376Epoch [79/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0011Epoch [79/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0008Epoch [79/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0035Epoch [79/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0027Epoch [79/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0105Epoch [79/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0001Epoch [79/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0018Epoch [79/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0193Epoch [79/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0028Epoch [79/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0017Epoch [79/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0014Epoch [79/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0015Epoch [79/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0001Epoch [79/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0522Epoch [79/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0166Epoch [79/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0001Epoch [79/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0126Epoch [79/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0003Epoch [79/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0002Epoch [79/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0001Epoch [79/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0038Epoch [79/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0027Epoch [79/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0036Epoch [79/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0007Epoch [79/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0171Epoch [79/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0590Epoch [79/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0019Epoch [79/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0009Epoch [79/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0015Epoch [79/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0243Epoch [79/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1290Epoch [79/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0037Epoch [79/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0150Epoch [79/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0002Epoch [79/124], Batch [100/125] [################----] 80.0%, Loss: 0.1170Epoch [79/124], Batch [101/125] [################----] 80.8%, Loss: 0.2894Epoch [79/124], Batch [102/125] [################----] 81.6%, Loss: 0.0028Epoch [79/124], Batch [103/125] [################----] 82.4%, Loss: 0.0004Epoch [79/124], Batch [104/125] [################----] 83.2%, Loss: 0.0244Epoch [79/124], Batch [105/125] [################----] 84.0%, Loss: 0.0044Epoch [79/124], Batch [106/125] [################----] 84.8%, Loss: 0.0003Epoch [79/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0106Epoch [79/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0024Epoch [79/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0045Epoch [79/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0106Epoch [79/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0383Epoch [79/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0348Epoch [79/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0055Epoch [79/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0064Epoch [79/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0426Epoch [79/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0001Epoch [79/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0061Epoch [79/124], Batch [118/125] [##################--] 94.4%, Loss: 0.7566Epoch [79/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0007Epoch [79/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1532Epoch [79/124], Batch [121/125] [###################-] 96.8%, Loss: 0.2660Epoch [79/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0007Epoch [79/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0012Epoch [79/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0030Epoch [79/124], Batch [125/125] [####################] 100.0%, Loss: 0.0010
Epoch [79/124] finished. Average Loss: 0.0266
Training Accuracy: 99.40%
--- Saving checkpoint for epoch 79 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [80/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0470Epoch [80/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0048Epoch [80/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0001Epoch [80/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0001Epoch [80/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.4614Epoch [80/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0001Epoch [80/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0024Epoch [80/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0011Epoch [80/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.3257Epoch [80/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0024Epoch [80/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0115Epoch [80/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0089Epoch [80/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0013Epoch [80/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0136Epoch [80/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0005Epoch [80/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0132Epoch [80/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3338Epoch [80/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.3852Epoch [80/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0163Epoch [80/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0276Epoch [80/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0003Epoch [80/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0659Epoch [80/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0033Epoch [80/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0039Epoch [80/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0609Epoch [80/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0002Epoch [80/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0017Epoch [80/124], Batch [28/125] [####----------------] 22.4%, Loss: 1.5318Epoch [80/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0071Epoch [80/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0361Epoch [80/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0055Epoch [80/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0697Epoch [80/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.3417Epoch [80/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0003Epoch [80/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0001Epoch [80/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0008Epoch [80/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0180Epoch [80/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0000Epoch [80/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.5229Epoch [80/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0151Epoch [80/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0006Epoch [80/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0019Epoch [80/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0011Epoch [80/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0523Epoch [80/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0473Epoch [80/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.5691Epoch [80/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0046Epoch [80/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0061Epoch [80/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0036Epoch [80/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0004Epoch [80/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0003Epoch [80/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0007Epoch [80/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0017Epoch [80/124], Batch [54/125] [########------------] 43.2%, Loss: 0.4766Epoch [80/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0028Epoch [80/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0264Epoch [80/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0026Epoch [80/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0006Epoch [80/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2976Epoch [80/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0035Epoch [80/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0063Epoch [80/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0048Epoch [80/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0386Epoch [80/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0002Epoch [80/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1673Epoch [80/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0887Epoch [80/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0017Epoch [80/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.3623Epoch [80/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0089Epoch [80/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0301Epoch [80/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0014Epoch [80/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0001Epoch [80/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0079Epoch [80/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0067Epoch [80/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0437Epoch [80/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0213Epoch [80/124], Batch [77/125] [############--------] 61.6%, Loss: 0.4119Epoch [80/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0009Epoch [80/124], Batch [79/125] [############--------] 63.2%, Loss: 0.5648Epoch [80/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0021Epoch [80/124], Batch [81/125] [############--------] 64.8%, Loss: 0.7346Epoch [80/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0230Epoch [80/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0102Epoch [80/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0011Epoch [80/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0118Epoch [80/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1058Epoch [80/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0124Epoch [80/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0052Epoch [80/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0354Epoch [80/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0003Epoch [80/124], Batch [91/125] [##############------] 72.8%, Loss: 0.3333Epoch [80/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0013Epoch [80/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1231Epoch [80/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0389Epoch [80/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.1194Epoch [80/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0042Epoch [80/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.2428Epoch [80/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0115Epoch [80/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0874Epoch [80/124], Batch [100/125] [################----] 80.0%, Loss: 0.2002Epoch [80/124], Batch [101/125] [################----] 80.8%, Loss: 0.0125Epoch [80/124], Batch [102/125] [################----] 81.6%, Loss: 0.0975Epoch [80/124], Batch [103/125] [################----] 82.4%, Loss: 0.0048Epoch [80/124], Batch [104/125] [################----] 83.2%, Loss: 0.0221Epoch [80/124], Batch [105/125] [################----] 84.0%, Loss: 0.0047Epoch [80/124], Batch [106/125] [################----] 84.8%, Loss: 0.0438Epoch [80/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0026Epoch [80/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0100Epoch [80/124], Batch [109/125] [#################---] 87.2%, Loss: 2.3864Epoch [80/124], Batch [110/125] [#################---] 88.0%, Loss: 0.3854Epoch [80/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0008Epoch [80/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0364Epoch [80/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0005Epoch [80/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0225Epoch [80/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0152Epoch [80/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0046Epoch [80/124], Batch [117/125] [##################--] 93.6%, Loss: 0.5088Epoch [80/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0016Epoch [80/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0090Epoch [80/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0953Epoch [80/124], Batch [121/125] [###################-] 96.8%, Loss: 0.3574Epoch [80/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0039Epoch [80/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0058Epoch [80/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0017Epoch [80/124], Batch [125/125] [####################] 100.0%, Loss: 0.0014
Epoch [80/124] finished. Average Loss: 0.1100
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 80 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [81/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0334Epoch [81/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0172Epoch [81/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.4711Epoch [81/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0096Epoch [81/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0412Epoch [81/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0497Epoch [81/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0021Epoch [81/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0066Epoch [81/124], Batch [9/125] [#-------------------] 7.2%, Loss: 1.4543Epoch [81/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0660Epoch [81/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0006Epoch [81/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0457Epoch [81/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0172Epoch [81/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0395Epoch [81/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0024Epoch [81/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0087Epoch [81/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.4168Epoch [81/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0008Epoch [81/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0191Epoch [81/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0508Epoch [81/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0027Epoch [81/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0171Epoch [81/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.4215Epoch [81/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0328Epoch [81/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0402Epoch [81/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0072Epoch [81/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0698Epoch [81/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0699Epoch [81/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0085Epoch [81/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1013Epoch [81/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0306Epoch [81/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0010Epoch [81/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0031Epoch [81/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0007Epoch [81/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0042Epoch [81/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0194Epoch [81/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0481Epoch [81/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.3291Epoch [81/124], Batch [39/125] [######--------------] 31.2%, Loss: 1.0152Epoch [81/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0042Epoch [81/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0228Epoch [81/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0943Epoch [81/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.5179Epoch [81/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.5087Epoch [81/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0047Epoch [81/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0076Epoch [81/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0867Epoch [81/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0364Epoch [81/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0034Epoch [81/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0254Epoch [81/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0423Epoch [81/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0673Epoch [81/124], Batch [53/125] [########------------] 42.4%, Loss: 0.1812Epoch [81/124], Batch [54/125] [########------------] 43.2%, Loss: 0.4843Epoch [81/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0671Epoch [81/124], Batch [56/125] [########------------] 44.8%, Loss: 0.2846Epoch [81/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.1441Epoch [81/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0021Epoch [81/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0114Epoch [81/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0148Epoch [81/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0028Epoch [81/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0962Epoch [81/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.8780Epoch [81/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0280Epoch [81/124], Batch [65/125] [##########----------] 52.0%, Loss: 1.2691Epoch [81/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.5772Epoch [81/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1235Epoch [81/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0085Epoch [81/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0105Epoch [81/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.7877Epoch [81/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0056Epoch [81/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0054Epoch [81/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0060Epoch [81/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0208Epoch [81/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0202Epoch [81/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1450Epoch [81/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0501Epoch [81/124], Batch [78/125] [############--------] 62.4%, Loss: 1.5052Epoch [81/124], Batch [79/125] [############--------] 63.2%, Loss: 0.8892Epoch [81/124], Batch [80/125] [############--------] 64.0%, Loss: 0.4368Epoch [81/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0174Epoch [81/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0161Epoch [81/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0452Epoch [81/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0629Epoch [81/124], Batch [85/125] [#############-------] 68.0%, Loss: 1.1162Epoch [81/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1386Epoch [81/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0044Epoch [81/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1586Epoch [81/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0360Epoch [81/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0805Epoch [81/124], Batch [91/125] [##############------] 72.8%, Loss: 0.2683Epoch [81/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0082Epoch [81/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0575Epoch [81/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2444Epoch [81/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0743Epoch [81/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.9524Epoch [81/124], Batch [97/125] [###############-----] 77.6%, Loss: 1.1902Epoch [81/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0210Epoch [81/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1606Epoch [81/124], Batch [100/125] [################----] 80.0%, Loss: 0.0023Epoch [81/124], Batch [101/125] [################----] 80.8%, Loss: 0.1361Epoch [81/124], Batch [102/125] [################----] 81.6%, Loss: 0.0322Epoch [81/124], Batch [103/125] [################----] 82.4%, Loss: 0.0056Epoch [81/124], Batch [104/125] [################----] 83.2%, Loss: 0.0223Epoch [81/124], Batch [105/125] [################----] 84.0%, Loss: 0.0073Epoch [81/124], Batch [106/125] [################----] 84.8%, Loss: 0.0109Epoch [81/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0284Epoch [81/124], Batch [108/125] [#################---] 86.4%, Loss: 0.4060Epoch [81/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0545Epoch [81/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0703Epoch [81/124], Batch [111/125] [#################---] 88.8%, Loss: 0.6348Epoch [81/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0398Epoch [81/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0830Epoch [81/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0126Epoch [81/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0131Epoch [81/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0047Epoch [81/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0025Epoch [81/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0052Epoch [81/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0212Epoch [81/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0265Epoch [81/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0318Epoch [81/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0199Epoch [81/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0049Epoch [81/124], Batch [124/125] [###################-] 99.2%, Loss: 0.5916Epoch [81/124], Batch [125/125] [####################] 100.0%, Loss: 0.0028
Epoch [81/124] finished. Average Loss: 0.1790
Training Accuracy: 96.60%
--- Saving checkpoint for epoch 81 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [82/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.8799Epoch [82/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0013Epoch [82/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0018Epoch [82/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0622Epoch [82/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0182Epoch [82/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0758Epoch [82/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1492Epoch [82/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0013Epoch [82/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0159Epoch [82/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0161Epoch [82/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1710Epoch [82/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0790Epoch [82/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.6270Epoch [82/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0084Epoch [82/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.0002Epoch [82/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.2032Epoch [82/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0039Epoch [82/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0039Epoch [82/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0019Epoch [82/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1727Epoch [82/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0357Epoch [82/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.3420Epoch [82/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0133Epoch [82/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0018Epoch [82/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0521Epoch [82/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0255Epoch [82/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0035Epoch [82/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.7984Epoch [82/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.3043Epoch [82/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0068Epoch [82/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0012Epoch [82/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0021Epoch [82/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.6259Epoch [82/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0023Epoch [82/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0295Epoch [82/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0037Epoch [82/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0150Epoch [82/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0023Epoch [82/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0083Epoch [82/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0006Epoch [82/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0014Epoch [82/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.2192Epoch [82/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0026Epoch [82/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0245Epoch [82/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0538Epoch [82/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0149Epoch [82/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0414Epoch [82/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0007Epoch [82/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0501Epoch [82/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0025Epoch [82/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0271Epoch [82/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0089Epoch [82/124], Batch [53/125] [########------------] 42.4%, Loss: 0.5429Epoch [82/124], Batch [54/125] [########------------] 43.2%, Loss: 0.3184Epoch [82/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0010Epoch [82/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0004Epoch [82/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0033Epoch [82/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0069Epoch [82/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0067Epoch [82/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0124Epoch [82/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0006Epoch [82/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0090Epoch [82/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0014Epoch [82/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2435Epoch [82/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0053Epoch [82/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.5590Epoch [82/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0346Epoch [82/124], Batch [68/125] [##########----------] 54.4%, Loss: 1.2898Epoch [82/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0013Epoch [82/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0383Epoch [82/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0009Epoch [82/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0466Epoch [82/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0003Epoch [82/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0039Epoch [82/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0330Epoch [82/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0288Epoch [82/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0299Epoch [82/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0018Epoch [82/124], Batch [79/125] [############--------] 63.2%, Loss: 0.4951Epoch [82/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0033Epoch [82/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0265Epoch [82/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0007Epoch [82/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0152Epoch [82/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0125Epoch [82/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0102Epoch [82/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0064Epoch [82/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0068Epoch [82/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0013Epoch [82/124], Batch [89/125] [##############------] 71.2%, Loss: 2.1256Epoch [82/124], Batch [90/125] [##############------] 72.0%, Loss: 0.4269Epoch [82/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0785Epoch [82/124], Batch [92/125] [##############------] 73.6%, Loss: 2.0173Epoch [82/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0008Epoch [82/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0485Epoch [82/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0061Epoch [82/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0059Epoch [82/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.4104Epoch [82/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.3430Epoch [82/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0613Epoch [82/124], Batch [100/125] [################----] 80.0%, Loss: 0.0140Epoch [82/124], Batch [101/125] [################----] 80.8%, Loss: 0.7288Epoch [82/124], Batch [102/125] [################----] 81.6%, Loss: 0.3278Epoch [82/124], Batch [103/125] [################----] 82.4%, Loss: 0.0225Epoch [82/124], Batch [104/125] [################----] 83.2%, Loss: 0.0299Epoch [82/124], Batch [105/125] [################----] 84.0%, Loss: 0.0359Epoch [82/124], Batch [106/125] [################----] 84.8%, Loss: 0.0019Epoch [82/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0801Epoch [82/124], Batch [108/125] [#################---] 86.4%, Loss: 0.3569Epoch [82/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0827Epoch [82/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0643Epoch [82/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0093Epoch [82/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0643Epoch [82/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0014Epoch [82/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0039Epoch [82/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0058Epoch [82/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0656Epoch [82/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0534Epoch [82/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0436Epoch [82/124], Batch [119/125] [###################-] 95.2%, Loss: 0.1087Epoch [82/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0010Epoch [82/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0224Epoch [82/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0708Epoch [82/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0411Epoch [82/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0031Epoch [82/124], Batch [125/125] [####################] 100.0%, Loss: 0.0051
Epoch [82/124] finished. Average Loss: 0.1422
Training Accuracy: 98.40%
--- Saving checkpoint for epoch 82 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [83/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0013Epoch [83/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0966Epoch [83/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.1074Epoch [83/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0033Epoch [83/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0134Epoch [83/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0205Epoch [83/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0129Epoch [83/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0026Epoch [83/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0034Epoch [83/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.9438Epoch [83/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0022Epoch [83/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0003Epoch [83/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0972Epoch [83/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0014Epoch [83/124], Batch [15/125] [##------------------] 12.0%, Loss: 1.0182Epoch [83/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0106Epoch [83/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0033Epoch [83/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0057Epoch [83/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0038Epoch [83/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0667Epoch [83/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0011Epoch [83/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0045Epoch [83/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.2391Epoch [83/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0316Epoch [83/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0053Epoch [83/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0246Epoch [83/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0296Epoch [83/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.2311Epoch [83/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0104Epoch [83/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0051Epoch [83/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0209Epoch [83/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0677Epoch [83/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0049Epoch [83/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.6924Epoch [83/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0404Epoch [83/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0044Epoch [83/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.1715Epoch [83/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0018Epoch [83/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.5658Epoch [83/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0132Epoch [83/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0026Epoch [83/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0230Epoch [83/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0320Epoch [83/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0358Epoch [83/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0036Epoch [83/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1876Epoch [83/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.5662Epoch [83/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0003Epoch [83/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0036Epoch [83/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0019Epoch [83/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0026Epoch [83/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0033Epoch [83/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0004Epoch [83/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0032Epoch [83/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0139Epoch [83/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0018Epoch [83/124], Batch [57/125] [#########-----------] 45.6%, Loss: 1.0479Epoch [83/124], Batch [58/125] [#########-----------] 46.4%, Loss: 1.2852Epoch [83/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0895Epoch [83/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0469Epoch [83/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0712Epoch [83/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0005Epoch [83/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0066Epoch [83/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0182Epoch [83/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0007Epoch [83/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0124Epoch [83/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0105Epoch [83/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0149Epoch [83/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0036Epoch [83/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0486Epoch [83/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0006Epoch [83/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0225Epoch [83/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0007Epoch [83/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0445Epoch [83/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0573Epoch [83/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0027Epoch [83/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0019Epoch [83/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0010Epoch [83/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0018Epoch [83/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0941Epoch [83/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0206Epoch [83/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0174Epoch [83/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0245Epoch [83/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0036Epoch [83/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0115Epoch [83/124], Batch [86/125] [#############-------] 68.8%, Loss: 1.5509Epoch [83/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.5150Epoch [83/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0155Epoch [83/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0020Epoch [83/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0003Epoch [83/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0319Epoch [83/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2365Epoch [83/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0069Epoch [83/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0300Epoch [83/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0053Epoch [83/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0002Epoch [83/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0078Epoch [83/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0113Epoch [83/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0046Epoch [83/124], Batch [100/125] [################----] 80.0%, Loss: 0.0007Epoch [83/124], Batch [101/125] [################----] 80.8%, Loss: 0.0066Epoch [83/124], Batch [102/125] [################----] 81.6%, Loss: 0.0023Epoch [83/124], Batch [103/125] [################----] 82.4%, Loss: 0.0079Epoch [83/124], Batch [104/125] [################----] 83.2%, Loss: 0.2384Epoch [83/124], Batch [105/125] [################----] 84.0%, Loss: 0.9938Epoch [83/124], Batch [106/125] [################----] 84.8%, Loss: 0.0051Epoch [83/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0420Epoch [83/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2153Epoch [83/124], Batch [109/125] [#################---] 87.2%, Loss: 0.5577Epoch [83/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0029Epoch [83/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0355Epoch [83/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0440Epoch [83/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1011Epoch [83/124], Batch [114/125] [##################--] 91.2%, Loss: 3.4428Epoch [83/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0821Epoch [83/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0004Epoch [83/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0393Epoch [83/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0591Epoch [83/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0256Epoch [83/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2873Epoch [83/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0139Epoch [83/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0004Epoch [83/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0017Epoch [83/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0136Epoch [83/124], Batch [125/125] [####################] 100.0%, Loss: 1.1878
Epoch [83/124] finished. Average Loss: 0.1460
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 83 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [84/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0030Epoch [84/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0124Epoch [84/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0037Epoch [84/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0447Epoch [84/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0008Epoch [84/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0095Epoch [84/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0266Epoch [84/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.4660Epoch [84/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0248Epoch [84/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0068Epoch [84/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0017Epoch [84/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0487Epoch [84/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3335Epoch [84/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0417Epoch [84/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0195Epoch [84/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1315Epoch [84/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0415Epoch [84/124], Batch [18/125] [##------------------] 14.4%, Loss: 1.4999Epoch [84/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0389Epoch [84/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1620Epoch [84/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0037Epoch [84/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0162Epoch [84/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1426Epoch [84/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0113Epoch [84/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.2393Epoch [84/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0068Epoch [84/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.9548Epoch [84/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0009Epoch [84/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0647Epoch [84/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.3542Epoch [84/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0016Epoch [84/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0505Epoch [84/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0013Epoch [84/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.3446Epoch [84/124], Batch [35/125] [#####---------------] 28.0%, Loss: 1.5025Epoch [84/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0456Epoch [84/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0868Epoch [84/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0771Epoch [84/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0022Epoch [84/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0021Epoch [84/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.6415Epoch [84/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0109Epoch [84/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0058Epoch [84/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0466Epoch [84/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0311Epoch [84/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0439Epoch [84/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0005Epoch [84/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0064Epoch [84/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0119Epoch [84/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0041Epoch [84/124], Batch [51/125] [########------------] 40.8%, Loss: 0.3699Epoch [84/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0261Epoch [84/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0312Epoch [84/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1904Epoch [84/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2780Epoch [84/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0021Epoch [84/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0033Epoch [84/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0001Epoch [84/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0020Epoch [84/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0050Epoch [84/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0436Epoch [84/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0003Epoch [84/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.4551Epoch [84/124], Batch [64/125] [##########----------] 51.2%, Loss: 1.2682Epoch [84/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.4176Epoch [84/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0106Epoch [84/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.3753Epoch [84/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0066Epoch [84/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0027Epoch [84/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0018Epoch [84/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0006Epoch [84/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0024Epoch [84/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0003Epoch [84/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0310Epoch [84/124], Batch [75/125] [############--------] 60.0%, Loss: 1.3003Epoch [84/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0002Epoch [84/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0371Epoch [84/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0019Epoch [84/124], Batch [79/125] [############--------] 63.2%, Loss: 0.1164Epoch [84/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0282Epoch [84/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0085Epoch [84/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.2152Epoch [84/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0093Epoch [84/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0238Epoch [84/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0959Epoch [84/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0082Epoch [84/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.2660Epoch [84/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0089Epoch [84/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3884Epoch [84/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0651Epoch [84/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0144Epoch [84/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0801Epoch [84/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1563Epoch [84/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2267Epoch [84/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0605Epoch [84/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1125Epoch [84/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0175Epoch [84/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0000Epoch [84/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0014Epoch [84/124], Batch [100/125] [################----] 80.0%, Loss: 0.6517Epoch [84/124], Batch [101/125] [################----] 80.8%, Loss: 0.7227Epoch [84/124], Batch [102/125] [################----] 81.6%, Loss: 0.1053Epoch [84/124], Batch [103/125] [################----] 82.4%, Loss: 0.0046Epoch [84/124], Batch [104/125] [################----] 83.2%, Loss: 0.0096Epoch [84/124], Batch [105/125] [################----] 84.0%, Loss: 0.2084Epoch [84/124], Batch [106/125] [################----] 84.8%, Loss: 0.0388Epoch [84/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0292Epoch [84/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0001Epoch [84/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0165Epoch [84/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0173Epoch [84/124], Batch [111/125] [#################---] 88.8%, Loss: 0.2547Epoch [84/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0708Epoch [84/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0167Epoch [84/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0177Epoch [84/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0370Epoch [84/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0264Epoch [84/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0014Epoch [84/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0046Epoch [84/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0036Epoch [84/124], Batch [120/125] [###################-] 96.0%, Loss: 0.9609Epoch [84/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0008Epoch [84/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0138Epoch [84/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0023Epoch [84/124], Batch [124/125] [###################-] 99.2%, Loss: 0.1132Epoch [84/124], Batch [125/125] [####################] 100.0%, Loss: 0.2304
Epoch [84/124] finished. Average Loss: 0.1436
Training Accuracy: 87.80%
--- Saving checkpoint for epoch 84 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [85/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0924Epoch [85/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0119Epoch [85/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0174Epoch [85/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.2452Epoch [85/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.2342Epoch [85/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0194Epoch [85/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0125Epoch [85/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0006Epoch [85/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0060Epoch [85/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0074Epoch [85/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2289Epoch [85/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0256Epoch [85/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.6458Epoch [85/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0007Epoch [85/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0012Epoch [85/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0501Epoch [85/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3846Epoch [85/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0014Epoch [85/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0069Epoch [85/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0082Epoch [85/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.6764Epoch [85/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0217Epoch [85/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.4594Epoch [85/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0063Epoch [85/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0499Epoch [85/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0273Epoch [85/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0033Epoch [85/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0193Epoch [85/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1070Epoch [85/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0104Epoch [85/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0018Epoch [85/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.3238Epoch [85/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0056Epoch [85/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0118Epoch [85/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0006Epoch [85/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1777Epoch [85/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.9265Epoch [85/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.4619Epoch [85/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.4258Epoch [85/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0025Epoch [85/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0238Epoch [85/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0006Epoch [85/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1082Epoch [85/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0040Epoch [85/124], Batch [45/125] [#######-------------] 36.0%, Loss: 1.0416Epoch [85/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.9155Epoch [85/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0360Epoch [85/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0178Epoch [85/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0028Epoch [85/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0029Epoch [85/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0073Epoch [85/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0459Epoch [85/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0046Epoch [85/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0769Epoch [85/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0003Epoch [85/124], Batch [56/125] [########------------] 44.8%, Loss: 0.4046Epoch [85/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0276Epoch [85/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1338Epoch [85/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2152Epoch [85/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0302Epoch [85/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0680Epoch [85/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.3348Epoch [85/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0023Epoch [85/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0095Epoch [85/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0026Epoch [85/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0005Epoch [85/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0009Epoch [85/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0400Epoch [85/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0014Epoch [85/124], Batch [70/125] [###########---------] 56.0%, Loss: 1.8220Epoch [85/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0035Epoch [85/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0019Epoch [85/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0021Epoch [85/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0430Epoch [85/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0063Epoch [85/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2321Epoch [85/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0962Epoch [85/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0359Epoch [85/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0099Epoch [85/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1414Epoch [85/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0021Epoch [85/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1847Epoch [85/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0206Epoch [85/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0001Epoch [85/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1049Epoch [85/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0210Epoch [85/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1191Epoch [85/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0059Epoch [85/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0077Epoch [85/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0305Epoch [85/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0343Epoch [85/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2678Epoch [85/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0059Epoch [85/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0013Epoch [85/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0168Epoch [85/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0005Epoch [85/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0159Epoch [85/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0310Epoch [85/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0650Epoch [85/124], Batch [100/125] [################----] 80.0%, Loss: 0.0025Epoch [85/124], Batch [101/125] [################----] 80.8%, Loss: 0.7398Epoch [85/124], Batch [102/125] [################----] 81.6%, Loss: 0.0099Epoch [85/124], Batch [103/125] [################----] 82.4%, Loss: 0.1205Epoch [85/124], Batch [104/125] [################----] 83.2%, Loss: 0.0108Epoch [85/124], Batch [105/125] [################----] 84.0%, Loss: 0.0051Epoch [85/124], Batch [106/125] [################----] 84.8%, Loss: 0.3919Epoch [85/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0014Epoch [85/124], Batch [108/125] [#################---] 86.4%, Loss: 1.2793Epoch [85/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0020Epoch [85/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0078Epoch [85/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0029Epoch [85/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1115Epoch [85/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0408Epoch [85/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2590Epoch [85/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0407Epoch [85/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0017Epoch [85/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0467Epoch [85/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0136Epoch [85/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0026Epoch [85/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0014Epoch [85/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0005Epoch [85/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0037Epoch [85/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0427Epoch [85/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0006Epoch [85/124], Batch [125/125] [####################] 100.0%, Loss: 0.0007
Epoch [85/124] finished. Average Loss: 0.1260
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 85 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [86/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0092Epoch [86/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0657Epoch [86/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0197Epoch [86/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0025Epoch [86/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0008Epoch [86/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0057Epoch [86/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0060Epoch [86/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0008Epoch [86/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0017Epoch [86/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.7281Epoch [86/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0025Epoch [86/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0260Epoch [86/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0009Epoch [86/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0005Epoch [86/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0056Epoch [86/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0016Epoch [86/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0478Epoch [86/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0014Epoch [86/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0624Epoch [86/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0769Epoch [86/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0030Epoch [86/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0025Epoch [86/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0003Epoch [86/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1593Epoch [86/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0696Epoch [86/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0065Epoch [86/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.1364Epoch [86/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0029Epoch [86/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0022Epoch [86/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0691Epoch [86/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1800Epoch [86/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.1730Epoch [86/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0077Epoch [86/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0496Epoch [86/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0036Epoch [86/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0009Epoch [86/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0020Epoch [86/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0158Epoch [86/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0018Epoch [86/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0010Epoch [86/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0133Epoch [86/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0063Epoch [86/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0014Epoch [86/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0034Epoch [86/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.2283Epoch [86/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0000Epoch [86/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0018Epoch [86/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0004Epoch [86/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0119Epoch [86/124], Batch [50/125] [########------------] 40.0%, Loss: 0.3043Epoch [86/124], Batch [51/125] [########------------] 40.8%, Loss: 0.5798Epoch [86/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0753Epoch [86/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0058Epoch [86/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0422Epoch [86/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0011Epoch [86/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0010Epoch [86/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.8168Epoch [86/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0715Epoch [86/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0014Epoch [86/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1692Epoch [86/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0070Epoch [86/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0150Epoch [86/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0016Epoch [86/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0029Epoch [86/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0228Epoch [86/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.6187Epoch [86/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0055Epoch [86/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0003Epoch [86/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0003Epoch [86/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0058Epoch [86/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.1321Epoch [86/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0009Epoch [86/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0276Epoch [86/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0011Epoch [86/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0203Epoch [86/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0002Epoch [86/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0697Epoch [86/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0006Epoch [86/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0017Epoch [86/124], Batch [80/125] [############--------] 64.0%, Loss: 1.3760Epoch [86/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0422Epoch [86/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0110Epoch [86/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.2275Epoch [86/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0558Epoch [86/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0104Epoch [86/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0008Epoch [86/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0004Epoch [86/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0050Epoch [86/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0290Epoch [86/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1000Epoch [86/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0159Epoch [86/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0144Epoch [86/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1002Epoch [86/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0188Epoch [86/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0014Epoch [86/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.2638Epoch [86/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0009Epoch [86/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0043Epoch [86/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0440Epoch [86/124], Batch [100/125] [################----] 80.0%, Loss: 0.1631Epoch [86/124], Batch [101/125] [################----] 80.8%, Loss: 0.0003Epoch [86/124], Batch [102/125] [################----] 81.6%, Loss: 0.0085Epoch [86/124], Batch [103/125] [################----] 82.4%, Loss: 0.0030Epoch [86/124], Batch [104/125] [################----] 83.2%, Loss: 0.2714Epoch [86/124], Batch [105/125] [################----] 84.0%, Loss: 0.0276Epoch [86/124], Batch [106/125] [################----] 84.8%, Loss: 0.1563Epoch [86/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0024Epoch [86/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0006Epoch [86/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0004Epoch [86/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0005Epoch [86/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0002Epoch [86/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0087Epoch [86/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0142Epoch [86/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0016Epoch [86/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0011Epoch [86/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0101Epoch [86/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0491Epoch [86/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1036Epoch [86/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0038Epoch [86/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0003Epoch [86/124], Batch [121/125] [###################-] 96.8%, Loss: 0.4286Epoch [86/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0086Epoch [86/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0102Epoch [86/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0075Epoch [86/124], Batch [125/125] [####################] 100.0%, Loss: 0.0182
Epoch [86/124] finished. Average Loss: 0.0707
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 86 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [87/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0042Epoch [87/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0049Epoch [87/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0049Epoch [87/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0012Epoch [87/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0005Epoch [87/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0004Epoch [87/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0046Epoch [87/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0023Epoch [87/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.5343Epoch [87/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0005Epoch [87/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0014Epoch [87/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0012Epoch [87/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0113Epoch [87/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.5400Epoch [87/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0007Epoch [87/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0005Epoch [87/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0659Epoch [87/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0006Epoch [87/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0013Epoch [87/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0040Epoch [87/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0073Epoch [87/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0020Epoch [87/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0265Epoch [87/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0188Epoch [87/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0162Epoch [87/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0979Epoch [87/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0354Epoch [87/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0008Epoch [87/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0090Epoch [87/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0027Epoch [87/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0052Epoch [87/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0258Epoch [87/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0114Epoch [87/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0012Epoch [87/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0063Epoch [87/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0135Epoch [87/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0016Epoch [87/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0042Epoch [87/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.7287Epoch [87/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0044Epoch [87/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0030Epoch [87/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0005Epoch [87/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0003Epoch [87/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.7506Epoch [87/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0013Epoch [87/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0993Epoch [87/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0008Epoch [87/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0202Epoch [87/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0008Epoch [87/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0012Epoch [87/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0606Epoch [87/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0033Epoch [87/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0001Epoch [87/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0700Epoch [87/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0020Epoch [87/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0080Epoch [87/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0019Epoch [87/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0010Epoch [87/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1639Epoch [87/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0264Epoch [87/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0095Epoch [87/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0057Epoch [87/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0314Epoch [87/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0008Epoch [87/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0075Epoch [87/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0001Epoch [87/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0085Epoch [87/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0173Epoch [87/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0010Epoch [87/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0095Epoch [87/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0227Epoch [87/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0203Epoch [87/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0002Epoch [87/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0033Epoch [87/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0355Epoch [87/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0007Epoch [87/124], Batch [77/125] [############--------] 61.6%, Loss: 0.1898Epoch [87/124], Batch [78/125] [############--------] 62.4%, Loss: 0.3558Epoch [87/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0005Epoch [87/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0113Epoch [87/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0025Epoch [87/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0010Epoch [87/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0150Epoch [87/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0515Epoch [87/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0152Epoch [87/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0041Epoch [87/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0063Epoch [87/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0013Epoch [87/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0035Epoch [87/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0649Epoch [87/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0075Epoch [87/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1491Epoch [87/124], Batch [93/125] [##############------] 74.4%, Loss: 0.2061Epoch [87/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0052Epoch [87/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0212Epoch [87/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0017Epoch [87/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0007Epoch [87/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0012Epoch [87/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0059Epoch [87/124], Batch [100/125] [################----] 80.0%, Loss: 0.0101Epoch [87/124], Batch [101/125] [################----] 80.8%, Loss: 0.0023Epoch [87/124], Batch [102/125] [################----] 81.6%, Loss: 0.0023Epoch [87/124], Batch [103/125] [################----] 82.4%, Loss: 1.1700Epoch [87/124], Batch [104/125] [################----] 83.2%, Loss: 0.0012Epoch [87/124], Batch [105/125] [################----] 84.0%, Loss: 0.2465Epoch [87/124], Batch [106/125] [################----] 84.8%, Loss: 0.0095Epoch [87/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0000Epoch [87/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0032Epoch [87/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1529Epoch [87/124], Batch [110/125] [#################---] 88.0%, Loss: 0.4540Epoch [87/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0028Epoch [87/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0202Epoch [87/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1203Epoch [87/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0368Epoch [87/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0023Epoch [87/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0002Epoch [87/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0020Epoch [87/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0014Epoch [87/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0207Epoch [87/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0005Epoch [87/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0023Epoch [87/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0029Epoch [87/124], Batch [123/125] [###################-] 98.4%, Loss: 0.5407Epoch [87/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0046Epoch [87/124], Batch [125/125] [####################] 100.0%, Loss: 0.1977
Epoch [87/124] finished. Average Loss: 0.0618
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 87 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [88/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0242Epoch [88/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0653Epoch [88/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0344Epoch [88/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0002Epoch [88/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0034Epoch [88/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.3102Epoch [88/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0017Epoch [88/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0010Epoch [88/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1208Epoch [88/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0011Epoch [88/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0018Epoch [88/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0121Epoch [88/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0374Epoch [88/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.2184Epoch [88/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0104Epoch [88/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0153Epoch [88/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.9485Epoch [88/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1416Epoch [88/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0012Epoch [88/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0003Epoch [88/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0369Epoch [88/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0289Epoch [88/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0007Epoch [88/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0013Epoch [88/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0572Epoch [88/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0014Epoch [88/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0003Epoch [88/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0000Epoch [88/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0016Epoch [88/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0012Epoch [88/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0007Epoch [88/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0120Epoch [88/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0035Epoch [88/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.1587Epoch [88/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0010Epoch [88/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0008Epoch [88/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0001Epoch [88/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0040Epoch [88/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0230Epoch [88/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0119Epoch [88/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0016Epoch [88/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.4356Epoch [88/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0346Epoch [88/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0048Epoch [88/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0583Epoch [88/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0002Epoch [88/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0445Epoch [88/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0153Epoch [88/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0001Epoch [88/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0000Epoch [88/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0842Epoch [88/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0005Epoch [88/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0152Epoch [88/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0003Epoch [88/124], Batch [55/125] [########------------] 44.0%, Loss: 0.1351Epoch [88/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0034Epoch [88/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0130Epoch [88/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0015Epoch [88/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0005Epoch [88/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0008Epoch [88/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0013Epoch [88/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0002Epoch [88/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0171Epoch [88/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0415Epoch [88/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0038Epoch [88/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0045Epoch [88/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0004Epoch [88/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0715Epoch [88/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0073Epoch [88/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0022Epoch [88/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0000Epoch [88/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0001Epoch [88/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0028Epoch [88/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0029Epoch [88/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0020Epoch [88/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0009Epoch [88/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0001Epoch [88/124], Batch [78/125] [############--------] 62.4%, Loss: 0.8881Epoch [88/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0008Epoch [88/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0001Epoch [88/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0733Epoch [88/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0000Epoch [88/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.7848Epoch [88/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0014Epoch [88/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0003Epoch [88/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.3299Epoch [88/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0019Epoch [88/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0007Epoch [88/124], Batch [89/125] [##############------] 71.2%, Loss: 0.4264Epoch [88/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0001Epoch [88/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0123Epoch [88/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0029Epoch [88/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0463Epoch [88/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0010Epoch [88/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0006Epoch [88/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0221Epoch [88/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0019Epoch [88/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0003Epoch [88/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.7127Epoch [88/124], Batch [100/125] [################----] 80.0%, Loss: 0.0016Epoch [88/124], Batch [101/125] [################----] 80.8%, Loss: 0.0016Epoch [88/124], Batch [102/125] [################----] 81.6%, Loss: 0.0220Epoch [88/124], Batch [103/125] [################----] 82.4%, Loss: 0.0324Epoch [88/124], Batch [104/125] [################----] 83.2%, Loss: 0.0202Epoch [88/124], Batch [105/125] [################----] 84.0%, Loss: 0.0044Epoch [88/124], Batch [106/125] [################----] 84.8%, Loss: 0.0019Epoch [88/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0015Epoch [88/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1915Epoch [88/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0730Epoch [88/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0533Epoch [88/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0036Epoch [88/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0035Epoch [88/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1257Epoch [88/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0025Epoch [88/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0586Epoch [88/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0031Epoch [88/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0033Epoch [88/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0039Epoch [88/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0013Epoch [88/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0019Epoch [88/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0008Epoch [88/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0016Epoch [88/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0511Epoch [88/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0005Epoch [88/124], Batch [125/125] [####################] 100.0%, Loss: 0.0057
Epoch [88/124] finished. Average Loss: 0.0582
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 88 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [89/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0020Epoch [89/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0289Epoch [89/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0000Epoch [89/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0023Epoch [89/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0004Epoch [89/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0020Epoch [89/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0002Epoch [89/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0040Epoch [89/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0050Epoch [89/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0030Epoch [89/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0002Epoch [89/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0011Epoch [89/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0098Epoch [89/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0039Epoch [89/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0001Epoch [89/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0027Epoch [89/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1218Epoch [89/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0050Epoch [89/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0005Epoch [89/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0058Epoch [89/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0076Epoch [89/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0003Epoch [89/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0042Epoch [89/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0027Epoch [89/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0020Epoch [89/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0164Epoch [89/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0030Epoch [89/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0057Epoch [89/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2781Epoch [89/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0001Epoch [89/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0001Epoch [89/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0081Epoch [89/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0017Epoch [89/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0151Epoch [89/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0006Epoch [89/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0067Epoch [89/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0083Epoch [89/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0035Epoch [89/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0001Epoch [89/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0051Epoch [89/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0014Epoch [89/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0001Epoch [89/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0089Epoch [89/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0233Epoch [89/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0073Epoch [89/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0040Epoch [89/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0007Epoch [89/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.6920Epoch [89/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0032Epoch [89/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0004Epoch [89/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0222Epoch [89/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0004Epoch [89/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0010Epoch [89/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0102Epoch [89/124], Batch [55/125] [########------------] 44.0%, Loss: 0.7179Epoch [89/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0008Epoch [89/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0003Epoch [89/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0005Epoch [89/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0002Epoch [89/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1816Epoch [89/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.3287Epoch [89/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.8169Epoch [89/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0019Epoch [89/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0081Epoch [89/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0260Epoch [89/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0717Epoch [89/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0020Epoch [89/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0032Epoch [89/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0009Epoch [89/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0005Epoch [89/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.1400Epoch [89/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0019Epoch [89/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0003Epoch [89/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0015Epoch [89/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0001Epoch [89/124], Batch [76/125] [############--------] 60.8%, Loss: 0.8094Epoch [89/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0094Epoch [89/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0003Epoch [89/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0022Epoch [89/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0028Epoch [89/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0026Epoch [89/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0161Epoch [89/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0159Epoch [89/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0128Epoch [89/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0186Epoch [89/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0238Epoch [89/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0012Epoch [89/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0118Epoch [89/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0015Epoch [89/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0074Epoch [89/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0134Epoch [89/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0651Epoch [89/124], Batch [93/125] [##############------] 74.4%, Loss: 0.6774Epoch [89/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0021Epoch [89/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0119Epoch [89/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0058Epoch [89/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0047Epoch [89/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0028Epoch [89/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0051Epoch [89/124], Batch [100/125] [################----] 80.0%, Loss: 0.0023Epoch [89/124], Batch [101/125] [################----] 80.8%, Loss: 0.0058Epoch [89/124], Batch [102/125] [################----] 81.6%, Loss: 0.3094Epoch [89/124], Batch [103/125] [################----] 82.4%, Loss: 0.0005Epoch [89/124], Batch [104/125] [################----] 83.2%, Loss: 0.0022Epoch [89/124], Batch [105/125] [################----] 84.0%, Loss: 1.5346Epoch [89/124], Batch [106/125] [################----] 84.8%, Loss: 0.0310Epoch [89/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0162Epoch [89/124], Batch [108/125] [#################---] 86.4%, Loss: 0.1307Epoch [89/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0004Epoch [89/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0025Epoch [89/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0690Epoch [89/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0038Epoch [89/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0066Epoch [89/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0004Epoch [89/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0008Epoch [89/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0236Epoch [89/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0000Epoch [89/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0010Epoch [89/124], Batch [119/125] [###################-] 95.2%, Loss: 0.9619Epoch [89/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0074Epoch [89/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0039Epoch [89/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0063Epoch [89/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0248Epoch [89/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0005Epoch [89/124], Batch [125/125] [####################] 100.0%, Loss: 0.2898
Epoch [89/124] finished. Average Loss: 0.0705
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 89 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [90/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0060Epoch [90/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0030Epoch [90/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0165Epoch [90/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0061Epoch [90/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0006Epoch [90/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0555Epoch [90/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0107Epoch [90/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0032Epoch [90/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0001Epoch [90/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0078Epoch [90/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0033Epoch [90/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0307Epoch [90/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0088Epoch [90/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0003Epoch [90/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0032Epoch [90/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0045Epoch [90/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0005Epoch [90/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0013Epoch [90/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0050Epoch [90/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0002Epoch [90/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0074Epoch [90/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0006Epoch [90/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0040Epoch [90/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0509Epoch [90/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0001Epoch [90/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0081Epoch [90/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.2939Epoch [90/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0007Epoch [90/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0055Epoch [90/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0029Epoch [90/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0309Epoch [90/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0435Epoch [90/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0002Epoch [90/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0103Epoch [90/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0011Epoch [90/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0187Epoch [90/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0010Epoch [90/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0001Epoch [90/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0046Epoch [90/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0070Epoch [90/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0076Epoch [90/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0001Epoch [90/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0118Epoch [90/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.1718Epoch [90/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0098Epoch [90/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0013Epoch [90/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0018Epoch [90/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0007Epoch [90/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0076Epoch [90/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0017Epoch [90/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0030Epoch [90/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0025Epoch [90/124], Batch [53/125] [########------------] 42.4%, Loss: 0.9858Epoch [90/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0020Epoch [90/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0012Epoch [90/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0870Epoch [90/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0010Epoch [90/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0012Epoch [90/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0169Epoch [90/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0008Epoch [90/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0117Epoch [90/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0043Epoch [90/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0004Epoch [90/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0005Epoch [90/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0030Epoch [90/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0021Epoch [90/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0017Epoch [90/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0326Epoch [90/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0475Epoch [90/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0011Epoch [90/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0003Epoch [90/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0079Epoch [90/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0817Epoch [90/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0014Epoch [90/124], Batch [75/125] [############--------] 60.0%, Loss: 0.3347Epoch [90/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0826Epoch [90/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0467Epoch [90/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0013Epoch [90/124], Batch [79/125] [############--------] 63.2%, Loss: 0.3432Epoch [90/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0068Epoch [90/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0150Epoch [90/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0074Epoch [90/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.5100Epoch [90/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0130Epoch [90/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0002Epoch [90/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0044Epoch [90/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.6438Epoch [90/124], Batch [88/125] [##############------] 70.4%, Loss: 0.7859Epoch [90/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0681Epoch [90/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0118Epoch [90/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0083Epoch [90/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0052Epoch [90/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0004Epoch [90/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0203Epoch [90/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0067Epoch [90/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0440Epoch [90/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.1384Epoch [90/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0004Epoch [90/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0063Epoch [90/124], Batch [100/125] [################----] 80.0%, Loss: 0.0027Epoch [90/124], Batch [101/125] [################----] 80.8%, Loss: 0.0007Epoch [90/124], Batch [102/125] [################----] 81.6%, Loss: 0.0169Epoch [90/124], Batch [103/125] [################----] 82.4%, Loss: 0.0066Epoch [90/124], Batch [104/125] [################----] 83.2%, Loss: 0.0115Epoch [90/124], Batch [105/125] [################----] 84.0%, Loss: 0.0197Epoch [90/124], Batch [106/125] [################----] 84.8%, Loss: 0.1796Epoch [90/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0074Epoch [90/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0737Epoch [90/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2201Epoch [90/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0003Epoch [90/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0011Epoch [90/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0043Epoch [90/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0032Epoch [90/124], Batch [114/125] [##################--] 91.2%, Loss: 0.2152Epoch [90/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0005Epoch [90/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0247Epoch [90/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0008Epoch [90/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0246Epoch [90/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0061Epoch [90/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0034Epoch [90/124], Batch [121/125] [###################-] 96.8%, Loss: 0.9491Epoch [90/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0002Epoch [90/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0021Epoch [90/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0059Epoch [90/124], Batch [125/125] [####################] 100.0%, Loss: 0.0012
Epoch [90/124] finished. Average Loss: 0.0565
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 90 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [91/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.3504Epoch [91/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0011Epoch [91/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0080Epoch [91/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0152Epoch [91/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0235Epoch [91/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.2568Epoch [91/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0137Epoch [91/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0029Epoch [91/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0145Epoch [91/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0295Epoch [91/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0016Epoch [91/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0052Epoch [91/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.1807Epoch [91/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [91/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0076Epoch [91/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0063Epoch [91/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.2081Epoch [91/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0003Epoch [91/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0027Epoch [91/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0050Epoch [91/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0045Epoch [91/124], Batch [22/125] [###-----------------] 17.6%, Loss: 1.0775Epoch [91/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0003Epoch [91/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1775Epoch [91/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0006Epoch [91/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0021Epoch [91/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0111Epoch [91/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0006Epoch [91/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.1803Epoch [91/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0022Epoch [91/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0015Epoch [91/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0312Epoch [91/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0005Epoch [91/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0041Epoch [91/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0769Epoch [91/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0055Epoch [91/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.9359Epoch [91/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0057Epoch [91/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0021Epoch [91/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0034Epoch [91/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0264Epoch [91/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1519Epoch [91/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1358Epoch [91/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0039Epoch [91/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0005Epoch [91/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0012Epoch [91/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0070Epoch [91/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0097Epoch [91/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2391Epoch [91/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0161Epoch [91/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0002Epoch [91/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1177Epoch [91/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0328Epoch [91/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1184Epoch [91/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2710Epoch [91/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0176Epoch [91/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0269Epoch [91/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1511Epoch [91/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0008Epoch [91/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0343Epoch [91/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0237Epoch [91/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0207Epoch [91/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0805Epoch [91/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0011Epoch [91/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.7844Epoch [91/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0032Epoch [91/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1590Epoch [91/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0226Epoch [91/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1867Epoch [91/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0004Epoch [91/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0232Epoch [91/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.4161Epoch [91/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0006Epoch [91/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0016Epoch [91/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0006Epoch [91/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0211Epoch [91/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0139Epoch [91/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0304Epoch [91/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0129Epoch [91/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0001Epoch [91/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0135Epoch [91/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1108Epoch [91/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.4662Epoch [91/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0110Epoch [91/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0009Epoch [91/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0107Epoch [91/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1792Epoch [91/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0746Epoch [91/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0016Epoch [91/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0340Epoch [91/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0023Epoch [91/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0020Epoch [91/124], Batch [93/125] [##############------] 74.4%, Loss: 0.6665Epoch [91/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0009Epoch [91/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0415Epoch [91/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.6114Epoch [91/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0016Epoch [91/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0050Epoch [91/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1241Epoch [91/124], Batch [100/125] [################----] 80.0%, Loss: 0.0895Epoch [91/124], Batch [101/125] [################----] 80.8%, Loss: 0.0160Epoch [91/124], Batch [102/125] [################----] 81.6%, Loss: 1.2272Epoch [91/124], Batch [103/125] [################----] 82.4%, Loss: 0.0026Epoch [91/124], Batch [104/125] [################----] 83.2%, Loss: 0.0010Epoch [91/124], Batch [105/125] [################----] 84.0%, Loss: 0.0022Epoch [91/124], Batch [106/125] [################----] 84.8%, Loss: 0.0017Epoch [91/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0183Epoch [91/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0125Epoch [91/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0121Epoch [91/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0028Epoch [91/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0034Epoch [91/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0102Epoch [91/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0033Epoch [91/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0262Epoch [91/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0054Epoch [91/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1737Epoch [91/124], Batch [117/125] [##################--] 93.6%, Loss: 0.5257Epoch [91/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0050Epoch [91/124], Batch [119/125] [###################-] 95.2%, Loss: 0.1515Epoch [91/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0032Epoch [91/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0001Epoch [91/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0006Epoch [91/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0321Epoch [91/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0226Epoch [91/124], Batch [125/125] [####################] 100.0%, Loss: 0.0031
Epoch [91/124] finished. Average Loss: 0.0923
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 91 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [92/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0003Epoch [92/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0329Epoch [92/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0010Epoch [92/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0034Epoch [92/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0210Epoch [92/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0013Epoch [92/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0010Epoch [92/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0004Epoch [92/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0067Epoch [92/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0525Epoch [92/124], Batch [11/125] [#-------------------] 8.8%, Loss: 1.1898Epoch [92/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0008Epoch [92/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.8814Epoch [92/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0018Epoch [92/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0005Epoch [92/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0056Epoch [92/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0011Epoch [92/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0045Epoch [92/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0002Epoch [92/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0013Epoch [92/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0051Epoch [92/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0199Epoch [92/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0355Epoch [92/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0009Epoch [92/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0415Epoch [92/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0112Epoch [92/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0049Epoch [92/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0602Epoch [92/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0003Epoch [92/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0326Epoch [92/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0002Epoch [92/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0014Epoch [92/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.4172Epoch [92/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0003Epoch [92/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0013Epoch [92/124], Batch [36/125] [#####---------------] 28.8%, Loss: 1.3817Epoch [92/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0004Epoch [92/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0070Epoch [92/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0058Epoch [92/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0003Epoch [92/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.3786Epoch [92/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.3197Epoch [92/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0002Epoch [92/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0002Epoch [92/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0517Epoch [92/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0020Epoch [92/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0009Epoch [92/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0055Epoch [92/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0005Epoch [92/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0075Epoch [92/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0134Epoch [92/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0523Epoch [92/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0275Epoch [92/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0752Epoch [92/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0002Epoch [92/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0428Epoch [92/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0655Epoch [92/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0156Epoch [92/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0003Epoch [92/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0369Epoch [92/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0023Epoch [92/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0151Epoch [92/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0052Epoch [92/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0002Epoch [92/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.6611Epoch [92/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0025Epoch [92/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0180Epoch [92/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1618Epoch [92/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0006Epoch [92/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0064Epoch [92/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0155Epoch [92/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0041Epoch [92/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0146Epoch [92/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0001Epoch [92/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0765Epoch [92/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0008Epoch [92/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0029Epoch [92/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0017Epoch [92/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0048Epoch [92/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0038Epoch [92/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0002Epoch [92/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.3325Epoch [92/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0181Epoch [92/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0186Epoch [92/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0022Epoch [92/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0229Epoch [92/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0354Epoch [92/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0773Epoch [92/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0023Epoch [92/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0272Epoch [92/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0009Epoch [92/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2031Epoch [92/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0012Epoch [92/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0010Epoch [92/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0044Epoch [92/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0942Epoch [92/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0001Epoch [92/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0250Epoch [92/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0154Epoch [92/124], Batch [100/125] [################----] 80.0%, Loss: 0.0022Epoch [92/124], Batch [101/125] [################----] 80.8%, Loss: 0.1306Epoch [92/124], Batch [102/125] [################----] 81.6%, Loss: 0.0007Epoch [92/124], Batch [103/125] [################----] 82.4%, Loss: 0.4638Epoch [92/124], Batch [104/125] [################----] 83.2%, Loss: 0.0398Epoch [92/124], Batch [105/125] [################----] 84.0%, Loss: 0.0105Epoch [92/124], Batch [106/125] [################----] 84.8%, Loss: 0.0004Epoch [92/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0495Epoch [92/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0007Epoch [92/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0013Epoch [92/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0022Epoch [92/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0049Epoch [92/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0025Epoch [92/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0020Epoch [92/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0008Epoch [92/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0478Epoch [92/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0004Epoch [92/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0161Epoch [92/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0043Epoch [92/124], Batch [119/125] [###################-] 95.2%, Loss: 0.5021Epoch [92/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0087Epoch [92/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0027Epoch [92/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0049Epoch [92/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0009Epoch [92/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0197Epoch [92/124], Batch [125/125] [####################] 100.0%, Loss: 0.0883
Epoch [92/124] finished. Average Loss: 0.0690
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 92 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [93/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0014Epoch [93/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0027Epoch [93/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0032Epoch [93/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0007Epoch [93/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0001Epoch [93/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0622Epoch [93/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0104Epoch [93/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0017Epoch [93/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0004Epoch [93/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0005Epoch [93/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0192Epoch [93/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0015Epoch [93/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0002Epoch [93/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0008Epoch [93/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0475Epoch [93/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0006Epoch [93/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0017Epoch [93/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0002Epoch [93/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0018Epoch [93/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0027Epoch [93/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0148Epoch [93/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0007Epoch [93/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0043Epoch [93/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.6670Epoch [93/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.4956Epoch [93/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0011Epoch [93/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.1416Epoch [93/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0035Epoch [93/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0016Epoch [93/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0358Epoch [93/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0039Epoch [93/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0770Epoch [93/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0128Epoch [93/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0001Epoch [93/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0058Epoch [93/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0282Epoch [93/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0207Epoch [93/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0011Epoch [93/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0004Epoch [93/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0163Epoch [93/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0002Epoch [93/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0041Epoch [93/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0039Epoch [93/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0642Epoch [93/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0001Epoch [93/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0014Epoch [93/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0005Epoch [93/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0095Epoch [93/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0738Epoch [93/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0076Epoch [93/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0019Epoch [93/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0052Epoch [93/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0006Epoch [93/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0455Epoch [93/124], Batch [55/125] [########------------] 44.0%, Loss: 0.5521Epoch [93/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0011Epoch [93/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0188Epoch [93/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0002Epoch [93/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0050Epoch [93/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0209Epoch [93/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0036Epoch [93/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0025Epoch [93/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0379Epoch [93/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0003Epoch [93/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0003Epoch [93/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0003Epoch [93/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0193Epoch [93/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0009Epoch [93/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0008Epoch [93/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0006Epoch [93/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0002Epoch [93/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0267Epoch [93/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0001Epoch [93/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0040Epoch [93/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0105Epoch [93/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0372Epoch [93/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0011Epoch [93/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0693Epoch [93/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0004Epoch [93/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0006Epoch [93/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0010Epoch [93/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0029Epoch [93/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0003Epoch [93/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0034Epoch [93/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0728Epoch [93/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0012Epoch [93/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0495Epoch [93/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0009Epoch [93/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0003Epoch [93/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0000Epoch [93/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0023Epoch [93/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0016Epoch [93/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0464Epoch [93/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0129Epoch [93/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0009Epoch [93/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0003Epoch [93/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0387Epoch [93/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0029Epoch [93/124], Batch [99/125] [###############-----] 79.2%, Loss: 1.1428Epoch [93/124], Batch [100/125] [################----] 80.0%, Loss: 0.9146Epoch [93/124], Batch [101/125] [################----] 80.8%, Loss: 0.0176Epoch [93/124], Batch [102/125] [################----] 81.6%, Loss: 0.0047Epoch [93/124], Batch [103/125] [################----] 82.4%, Loss: 0.0107Epoch [93/124], Batch [104/125] [################----] 83.2%, Loss: 0.0005Epoch [93/124], Batch [105/125] [################----] 84.0%, Loss: 0.0011Epoch [93/124], Batch [106/125] [################----] 84.8%, Loss: 0.1049Epoch [93/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0314Epoch [93/124], Batch [108/125] [#################---] 86.4%, Loss: 0.4534Epoch [93/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0008Epoch [93/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0030Epoch [93/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0002Epoch [93/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0000Epoch [93/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0113Epoch [93/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0069Epoch [93/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0166Epoch [93/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0148Epoch [93/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0033Epoch [93/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0005Epoch [93/124], Batch [119/125] [###################-] 95.2%, Loss: 1.3125Epoch [93/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0061Epoch [93/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0579Epoch [93/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0015Epoch [93/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1277Epoch [93/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0031Epoch [93/124], Batch [125/125] [####################] 100.0%, Loss: 0.0007
Epoch [93/124] finished. Average Loss: 0.0577
Training Accuracy: 99.40%
--- Saving checkpoint for epoch 93 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [94/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0085Epoch [94/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0026Epoch [94/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0009Epoch [94/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0004Epoch [94/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0253Epoch [94/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0001Epoch [94/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0236Epoch [94/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0006Epoch [94/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0342Epoch [94/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0013Epoch [94/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.4482Epoch [94/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0051Epoch [94/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0434Epoch [94/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0007Epoch [94/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0002Epoch [94/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0019Epoch [94/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.1704Epoch [94/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0039Epoch [94/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0299Epoch [94/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0011Epoch [94/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0010Epoch [94/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0043Epoch [94/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0005Epoch [94/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0198Epoch [94/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0004Epoch [94/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0049Epoch [94/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0047Epoch [94/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0274Epoch [94/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0092Epoch [94/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0032Epoch [94/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0268Epoch [94/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0245Epoch [94/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.6457Epoch [94/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0313Epoch [94/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0087Epoch [94/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0003Epoch [94/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0007Epoch [94/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.4822Epoch [94/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0057Epoch [94/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0276Epoch [94/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.7337Epoch [94/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0064Epoch [94/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0081Epoch [94/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0006Epoch [94/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0028Epoch [94/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0089Epoch [94/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0010Epoch [94/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0057Epoch [94/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0001Epoch [94/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0009Epoch [94/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0031Epoch [94/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0140Epoch [94/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0002Epoch [94/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0100Epoch [94/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0006Epoch [94/124], Batch [56/125] [########------------] 44.8%, Loss: 0.1025Epoch [94/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0015Epoch [94/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0064Epoch [94/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0008Epoch [94/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0091Epoch [94/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0081Epoch [94/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.5934Epoch [94/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0267Epoch [94/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0007Epoch [94/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.7653Epoch [94/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0002Epoch [94/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0015Epoch [94/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1231Epoch [94/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0056Epoch [94/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0126Epoch [94/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.3833Epoch [94/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0432Epoch [94/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0011Epoch [94/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.6643Epoch [94/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0046Epoch [94/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0009Epoch [94/124], Batch [77/125] [############--------] 61.6%, Loss: 0.5442Epoch [94/124], Batch [78/125] [############--------] 62.4%, Loss: 0.2027Epoch [94/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0046Epoch [94/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0064Epoch [94/124], Batch [81/125] [############--------] 64.8%, Loss: 0.5863Epoch [94/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.3565Epoch [94/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0020Epoch [94/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0013Epoch [94/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0114Epoch [94/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0036Epoch [94/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0184Epoch [94/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0795Epoch [94/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0065Epoch [94/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0014Epoch [94/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0365Epoch [94/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0095Epoch [94/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0009Epoch [94/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0015Epoch [94/124], Batch [95/125] [###############-----] 76.0%, Loss: 1.1536Epoch [94/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0025Epoch [94/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0153Epoch [94/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0023Epoch [94/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0138Epoch [94/124], Batch [100/125] [################----] 80.0%, Loss: 0.0003Epoch [94/124], Batch [101/125] [################----] 80.8%, Loss: 0.0118Epoch [94/124], Batch [102/125] [################----] 81.6%, Loss: 0.2668Epoch [94/124], Batch [103/125] [################----] 82.4%, Loss: 0.0016Epoch [94/124], Batch [104/125] [################----] 83.2%, Loss: 0.0016Epoch [94/124], Batch [105/125] [################----] 84.0%, Loss: 0.0010Epoch [94/124], Batch [106/125] [################----] 84.8%, Loss: 0.7680Epoch [94/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0012Epoch [94/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0126Epoch [94/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0021Epoch [94/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0487Epoch [94/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0445Epoch [94/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0501Epoch [94/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1605Epoch [94/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0490Epoch [94/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0524Epoch [94/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1379Epoch [94/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0793Epoch [94/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0160Epoch [94/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0030Epoch [94/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0640Epoch [94/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0006Epoch [94/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0013Epoch [94/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0065Epoch [94/124], Batch [124/125] [###################-] 99.2%, Loss: 0.2410Epoch [94/124], Batch [125/125] [####################] 100.0%, Loss: 0.0434
Epoch [94/124] finished. Average Loss: 0.0865
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 94 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [95/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.2292Epoch [95/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0180Epoch [95/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.3321Epoch [95/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0066Epoch [95/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0487Epoch [95/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.2087Epoch [95/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0791Epoch [95/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0069Epoch [95/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.1682Epoch [95/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0036Epoch [95/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0034Epoch [95/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0004Epoch [95/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.5365Epoch [95/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0137Epoch [95/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0265Epoch [95/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0329Epoch [95/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0062Epoch [95/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0075Epoch [95/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0052Epoch [95/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0496Epoch [95/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0024Epoch [95/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0042Epoch [95/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0001Epoch [95/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0039Epoch [95/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0005Epoch [95/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0007Epoch [95/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0122Epoch [95/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.1141Epoch [95/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0331Epoch [95/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0286Epoch [95/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0000Epoch [95/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0275Epoch [95/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0032Epoch [95/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0131Epoch [95/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0017Epoch [95/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0075Epoch [95/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.6752Epoch [95/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0205Epoch [95/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3356Epoch [95/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0738Epoch [95/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0402Epoch [95/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0378Epoch [95/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2248Epoch [95/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0130Epoch [95/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0077Epoch [95/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0232Epoch [95/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.1045Epoch [95/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0069Epoch [95/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0518Epoch [95/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0058Epoch [95/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0011Epoch [95/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0013Epoch [95/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0041Epoch [95/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1427Epoch [95/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0327Epoch [95/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0018Epoch [95/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0065Epoch [95/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1748Epoch [95/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0004Epoch [95/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0614Epoch [95/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0194Epoch [95/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.3443Epoch [95/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0012Epoch [95/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0457Epoch [95/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0060Epoch [95/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0220Epoch [95/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.2087Epoch [95/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0030Epoch [95/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0268Epoch [95/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0008Epoch [95/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0042Epoch [95/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.4387Epoch [95/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.4009Epoch [95/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0012Epoch [95/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0325Epoch [95/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0006Epoch [95/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0034Epoch [95/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0639Epoch [95/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0014Epoch [95/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1873Epoch [95/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0024Epoch [95/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0087Epoch [95/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1488Epoch [95/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0011Epoch [95/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0002Epoch [95/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1540Epoch [95/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0012Epoch [95/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0002Epoch [95/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0387Epoch [95/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0022Epoch [95/124], Batch [91/125] [##############------] 72.8%, Loss: 1.5362Epoch [95/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0005Epoch [95/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0003Epoch [95/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2454Epoch [95/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0026Epoch [95/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0081Epoch [95/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0184Epoch [95/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0017Epoch [95/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0080Epoch [95/124], Batch [100/125] [################----] 80.0%, Loss: 0.0110Epoch [95/124], Batch [101/125] [################----] 80.8%, Loss: 0.0032Epoch [95/124], Batch [102/125] [################----] 81.6%, Loss: 0.0266Epoch [95/124], Batch [103/125] [################----] 82.4%, Loss: 0.0246Epoch [95/124], Batch [104/125] [################----] 83.2%, Loss: 0.0056Epoch [95/124], Batch [105/125] [################----] 84.0%, Loss: 0.0654Epoch [95/124], Batch [106/125] [################----] 84.8%, Loss: 0.0050Epoch [95/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0196Epoch [95/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0009Epoch [95/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0214Epoch [95/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0057Epoch [95/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0007Epoch [95/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0029Epoch [95/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0287Epoch [95/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0047Epoch [95/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0047Epoch [95/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0053Epoch [95/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0006Epoch [95/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0047Epoch [95/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0115Epoch [95/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0586Epoch [95/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0048Epoch [95/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0530Epoch [95/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0521Epoch [95/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0407Epoch [95/124], Batch [125/125] [####################] 100.0%, Loss: 0.0019
Epoch [95/124] finished. Average Loss: 0.0763
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 95 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [96/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1244Epoch [96/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0040Epoch [96/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0006Epoch [96/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0443Epoch [96/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0078Epoch [96/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0004Epoch [96/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0313Epoch [96/124], Batch [8/125] [#-------------------] 6.4%, Loss: 1.2936Epoch [96/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0006Epoch [96/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.1240Epoch [96/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0003Epoch [96/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0005Epoch [96/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0301Epoch [96/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0062Epoch [96/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0436Epoch [96/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0075Epoch [96/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0000Epoch [96/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0004Epoch [96/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0221Epoch [96/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0023Epoch [96/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0013Epoch [96/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0053Epoch [96/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0068Epoch [96/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0019Epoch [96/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0000Epoch [96/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0512Epoch [96/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0003Epoch [96/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0108Epoch [96/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0001Epoch [96/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0032Epoch [96/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0065Epoch [96/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0005Epoch [96/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0052Epoch [96/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0001Epoch [96/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0049Epoch [96/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0243Epoch [96/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0522Epoch [96/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0006Epoch [96/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0201Epoch [96/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0065Epoch [96/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0006Epoch [96/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0019Epoch [96/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.2399Epoch [96/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0306Epoch [96/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0011Epoch [96/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0515Epoch [96/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0012Epoch [96/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0002Epoch [96/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0372Epoch [96/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0099Epoch [96/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0630Epoch [96/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0021Epoch [96/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0044Epoch [96/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0093Epoch [96/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0017Epoch [96/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0015Epoch [96/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.3075Epoch [96/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0193Epoch [96/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0004Epoch [96/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0001Epoch [96/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.7496Epoch [96/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0038Epoch [96/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0019Epoch [96/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0011Epoch [96/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0001Epoch [96/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0081Epoch [96/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0064Epoch [96/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0022Epoch [96/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0027Epoch [96/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0080Epoch [96/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0026Epoch [96/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0187Epoch [96/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0076Epoch [96/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0014Epoch [96/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0062Epoch [96/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0011Epoch [96/124], Batch [77/125] [############--------] 61.6%, Loss: 0.8655Epoch [96/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0018Epoch [96/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0317Epoch [96/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0006Epoch [96/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0206Epoch [96/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0004Epoch [96/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0270Epoch [96/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0132Epoch [96/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0003Epoch [96/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0002Epoch [96/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0004Epoch [96/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0073Epoch [96/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0097Epoch [96/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0018Epoch [96/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0002Epoch [96/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0000Epoch [96/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0275Epoch [96/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0006Epoch [96/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0022Epoch [96/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.1267Epoch [96/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0029Epoch [96/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0020Epoch [96/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0148Epoch [96/124], Batch [100/125] [################----] 80.0%, Loss: 0.0049Epoch [96/124], Batch [101/125] [################----] 80.8%, Loss: 0.0150Epoch [96/124], Batch [102/125] [################----] 81.6%, Loss: 0.0143Epoch [96/124], Batch [103/125] [################----] 82.4%, Loss: 0.0000Epoch [96/124], Batch [104/125] [################----] 83.2%, Loss: 0.0005Epoch [96/124], Batch [105/125] [################----] 84.0%, Loss: 0.0131Epoch [96/124], Batch [106/125] [################----] 84.8%, Loss: 0.0066Epoch [96/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0746Epoch [96/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0003Epoch [96/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0232Epoch [96/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0034Epoch [96/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0011Epoch [96/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0012Epoch [96/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0323Epoch [96/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0085Epoch [96/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1519Epoch [96/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0150Epoch [96/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0005Epoch [96/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0009Epoch [96/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0017Epoch [96/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0004Epoch [96/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0052Epoch [96/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0040Epoch [96/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0155Epoch [96/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0005Epoch [96/124], Batch [125/125] [####################] 100.0%, Loss: 0.0086
Epoch [96/124] finished. Average Loss: 0.0409
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 96 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [97/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0000Epoch [97/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0004Epoch [97/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0002Epoch [97/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0022Epoch [97/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0025Epoch [97/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0009Epoch [97/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1018Epoch [97/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0001Epoch [97/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0062Epoch [97/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0091Epoch [97/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0285Epoch [97/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0002Epoch [97/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0028Epoch [97/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0001Epoch [97/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0019Epoch [97/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0027Epoch [97/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0000Epoch [97/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0040Epoch [97/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0026Epoch [97/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.2746Epoch [97/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0018Epoch [97/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0051Epoch [97/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0001Epoch [97/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0002Epoch [97/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0016Epoch [97/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0044Epoch [97/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0156Epoch [97/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0001Epoch [97/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0001Epoch [97/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0001Epoch [97/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0004Epoch [97/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0098Epoch [97/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0016Epoch [97/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0002Epoch [97/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0009Epoch [97/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0003Epoch [97/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0082Epoch [97/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0005Epoch [97/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0810Epoch [97/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0001Epoch [97/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0001Epoch [97/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0003Epoch [97/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0003Epoch [97/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0007Epoch [97/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0011Epoch [97/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0182Epoch [97/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0036Epoch [97/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0001Epoch [97/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0793Epoch [97/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0003Epoch [97/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0022Epoch [97/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0303Epoch [97/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0186Epoch [97/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0014Epoch [97/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0282Epoch [97/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0010Epoch [97/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0662Epoch [97/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0528Epoch [97/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0008Epoch [97/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0074Epoch [97/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0052Epoch [97/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0013Epoch [97/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0031Epoch [97/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0023Epoch [97/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0005Epoch [97/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0267Epoch [97/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0000Epoch [97/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0042Epoch [97/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0002Epoch [97/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0362Epoch [97/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0010Epoch [97/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0044Epoch [97/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.3719Epoch [97/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1145Epoch [97/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0150Epoch [97/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0008Epoch [97/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0002Epoch [97/124], Batch [78/125] [############--------] 62.4%, Loss: 0.3524Epoch [97/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0013Epoch [97/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0047Epoch [97/124], Batch [81/125] [############--------] 64.8%, Loss: 0.2384Epoch [97/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0001Epoch [97/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0010Epoch [97/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0091Epoch [97/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0012Epoch [97/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0020Epoch [97/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0002Epoch [97/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0001Epoch [97/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0206Epoch [97/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0003Epoch [97/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0000Epoch [97/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0004Epoch [97/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0058Epoch [97/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0005Epoch [97/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0064Epoch [97/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0007Epoch [97/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0012Epoch [97/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0192Epoch [97/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0043Epoch [97/124], Batch [100/125] [################----] 80.0%, Loss: 1.0264Epoch [97/124], Batch [101/125] [################----] 80.8%, Loss: 0.0182Epoch [97/124], Batch [102/125] [################----] 81.6%, Loss: 0.0139Epoch [97/124], Batch [103/125] [################----] 82.4%, Loss: 0.0604Epoch [97/124], Batch [104/125] [################----] 83.2%, Loss: 0.0028Epoch [97/124], Batch [105/125] [################----] 84.0%, Loss: 0.0002Epoch [97/124], Batch [106/125] [################----] 84.8%, Loss: 0.0149Epoch [97/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0058Epoch [97/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0250Epoch [97/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0034Epoch [97/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0003Epoch [97/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0461Epoch [97/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0002Epoch [97/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0018Epoch [97/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0075Epoch [97/124], Batch [115/125] [##################--] 92.0%, Loss: 1.0290Epoch [97/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0001Epoch [97/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0010Epoch [97/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0002Epoch [97/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0044Epoch [97/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0153Epoch [97/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0234Epoch [97/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0013Epoch [97/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0022Epoch [97/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0051Epoch [97/124], Batch [125/125] [####################] 100.0%, Loss: 0.0534
Epoch [97/124] finished. Average Loss: 0.0360
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 97 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [98/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0003Epoch [98/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0083Epoch [98/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0003Epoch [98/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0017Epoch [98/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1399Epoch [98/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0025Epoch [98/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0026Epoch [98/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0010Epoch [98/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0020Epoch [98/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0012Epoch [98/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0005Epoch [98/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0171Epoch [98/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0041Epoch [98/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0580Epoch [98/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0003Epoch [98/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0020Epoch [98/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0006Epoch [98/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0030Epoch [98/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0986Epoch [98/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0001Epoch [98/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0005Epoch [98/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2325Epoch [98/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0984Epoch [98/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0002Epoch [98/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0827Epoch [98/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0000Epoch [98/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0042Epoch [98/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0076Epoch [98/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0389Epoch [98/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0015Epoch [98/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0060Epoch [98/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0010Epoch [98/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0148Epoch [98/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0041Epoch [98/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0006Epoch [98/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0034Epoch [98/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0006Epoch [98/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0007Epoch [98/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.3312Epoch [98/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0008Epoch [98/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0010Epoch [98/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0087Epoch [98/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0024Epoch [98/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0023Epoch [98/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.2891Epoch [98/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0049Epoch [98/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0133Epoch [98/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.4013Epoch [98/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0593Epoch [98/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0243Epoch [98/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0005Epoch [98/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0029Epoch [98/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0016Epoch [98/124], Batch [54/125] [########------------] 43.2%, Loss: 0.2477Epoch [98/124], Batch [55/125] [########------------] 44.0%, Loss: 0.3191Epoch [98/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0077Epoch [98/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0021Epoch [98/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0016Epoch [98/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0098Epoch [98/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0001Epoch [98/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0043Epoch [98/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0885Epoch [98/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1023Epoch [98/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0002Epoch [98/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0030Epoch [98/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0228Epoch [98/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0186Epoch [98/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0015Epoch [98/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0080Epoch [98/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0433Epoch [98/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0129Epoch [98/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0004Epoch [98/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0002Epoch [98/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0004Epoch [98/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0012Epoch [98/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0058Epoch [98/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0302Epoch [98/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0031Epoch [98/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0021Epoch [98/124], Batch [80/125] [############--------] 64.0%, Loss: 0.1276Epoch [98/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0028Epoch [98/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0171Epoch [98/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0072Epoch [98/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0010Epoch [98/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0001Epoch [98/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0006Epoch [98/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0006Epoch [98/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0179Epoch [98/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0141Epoch [98/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0008Epoch [98/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0436Epoch [98/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0066Epoch [98/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0008Epoch [98/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0023Epoch [98/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0052Epoch [98/124], Batch [96/125] [###############-----] 76.8%, Loss: 1.2576Epoch [98/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0005Epoch [98/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0005Epoch [98/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0003Epoch [98/124], Batch [100/125] [################----] 80.0%, Loss: 0.0022Epoch [98/124], Batch [101/125] [################----] 80.8%, Loss: 0.0185Epoch [98/124], Batch [102/125] [################----] 81.6%, Loss: 0.0004Epoch [98/124], Batch [103/125] [################----] 82.4%, Loss: 0.0002Epoch [98/124], Batch [104/125] [################----] 83.2%, Loss: 0.0071Epoch [98/124], Batch [105/125] [################----] 84.0%, Loss: 0.0047Epoch [98/124], Batch [106/125] [################----] 84.8%, Loss: 0.0001Epoch [98/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0007Epoch [98/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0001Epoch [98/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0261Epoch [98/124], Batch [110/125] [#################---] 88.0%, Loss: 0.3681Epoch [98/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0012Epoch [98/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0006Epoch [98/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0014Epoch [98/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0015Epoch [98/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0004Epoch [98/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0084Epoch [98/124], Batch [117/125] [##################--] 93.6%, Loss: 0.2391Epoch [98/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0025Epoch [98/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0029Epoch [98/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0051Epoch [98/124], Batch [121/125] [###################-] 96.8%, Loss: 0.2786Epoch [98/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0014Epoch [98/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0020Epoch [98/124], Batch [124/125] [###################-] 99.2%, Loss: 1.0497Epoch [98/124], Batch [125/125] [####################] 100.0%, Loss: 0.0001
Epoch [98/124] finished. Average Loss: 0.0516
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 98 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [99/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0004Epoch [99/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0013Epoch [99/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0055Epoch [99/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0004Epoch [99/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0132Epoch [99/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0020Epoch [99/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0042Epoch [99/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0001Epoch [99/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0012Epoch [99/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0039Epoch [99/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0000Epoch [99/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0009Epoch [99/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0037Epoch [99/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0002Epoch [99/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0006Epoch [99/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0509Epoch [99/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0394Epoch [99/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0457Epoch [99/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.4911Epoch [99/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0023Epoch [99/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0104Epoch [99/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0096Epoch [99/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.5586Epoch [99/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0458Epoch [99/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0338Epoch [99/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0002Epoch [99/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0133Epoch [99/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0084Epoch [99/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0365Epoch [99/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0032Epoch [99/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0007Epoch [99/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0003Epoch [99/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0032Epoch [99/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0005Epoch [99/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0121Epoch [99/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0021Epoch [99/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0071Epoch [99/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0933Epoch [99/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0423Epoch [99/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0179Epoch [99/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0061Epoch [99/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0087Epoch [99/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0012Epoch [99/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0023Epoch [99/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0014Epoch [99/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0020Epoch [99/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0001Epoch [99/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0513Epoch [99/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0237Epoch [99/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0013Epoch [99/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0010Epoch [99/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0014Epoch [99/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0055Epoch [99/124], Batch [54/125] [########------------] 43.2%, Loss: 0.2445Epoch [99/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0172Epoch [99/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0087Epoch [99/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0011Epoch [99/124], Batch [58/125] [#########-----------] 46.4%, Loss: 1.3121Epoch [99/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0020Epoch [99/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0105Epoch [99/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0004Epoch [99/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0007Epoch [99/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0001Epoch [99/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0612Epoch [99/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0512Epoch [99/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0866Epoch [99/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0052Epoch [99/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0060Epoch [99/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0218Epoch [99/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0005Epoch [99/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0032Epoch [99/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0024Epoch [99/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0009Epoch [99/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0359Epoch [99/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0118Epoch [99/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0045Epoch [99/124], Batch [77/125] [############--------] 61.6%, Loss: 0.5399Epoch [99/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0017Epoch [99/124], Batch [79/125] [############--------] 63.2%, Loss: 0.2562Epoch [99/124], Batch [80/125] [############--------] 64.0%, Loss: 1.1869Epoch [99/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0021Epoch [99/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0182Epoch [99/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.5209Epoch [99/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0020Epoch [99/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0024Epoch [99/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1281Epoch [99/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0053Epoch [99/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0050Epoch [99/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0015Epoch [99/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0248Epoch [99/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0157Epoch [99/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0141Epoch [99/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0357Epoch [99/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1500Epoch [99/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0666Epoch [99/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0060Epoch [99/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0193Epoch [99/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0014Epoch [99/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0094Epoch [99/124], Batch [100/125] [################----] 80.0%, Loss: 0.0016Epoch [99/124], Batch [101/125] [################----] 80.8%, Loss: 0.0126Epoch [99/124], Batch [102/125] [################----] 81.6%, Loss: 0.0185Epoch [99/124], Batch [103/125] [################----] 82.4%, Loss: 0.0075Epoch [99/124], Batch [104/125] [################----] 83.2%, Loss: 0.0087Epoch [99/124], Batch [105/125] [################----] 84.0%, Loss: 0.0007Epoch [99/124], Batch [106/125] [################----] 84.8%, Loss: 0.0890Epoch [99/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0070Epoch [99/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0733Epoch [99/124], Batch [109/125] [#################---] 87.2%, Loss: 0.3037Epoch [99/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0427Epoch [99/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0767Epoch [99/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0008Epoch [99/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0133Epoch [99/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0016Epoch [99/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0893Epoch [99/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0108Epoch [99/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0002Epoch [99/124], Batch [118/125] [##################--] 94.4%, Loss: 0.1722Epoch [99/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0423Epoch [99/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0124Epoch [99/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0024Epoch [99/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0363Epoch [99/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0074Epoch [99/124], Batch [124/125] [###################-] 99.2%, Loss: 0.5029Epoch [99/124], Batch [125/125] [####################] 100.0%, Loss: 0.0075
Epoch [99/124] finished. Average Loss: 0.0649
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 99 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [100/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0001Epoch [100/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0000Epoch [100/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0029Epoch [100/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0219Epoch [100/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0204Epoch [100/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0274Epoch [100/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0007Epoch [100/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0003Epoch [100/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0040Epoch [100/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0270Epoch [100/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0057Epoch [100/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0005Epoch [100/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0526Epoch [100/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0004Epoch [100/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0013Epoch [100/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0014Epoch [100/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0013Epoch [100/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0010Epoch [100/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0003Epoch [100/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0063Epoch [100/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0012Epoch [100/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0119Epoch [100/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0019Epoch [100/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0866Epoch [100/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0015Epoch [100/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0036Epoch [100/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0002Epoch [100/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0003Epoch [100/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0009Epoch [100/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0472Epoch [100/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0141Epoch [100/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0120Epoch [100/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0001Epoch [100/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0000Epoch [100/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0035Epoch [100/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0029Epoch [100/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0012Epoch [100/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0023Epoch [100/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0010Epoch [100/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0024Epoch [100/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0189Epoch [100/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0058Epoch [100/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0004Epoch [100/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0003Epoch [100/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0014Epoch [100/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0057Epoch [100/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0023Epoch [100/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0008Epoch [100/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.4071Epoch [100/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0001Epoch [100/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0010Epoch [100/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0098Epoch [100/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0005Epoch [100/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0010Epoch [100/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0142Epoch [100/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0926Epoch [100/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0011Epoch [100/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0005Epoch [100/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0006Epoch [100/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0006Epoch [100/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0002Epoch [100/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0010Epoch [100/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0002Epoch [100/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0050Epoch [100/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0038Epoch [100/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.4891Epoch [100/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0161Epoch [100/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0003Epoch [100/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0012Epoch [100/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0049Epoch [100/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0028Epoch [100/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0004Epoch [100/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0573Epoch [100/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0102Epoch [100/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0062Epoch [100/124], Batch [76/125] [############--------] 60.8%, Loss: 0.2074Epoch [100/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0314Epoch [100/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0007Epoch [100/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0034Epoch [100/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0140Epoch [100/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0023Epoch [100/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.2447Epoch [100/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.1093Epoch [100/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0009Epoch [100/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0001Epoch [100/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0025Epoch [100/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0013Epoch [100/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0021Epoch [100/124], Batch [89/125] [##############------] 71.2%, Loss: 0.5817Epoch [100/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0029Epoch [100/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0004Epoch [100/124], Batch [92/125] [##############------] 73.6%, Loss: 0.4352Epoch [100/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0024Epoch [100/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1035Epoch [100/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0007Epoch [100/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0023Epoch [100/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0002Epoch [100/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0014Epoch [100/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0119Epoch [100/124], Batch [100/125] [################----] 80.0%, Loss: 0.0012Epoch [100/124], Batch [101/125] [################----] 80.8%, Loss: 0.0126Epoch [100/124], Batch [102/125] [################----] 81.6%, Loss: 0.0138Epoch [100/124], Batch [103/125] [################----] 82.4%, Loss: 0.0019Epoch [100/124], Batch [104/125] [################----] 83.2%, Loss: 0.0001Epoch [100/124], Batch [105/125] [################----] 84.0%, Loss: 0.0049Epoch [100/124], Batch [106/125] [################----] 84.8%, Loss: 0.0113Epoch [100/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0092Epoch [100/124], Batch [108/125] [#################---] 86.4%, Loss: 0.9812Epoch [100/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0001Epoch [100/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0023Epoch [100/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0027Epoch [100/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0024Epoch [100/124], Batch [113/125] [##################--] 90.4%, Loss: 0.2230Epoch [100/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0009Epoch [100/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0027Epoch [100/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1939Epoch [100/124], Batch [117/125] [##################--] 93.6%, Loss: 1.2406Epoch [100/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0005Epoch [100/124], Batch [119/125] [###################-] 95.2%, Loss: 0.1389Epoch [100/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0221Epoch [100/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0057Epoch [100/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0017Epoch [100/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0072Epoch [100/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0016Epoch [100/124], Batch [125/125] [####################] 100.0%, Loss: 0.0163
Epoch [100/124] finished. Average Loss: 0.0496
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 100 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [101/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0013Epoch [101/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0057Epoch [101/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.4104Epoch [101/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0490Epoch [101/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0102Epoch [101/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.5314Epoch [101/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1229Epoch [101/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0080Epoch [101/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0026Epoch [101/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0051Epoch [101/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0008Epoch [101/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0091Epoch [101/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0259Epoch [101/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0026Epoch [101/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0156Epoch [101/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0070Epoch [101/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0005Epoch [101/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0030Epoch [101/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0176Epoch [101/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0003Epoch [101/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0231Epoch [101/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0024Epoch [101/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0683Epoch [101/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0395Epoch [101/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0036Epoch [101/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0418Epoch [101/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0332Epoch [101/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0028Epoch [101/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0070Epoch [101/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0083Epoch [101/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0426Epoch [101/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0873Epoch [101/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0116Epoch [101/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0597Epoch [101/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0043Epoch [101/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0035Epoch [101/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0089Epoch [101/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0129Epoch [101/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0017Epoch [101/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0730Epoch [101/124], Batch [41/125] [######--------------] 32.8%, Loss: 2.0677Epoch [101/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0197Epoch [101/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0030Epoch [101/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0420Epoch [101/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0021Epoch [101/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0024Epoch [101/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0603Epoch [101/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0000Epoch [101/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0144Epoch [101/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0294Epoch [101/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0009Epoch [101/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0227Epoch [101/124], Batch [53/125] [########------------] 42.4%, Loss: 0.7371Epoch [101/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0009Epoch [101/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0136Epoch [101/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0225Epoch [101/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0050Epoch [101/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0073Epoch [101/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.1021Epoch [101/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0012Epoch [101/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0017Epoch [101/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0074Epoch [101/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.2432Epoch [101/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0011Epoch [101/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0002Epoch [101/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.3238Epoch [101/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0015Epoch [101/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.4077Epoch [101/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0032Epoch [101/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0015Epoch [101/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0057Epoch [101/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0004Epoch [101/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0086Epoch [101/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0019Epoch [101/124], Batch [75/125] [############--------] 60.0%, Loss: 0.2114Epoch [101/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0204Epoch [101/124], Batch [77/125] [############--------] 61.6%, Loss: 2.8924Epoch [101/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0106Epoch [101/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0041Epoch [101/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0327Epoch [101/124], Batch [81/125] [############--------] 64.8%, Loss: 0.2468Epoch [101/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0031Epoch [101/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0011Epoch [101/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.6082Epoch [101/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0087Epoch [101/124], Batch [86/125] [#############-------] 68.8%, Loss: 1.0816Epoch [101/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0031Epoch [101/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0043Epoch [101/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0174Epoch [101/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0029Epoch [101/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0886Epoch [101/124], Batch [92/125] [##############------] 73.6%, Loss: 1.3209Epoch [101/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1662Epoch [101/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.3563Epoch [101/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0124Epoch [101/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0005Epoch [101/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0006Epoch [101/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0197Epoch [101/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0086Epoch [101/124], Batch [100/125] [################----] 80.0%, Loss: 0.0174Epoch [101/124], Batch [101/125] [################----] 80.8%, Loss: 0.0392Epoch [101/124], Batch [102/125] [################----] 81.6%, Loss: 0.0468Epoch [101/124], Batch [103/125] [################----] 82.4%, Loss: 0.0025Epoch [101/124], Batch [104/125] [################----] 83.2%, Loss: 0.1007Epoch [101/124], Batch [105/125] [################----] 84.0%, Loss: 0.6588Epoch [101/124], Batch [106/125] [################----] 84.8%, Loss: 0.0075Epoch [101/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0005Epoch [101/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0577Epoch [101/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0162Epoch [101/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0753Epoch [101/124], Batch [111/125] [#################---] 88.8%, Loss: 0.4480Epoch [101/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0003Epoch [101/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0039Epoch [101/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0046Epoch [101/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0032Epoch [101/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0067Epoch [101/124], Batch [117/125] [##################--] 93.6%, Loss: 0.4838Epoch [101/124], Batch [118/125] [##################--] 94.4%, Loss: 0.4932Epoch [101/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0008Epoch [101/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0044Epoch [101/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0079Epoch [101/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2089Epoch [101/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0055Epoch [101/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0016Epoch [101/124], Batch [125/125] [####################] 100.0%, Loss: 0.0139
Epoch [101/124] finished. Average Loss: 0.1261
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 101 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [102/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.4729Epoch [102/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0086Epoch [102/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0430Epoch [102/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0275Epoch [102/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0038Epoch [102/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.6215Epoch [102/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0018Epoch [102/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0390Epoch [102/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0024Epoch [102/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0341Epoch [102/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0003Epoch [102/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0005Epoch [102/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2022Epoch [102/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0511Epoch [102/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0031Epoch [102/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0197Epoch [102/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0009Epoch [102/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0032Epoch [102/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0658Epoch [102/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.6837Epoch [102/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0231Epoch [102/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0093Epoch [102/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0002Epoch [102/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0544Epoch [102/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0034Epoch [102/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0044Epoch [102/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0027Epoch [102/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0054Epoch [102/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0598Epoch [102/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0033Epoch [102/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1224Epoch [102/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0680Epoch [102/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0154Epoch [102/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0507Epoch [102/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0756Epoch [102/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0057Epoch [102/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0286Epoch [102/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0685Epoch [102/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.1354Epoch [102/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0088Epoch [102/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.1409Epoch [102/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0018Epoch [102/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.4576Epoch [102/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0056Epoch [102/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0120Epoch [102/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0005Epoch [102/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0010Epoch [102/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0008Epoch [102/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0306Epoch [102/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0648Epoch [102/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0637Epoch [102/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0012Epoch [102/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0517Epoch [102/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1990Epoch [102/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0011Epoch [102/124], Batch [56/125] [########------------] 44.8%, Loss: 0.2402Epoch [102/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0752Epoch [102/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0757Epoch [102/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0015Epoch [102/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.4807Epoch [102/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0003Epoch [102/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0009Epoch [102/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0006Epoch [102/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0473Epoch [102/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0007Epoch [102/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0034Epoch [102/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0072Epoch [102/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.5916Epoch [102/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0142Epoch [102/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.5993Epoch [102/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0012Epoch [102/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0013Epoch [102/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0075Epoch [102/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0121Epoch [102/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0016Epoch [102/124], Batch [76/125] [############--------] 60.8%, Loss: 0.1588Epoch [102/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0028Epoch [102/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0013Epoch [102/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0233Epoch [102/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0361Epoch [102/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1195Epoch [102/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1395Epoch [102/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0040Epoch [102/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0001Epoch [102/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0018Epoch [102/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0003Epoch [102/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0236Epoch [102/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0014Epoch [102/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0137Epoch [102/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0082Epoch [102/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0373Epoch [102/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0080Epoch [102/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0046Epoch [102/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0746Epoch [102/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3134Epoch [102/124], Batch [96/125] [###############-----] 76.8%, Loss: 1.0771Epoch [102/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0288Epoch [102/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.5929Epoch [102/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0002Epoch [102/124], Batch [100/125] [################----] 80.0%, Loss: 0.0058Epoch [102/124], Batch [101/125] [################----] 80.8%, Loss: 0.1402Epoch [102/124], Batch [102/125] [################----] 81.6%, Loss: 0.0084Epoch [102/124], Batch [103/125] [################----] 82.4%, Loss: 0.0128Epoch [102/124], Batch [104/125] [################----] 83.2%, Loss: 0.4244Epoch [102/124], Batch [105/125] [################----] 84.0%, Loss: 0.0352Epoch [102/124], Batch [106/125] [################----] 84.8%, Loss: 0.0023Epoch [102/124], Batch [107/125] [#################---] 85.6%, Loss: 0.7074Epoch [102/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0051Epoch [102/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0002Epoch [102/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0051Epoch [102/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0004Epoch [102/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0008Epoch [102/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0195Epoch [102/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0001Epoch [102/124], Batch [115/125] [##################--] 92.0%, Loss: 0.1950Epoch [102/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0070Epoch [102/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0028Epoch [102/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0027Epoch [102/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0709Epoch [102/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0004Epoch [102/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0144Epoch [102/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0535Epoch [102/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0006Epoch [102/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0382Epoch [102/124], Batch [125/125] [####################] 100.0%, Loss: 0.1285
Epoch [102/124] finished. Average Loss: 0.0862
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 102 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [103/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0020Epoch [103/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1533Epoch [103/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0017Epoch [103/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0022Epoch [103/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0063Epoch [103/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0500Epoch [103/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0314Epoch [103/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0064Epoch [103/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0002Epoch [103/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0011Epoch [103/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1160Epoch [103/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0071Epoch [103/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0007Epoch [103/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0109Epoch [103/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0078Epoch [103/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0021Epoch [103/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0031Epoch [103/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0134Epoch [103/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0006Epoch [103/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1449Epoch [103/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0323Epoch [103/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0056Epoch [103/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0055Epoch [103/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0003Epoch [103/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0003Epoch [103/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0585Epoch [103/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0061Epoch [103/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0074Epoch [103/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0004Epoch [103/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0030Epoch [103/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0121Epoch [103/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0038Epoch [103/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0643Epoch [103/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0091Epoch [103/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0388Epoch [103/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0053Epoch [103/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0766Epoch [103/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0095Epoch [103/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0079Epoch [103/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0007Epoch [103/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.8630Epoch [103/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0954Epoch [103/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0012Epoch [103/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0070Epoch [103/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0001Epoch [103/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0004Epoch [103/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0009Epoch [103/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0029Epoch [103/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0012Epoch [103/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0038Epoch [103/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0009Epoch [103/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0026Epoch [103/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0452Epoch [103/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0002Epoch [103/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0644Epoch [103/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0044Epoch [103/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0476Epoch [103/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0004Epoch [103/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0078Epoch [103/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0050Epoch [103/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0003Epoch [103/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0160Epoch [103/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0008Epoch [103/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0001Epoch [103/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0091Epoch [103/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0441Epoch [103/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0002Epoch [103/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0052Epoch [103/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0142Epoch [103/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0006Epoch [103/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0013Epoch [103/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.7857Epoch [103/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0001Epoch [103/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0002Epoch [103/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0004Epoch [103/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0003Epoch [103/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0004Epoch [103/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0114Epoch [103/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0077Epoch [103/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0003Epoch [103/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0002Epoch [103/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0022Epoch [103/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0077Epoch [103/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0080Epoch [103/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0043Epoch [103/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1490Epoch [103/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0035Epoch [103/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0039Epoch [103/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0021Epoch [103/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0018Epoch [103/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0149Epoch [103/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0005Epoch [103/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0001Epoch [103/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0059Epoch [103/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0003Epoch [103/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0015Epoch [103/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0112Epoch [103/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0011Epoch [103/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0068Epoch [103/124], Batch [100/125] [################----] 80.0%, Loss: 0.1940Epoch [103/124], Batch [101/125] [################----] 80.8%, Loss: 0.0009Epoch [103/124], Batch [102/125] [################----] 81.6%, Loss: 0.0001Epoch [103/124], Batch [103/125] [################----] 82.4%, Loss: 0.0175Epoch [103/124], Batch [104/125] [################----] 83.2%, Loss: 0.1211Epoch [103/124], Batch [105/125] [################----] 84.0%, Loss: 0.0021Epoch [103/124], Batch [106/125] [################----] 84.8%, Loss: 0.0134Epoch [103/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0027Epoch [103/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0104Epoch [103/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0034Epoch [103/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0011Epoch [103/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0010Epoch [103/124], Batch [112/125] [#################---] 89.6%, Loss: 0.9882Epoch [103/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0032Epoch [103/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0066Epoch [103/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0037Epoch [103/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0253Epoch [103/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0065Epoch [103/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0000Epoch [103/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0000Epoch [103/124], Batch [120/125] [###################-] 96.0%, Loss: 0.1256Epoch [103/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0634Epoch [103/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0012Epoch [103/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0035Epoch [103/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0090Epoch [103/124], Batch [125/125] [####################] 100.0%, Loss: 0.1553
Epoch [103/124] finished. Average Loss: 0.0396
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 103 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [104/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0022Epoch [104/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0002Epoch [104/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0051Epoch [104/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0468Epoch [104/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0000Epoch [104/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0006Epoch [104/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0000Epoch [104/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0617Epoch [104/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0008Epoch [104/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0177Epoch [104/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0430Epoch [104/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0343Epoch [104/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0008Epoch [104/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0298Epoch [104/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0064Epoch [104/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0004Epoch [104/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0003Epoch [104/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0011Epoch [104/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0029Epoch [104/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0003Epoch [104/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0049Epoch [104/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0068Epoch [104/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0000Epoch [104/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0023Epoch [104/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0035Epoch [104/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0003Epoch [104/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0000Epoch [104/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0001Epoch [104/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0003Epoch [104/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0001Epoch [104/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0003Epoch [104/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0009Epoch [104/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0905Epoch [104/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0004Epoch [104/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0203Epoch [104/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0005Epoch [104/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0003Epoch [104/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0015Epoch [104/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0007Epoch [104/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0012Epoch [104/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0985Epoch [104/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0001Epoch [104/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0001Epoch [104/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0009Epoch [104/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0000Epoch [104/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0001Epoch [104/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0006Epoch [104/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0003Epoch [104/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0047Epoch [104/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0007Epoch [104/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0028Epoch [104/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0136Epoch [104/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0504Epoch [104/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0000Epoch [104/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0000Epoch [104/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0005Epoch [104/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0001Epoch [104/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0026Epoch [104/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0126Epoch [104/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0013Epoch [104/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0098Epoch [104/124], Batch [62/125] [#########-----------] 49.6%, Loss: 1.0641Epoch [104/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0003Epoch [104/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0005Epoch [104/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0001Epoch [104/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0006Epoch [104/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0009Epoch [104/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0018Epoch [104/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0001Epoch [104/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0009Epoch [104/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0027Epoch [104/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0000Epoch [104/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0125Epoch [104/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0005Epoch [104/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0064Epoch [104/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0025Epoch [104/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0011Epoch [104/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0069Epoch [104/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0001Epoch [104/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0015Epoch [104/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0008Epoch [104/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0002Epoch [104/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0038Epoch [104/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0004Epoch [104/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0013Epoch [104/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0005Epoch [104/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0162Epoch [104/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0662Epoch [104/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0002Epoch [104/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0731Epoch [104/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0099Epoch [104/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0011Epoch [104/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0005Epoch [104/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0003Epoch [104/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0002Epoch [104/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0098Epoch [104/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0111Epoch [104/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0004Epoch [104/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0003Epoch [104/124], Batch [100/125] [################----] 80.0%, Loss: 0.0133Epoch [104/124], Batch [101/125] [################----] 80.8%, Loss: 0.7640Epoch [104/124], Batch [102/125] [################----] 81.6%, Loss: 0.0018Epoch [104/124], Batch [103/125] [################----] 82.4%, Loss: 0.0241Epoch [104/124], Batch [104/125] [################----] 83.2%, Loss: 0.0014Epoch [104/124], Batch [105/125] [################----] 84.0%, Loss: 0.0027Epoch [104/124], Batch [106/125] [################----] 84.8%, Loss: 0.1131Epoch [104/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0138Epoch [104/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0001Epoch [104/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0006Epoch [104/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0001Epoch [104/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0143Epoch [104/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0001Epoch [104/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0000Epoch [104/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0018Epoch [104/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0002Epoch [104/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0000Epoch [104/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0018Epoch [104/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0000Epoch [104/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0004Epoch [104/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0011Epoch [104/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0003Epoch [104/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0159Epoch [104/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0000Epoch [104/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0008Epoch [104/124], Batch [125/125] [####################] 100.0%, Loss: 0.0049
Epoch [104/124] finished. Average Loss: 0.0229
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 104 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [105/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0231Epoch [105/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0003Epoch [105/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0011Epoch [105/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0402Epoch [105/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.1604Epoch [105/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0003Epoch [105/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0069Epoch [105/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0005Epoch [105/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0000Epoch [105/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0016Epoch [105/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0007Epoch [105/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0009Epoch [105/124], Batch [13/125] [##------------------] 10.4%, Loss: 1.0950Epoch [105/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0465Epoch [105/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0048Epoch [105/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0014Epoch [105/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0003Epoch [105/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0410Epoch [105/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0089Epoch [105/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0006Epoch [105/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0026Epoch [105/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0006Epoch [105/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0252Epoch [105/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0021Epoch [105/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0389Epoch [105/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0011Epoch [105/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0002Epoch [105/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0014Epoch [105/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0002Epoch [105/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0028Epoch [105/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0074Epoch [105/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2641Epoch [105/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0006Epoch [105/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0007Epoch [105/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0275Epoch [105/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0022Epoch [105/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0001Epoch [105/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0000Epoch [105/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0041Epoch [105/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0015Epoch [105/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0013Epoch [105/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0048Epoch [105/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0895Epoch [105/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0001Epoch [105/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0011Epoch [105/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0213Epoch [105/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0007Epoch [105/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0001Epoch [105/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0057Epoch [105/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0005Epoch [105/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0026Epoch [105/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0021Epoch [105/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0001Epoch [105/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0062Epoch [105/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0002Epoch [105/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0016Epoch [105/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0147Epoch [105/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0003Epoch [105/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0007Epoch [105/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0010Epoch [105/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0005Epoch [105/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0000Epoch [105/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0001Epoch [105/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0042Epoch [105/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0012Epoch [105/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0061Epoch [105/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0001Epoch [105/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0024Epoch [105/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0010Epoch [105/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0025Epoch [105/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0001Epoch [105/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0097Epoch [105/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0062Epoch [105/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0015Epoch [105/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0044Epoch [105/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0006Epoch [105/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0000Epoch [105/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0014Epoch [105/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0025Epoch [105/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0000Epoch [105/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0026Epoch [105/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0001Epoch [105/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0150Epoch [105/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0003Epoch [105/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0014Epoch [105/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0028Epoch [105/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0002Epoch [105/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0083Epoch [105/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0011Epoch [105/124], Batch [90/125] [##############------] 72.0%, Loss: 0.2369Epoch [105/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0002Epoch [105/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0005Epoch [105/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0002Epoch [105/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0018Epoch [105/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2479Epoch [105/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0025Epoch [105/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0049Epoch [105/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0005Epoch [105/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0005Epoch [105/124], Batch [100/125] [################----] 80.0%, Loss: 0.0086Epoch [105/124], Batch [101/125] [################----] 80.8%, Loss: 0.0007Epoch [105/124], Batch [102/125] [################----] 81.6%, Loss: 0.0008Epoch [105/124], Batch [103/125] [################----] 82.4%, Loss: 0.0001Epoch [105/124], Batch [104/125] [################----] 83.2%, Loss: 0.1634Epoch [105/124], Batch [105/125] [################----] 84.0%, Loss: 0.0015Epoch [105/124], Batch [106/125] [################----] 84.8%, Loss: 0.0084Epoch [105/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0035Epoch [105/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0042Epoch [105/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0131Epoch [105/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0264Epoch [105/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0395Epoch [105/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0157Epoch [105/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0046Epoch [105/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0011Epoch [105/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0001Epoch [105/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0010Epoch [105/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0002Epoch [105/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0010Epoch [105/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0115Epoch [105/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0001Epoch [105/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0116Epoch [105/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0002Epoch [105/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0086Epoch [105/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0001Epoch [105/124], Batch [125/125] [####################] 100.0%, Loss: 0.0048
Epoch [105/124] finished. Average Loss: 0.0230
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 105 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [106/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0012Epoch [106/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0025Epoch [106/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0005Epoch [106/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0000Epoch [106/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0019Epoch [106/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0025Epoch [106/124], Batch [7/125] [#-------------------] 5.6%, Loss: 1.0044Epoch [106/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0000Epoch [106/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0018Epoch [106/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0001Epoch [106/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0001Epoch [106/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0025Epoch [106/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0007Epoch [106/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0017Epoch [106/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0038Epoch [106/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0003Epoch [106/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0003Epoch [106/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0024Epoch [106/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0008Epoch [106/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0012Epoch [106/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0002Epoch [106/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0028Epoch [106/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0016Epoch [106/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0006Epoch [106/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0000Epoch [106/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0105Epoch [106/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0040Epoch [106/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0566Epoch [106/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0010Epoch [106/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0031Epoch [106/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0005Epoch [106/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0024Epoch [106/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0022Epoch [106/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0013Epoch [106/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0015Epoch [106/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0003Epoch [106/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0009Epoch [106/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0027Epoch [106/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0817Epoch [106/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0534Epoch [106/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0001Epoch [106/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0002Epoch [106/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0056Epoch [106/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0011Epoch [106/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0001Epoch [106/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0009Epoch [106/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0092Epoch [106/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0004Epoch [106/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0002Epoch [106/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0034Epoch [106/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0000Epoch [106/124], Batch [52/125] [########------------] 41.6%, Loss: 0.2767Epoch [106/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0029Epoch [106/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0001Epoch [106/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0006Epoch [106/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0072Epoch [106/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0003Epoch [106/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0218Epoch [106/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0006Epoch [106/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0002Epoch [106/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0010Epoch [106/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0006Epoch [106/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0052Epoch [106/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0097Epoch [106/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0005Epoch [106/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0002Epoch [106/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0036Epoch [106/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0001Epoch [106/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0001Epoch [106/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0072Epoch [106/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0003Epoch [106/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0009Epoch [106/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0012Epoch [106/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0281Epoch [106/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0020Epoch [106/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0059Epoch [106/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0003Epoch [106/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0002Epoch [106/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0280Epoch [106/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0042Epoch [106/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0001Epoch [106/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0017Epoch [106/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0001Epoch [106/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0034Epoch [106/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0004Epoch [106/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0001Epoch [106/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0010Epoch [106/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0002Epoch [106/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0008Epoch [106/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0002Epoch [106/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0080Epoch [106/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0560Epoch [106/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0040Epoch [106/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0194Epoch [106/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0003Epoch [106/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0001Epoch [106/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0003Epoch [106/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0000Epoch [106/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0000Epoch [106/124], Batch [100/125] [################----] 80.0%, Loss: 0.0001Epoch [106/124], Batch [101/125] [################----] 80.8%, Loss: 0.0001Epoch [106/124], Batch [102/125] [################----] 81.6%, Loss: 0.0696Epoch [106/124], Batch [103/125] [################----] 82.4%, Loss: 0.0001Epoch [106/124], Batch [104/125] [################----] 83.2%, Loss: 0.0001Epoch [106/124], Batch [105/125] [################----] 84.0%, Loss: 0.0032Epoch [106/124], Batch [106/125] [################----] 84.8%, Loss: 0.0005Epoch [106/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0000Epoch [106/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0152Epoch [106/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0013Epoch [106/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0005Epoch [106/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0003Epoch [106/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0036Epoch [106/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0009Epoch [106/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0000Epoch [106/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0017Epoch [106/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0141Epoch [106/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0000Epoch [106/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0197Epoch [106/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0004Epoch [106/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0007Epoch [106/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0002Epoch [106/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0001Epoch [106/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1035Epoch [106/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0003Epoch [106/124], Batch [125/125] [####################] 100.0%, Loss: 0.0058
Epoch [106/124] finished. Average Loss: 0.0162
Training Accuracy: 99.60%
--- Saving checkpoint for epoch 106 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [107/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0032Epoch [107/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0001Epoch [107/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0008Epoch [107/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0001Epoch [107/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0025Epoch [107/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0006Epoch [107/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0003Epoch [107/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0494Epoch [107/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0010Epoch [107/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0012Epoch [107/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2866Epoch [107/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0299Epoch [107/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0018Epoch [107/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0014Epoch [107/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0037Epoch [107/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0000Epoch [107/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0017Epoch [107/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0022Epoch [107/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0061Epoch [107/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0022Epoch [107/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0152Epoch [107/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0000Epoch [107/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0000Epoch [107/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0002Epoch [107/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.4618Epoch [107/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0003Epoch [107/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0002Epoch [107/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0299Epoch [107/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0145Epoch [107/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0001Epoch [107/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0011Epoch [107/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0260Epoch [107/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0075Epoch [107/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0006Epoch [107/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0023Epoch [107/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0042Epoch [107/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0002Epoch [107/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0009Epoch [107/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0040Epoch [107/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0045Epoch [107/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0005Epoch [107/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0003Epoch [107/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0001Epoch [107/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0035Epoch [107/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0000Epoch [107/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0004Epoch [107/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0042Epoch [107/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0013Epoch [107/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0000Epoch [107/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0005Epoch [107/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0006Epoch [107/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0009Epoch [107/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0005Epoch [107/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0002Epoch [107/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0000Epoch [107/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0012Epoch [107/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0005Epoch [107/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0041Epoch [107/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0006Epoch [107/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0183Epoch [107/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0004Epoch [107/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0001Epoch [107/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0005Epoch [107/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0008Epoch [107/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0003Epoch [107/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0021Epoch [107/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0039Epoch [107/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0000Epoch [107/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0002Epoch [107/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0016Epoch [107/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0015Epoch [107/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0021Epoch [107/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0001Epoch [107/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0056Epoch [107/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0000Epoch [107/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0018Epoch [107/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0000Epoch [107/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0101Epoch [107/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0000Epoch [107/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0000Epoch [107/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1719Epoch [107/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1407Epoch [107/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0010Epoch [107/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0034Epoch [107/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0029Epoch [107/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0001Epoch [107/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0014Epoch [107/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0564Epoch [107/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0006Epoch [107/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0001Epoch [107/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0242Epoch [107/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0002Epoch [107/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0001Epoch [107/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0089Epoch [107/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0006Epoch [107/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0016Epoch [107/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0139Epoch [107/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0112Epoch [107/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0004Epoch [107/124], Batch [100/125] [################----] 80.0%, Loss: 0.0160Epoch [107/124], Batch [101/125] [################----] 80.8%, Loss: 0.0002Epoch [107/124], Batch [102/125] [################----] 81.6%, Loss: 0.0003Epoch [107/124], Batch [103/125] [################----] 82.4%, Loss: 0.0039Epoch [107/124], Batch [104/125] [################----] 83.2%, Loss: 0.0004Epoch [107/124], Batch [105/125] [################----] 84.0%, Loss: 0.0004Epoch [107/124], Batch [106/125] [################----] 84.8%, Loss: 0.0001Epoch [107/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0002Epoch [107/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0003Epoch [107/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0002Epoch [107/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0001Epoch [107/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0000Epoch [107/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0009Epoch [107/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0001Epoch [107/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0001Epoch [107/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0008Epoch [107/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0007Epoch [107/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0097Epoch [107/124], Batch [118/125] [##################--] 94.4%, Loss: 0.4983Epoch [107/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0001Epoch [107/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0001Epoch [107/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0000Epoch [107/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0053Epoch [107/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0000Epoch [107/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0020Epoch [107/124], Batch [125/125] [####################] 100.0%, Loss: 0.0012
Epoch [107/124] finished. Average Loss: 0.0161
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 107 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [108/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.1739Epoch [108/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0032Epoch [108/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0001Epoch [108/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0002Epoch [108/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0010Epoch [108/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0005Epoch [108/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1482Epoch [108/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0000Epoch [108/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0032Epoch [108/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0028Epoch [108/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0001Epoch [108/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0002Epoch [108/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0001Epoch [108/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0014Epoch [108/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0064Epoch [108/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0007Epoch [108/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0012Epoch [108/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0000Epoch [108/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0009Epoch [108/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0011Epoch [108/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0107Epoch [108/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0089Epoch [108/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0107Epoch [108/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0007Epoch [108/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0002Epoch [108/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.1042Epoch [108/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0027Epoch [108/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0106Epoch [108/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0003Epoch [108/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0006Epoch [108/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0010Epoch [108/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0053Epoch [108/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0017Epoch [108/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0006Epoch [108/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0000Epoch [108/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0001Epoch [108/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0173Epoch [108/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0586Epoch [108/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0005Epoch [108/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0033Epoch [108/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0021Epoch [108/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0001Epoch [108/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0006Epoch [108/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0030Epoch [108/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0014Epoch [108/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0050Epoch [108/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0004Epoch [108/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0022Epoch [108/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0005Epoch [108/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0005Epoch [108/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0009Epoch [108/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0003Epoch [108/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0004Epoch [108/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0009Epoch [108/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0008Epoch [108/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0005Epoch [108/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0006Epoch [108/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0005Epoch [108/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0608Epoch [108/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0000Epoch [108/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0000Epoch [108/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0104Epoch [108/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0000Epoch [108/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0509Epoch [108/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0011Epoch [108/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0003Epoch [108/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0031Epoch [108/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0027Epoch [108/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0003Epoch [108/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0038Epoch [108/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0151Epoch [108/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0394Epoch [108/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0001Epoch [108/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0001Epoch [108/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0000Epoch [108/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0057Epoch [108/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0047Epoch [108/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0000Epoch [108/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0001Epoch [108/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0001Epoch [108/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0002Epoch [108/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0081Epoch [108/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0003Epoch [108/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0002Epoch [108/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0459Epoch [108/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0075Epoch [108/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0012Epoch [108/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0005Epoch [108/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0009Epoch [108/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0010Epoch [108/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0000Epoch [108/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0425Epoch [108/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1704Epoch [108/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0087Epoch [108/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3220Epoch [108/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0000Epoch [108/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0000Epoch [108/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0160Epoch [108/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0004Epoch [108/124], Batch [100/125] [################----] 80.0%, Loss: 0.0003Epoch [108/124], Batch [101/125] [################----] 80.8%, Loss: 0.0198Epoch [108/124], Batch [102/125] [################----] 81.6%, Loss: 0.0001Epoch [108/124], Batch [103/125] [################----] 82.4%, Loss: 0.0013Epoch [108/124], Batch [104/125] [################----] 83.2%, Loss: 0.4506Epoch [108/124], Batch [105/125] [################----] 84.0%, Loss: 0.2030Epoch [108/124], Batch [106/125] [################----] 84.8%, Loss: 0.0014Epoch [108/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0016Epoch [108/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0005Epoch [108/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0001Epoch [108/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0000Epoch [108/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0001Epoch [108/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0001Epoch [108/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0013Epoch [108/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0030Epoch [108/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0003Epoch [108/124], Batch [116/125] [##################--] 92.8%, Loss: 0.1110Epoch [108/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0004Epoch [108/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0161Epoch [108/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0059Epoch [108/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0001Epoch [108/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0000Epoch [108/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0031Epoch [108/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0603Epoch [108/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0004Epoch [108/124], Batch [125/125] [####################] 100.0%, Loss: 0.0555
Epoch [108/124] finished. Average Loss: 0.0189
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 108 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [109/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0002Epoch [109/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0004Epoch [109/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0008Epoch [109/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0000Epoch [109/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0003Epoch [109/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0118Epoch [109/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0024Epoch [109/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0012Epoch [109/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0626Epoch [109/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0015Epoch [109/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0001Epoch [109/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0001Epoch [109/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0049Epoch [109/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0000Epoch [109/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0047Epoch [109/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0018Epoch [109/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0095Epoch [109/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0003Epoch [109/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0058Epoch [109/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0002Epoch [109/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0001Epoch [109/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0110Epoch [109/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0003Epoch [109/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0004Epoch [109/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0006Epoch [109/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0166Epoch [109/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0005Epoch [109/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0006Epoch [109/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0238Epoch [109/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0001Epoch [109/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0034Epoch [109/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0001Epoch [109/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0029Epoch [109/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0167Epoch [109/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0059Epoch [109/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0017Epoch [109/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0347Epoch [109/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0064Epoch [109/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.2109Epoch [109/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0031Epoch [109/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0477Epoch [109/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0401Epoch [109/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0004Epoch [109/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0003Epoch [109/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0000Epoch [109/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0011Epoch [109/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0002Epoch [109/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0003Epoch [109/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0210Epoch [109/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0000Epoch [109/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0004Epoch [109/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0001Epoch [109/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0002Epoch [109/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0003Epoch [109/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0000Epoch [109/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0005Epoch [109/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0136Epoch [109/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0005Epoch [109/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0096Epoch [109/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0043Epoch [109/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0162Epoch [109/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0051Epoch [109/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0008Epoch [109/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0048Epoch [109/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0003Epoch [109/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0001Epoch [109/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0964Epoch [109/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0429Epoch [109/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0000Epoch [109/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0006Epoch [109/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0005Epoch [109/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0006Epoch [109/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0008Epoch [109/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0004Epoch [109/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0013Epoch [109/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0017Epoch [109/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0002Epoch [109/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1675Epoch [109/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0017Epoch [109/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0022Epoch [109/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0010Epoch [109/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0067Epoch [109/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0024Epoch [109/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0012Epoch [109/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0006Epoch [109/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0014Epoch [109/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0015Epoch [109/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0000Epoch [109/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0006Epoch [109/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0029Epoch [109/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0001Epoch [109/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0003Epoch [109/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0002Epoch [109/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0006Epoch [109/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0011Epoch [109/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0023Epoch [109/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0001Epoch [109/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0006Epoch [109/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0065Epoch [109/124], Batch [100/125] [################----] 80.0%, Loss: 0.0129Epoch [109/124], Batch [101/125] [################----] 80.8%, Loss: 0.0004Epoch [109/124], Batch [102/125] [################----] 81.6%, Loss: 0.0003Epoch [109/124], Batch [103/125] [################----] 82.4%, Loss: 0.0002Epoch [109/124], Batch [104/125] [################----] 83.2%, Loss: 0.0078Epoch [109/124], Batch [105/125] [################----] 84.0%, Loss: 0.0003Epoch [109/124], Batch [106/125] [################----] 84.8%, Loss: 0.0002Epoch [109/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0000Epoch [109/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0000Epoch [109/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0009Epoch [109/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0014Epoch [109/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0095Epoch [109/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0011Epoch [109/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0003Epoch [109/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0001Epoch [109/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0058Epoch [109/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3910Epoch [109/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0006Epoch [109/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0001Epoch [109/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0001Epoch [109/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0003Epoch [109/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0004Epoch [109/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0006Epoch [109/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0017Epoch [109/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0011Epoch [109/124], Batch [125/125] [####################] 100.0%, Loss: 0.0075
Epoch [109/124] finished. Average Loss: 0.0113
Training Accuracy: 99.40%
--- Saving checkpoint for epoch 109 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [110/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0009Epoch [110/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0591Epoch [110/124], Batch [3/125] [--------------------] 2.4%, Loss: 1.0672Epoch [110/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0132Epoch [110/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0169Epoch [110/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.1847Epoch [110/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0011Epoch [110/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0002Epoch [110/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.7636Epoch [110/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0009Epoch [110/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0005Epoch [110/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0748Epoch [110/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0036Epoch [110/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0548Epoch [110/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0001Epoch [110/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0002Epoch [110/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0020Epoch [110/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0128Epoch [110/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0002Epoch [110/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0112Epoch [110/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0022Epoch [110/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0019Epoch [110/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0016Epoch [110/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.2613Epoch [110/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0057Epoch [110/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0013Epoch [110/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0047Epoch [110/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0103Epoch [110/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0001Epoch [110/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0074Epoch [110/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0018Epoch [110/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0007Epoch [110/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0002Epoch [110/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0004Epoch [110/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0121Epoch [110/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.1051Epoch [110/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0011Epoch [110/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0079Epoch [110/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0066Epoch [110/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0117Epoch [110/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0033Epoch [110/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0037Epoch [110/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0016Epoch [110/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0346Epoch [110/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0009Epoch [110/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0494Epoch [110/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0005Epoch [110/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0290Epoch [110/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0192Epoch [110/124], Batch [50/125] [########------------] 40.0%, Loss: 0.1743Epoch [110/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1890Epoch [110/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0146Epoch [110/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0365Epoch [110/124], Batch [54/125] [########------------] 43.2%, Loss: 1.3315Epoch [110/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0012Epoch [110/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0001Epoch [110/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0003Epoch [110/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0002Epoch [110/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0043Epoch [110/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0004Epoch [110/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0041Epoch [110/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0002Epoch [110/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0003Epoch [110/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0029Epoch [110/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0196Epoch [110/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0144Epoch [110/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0010Epoch [110/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0052Epoch [110/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0003Epoch [110/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0068Epoch [110/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0339Epoch [110/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0899Epoch [110/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0008Epoch [110/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0064Epoch [110/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0101Epoch [110/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0186Epoch [110/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0076Epoch [110/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0008Epoch [110/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0001Epoch [110/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0016Epoch [110/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0028Epoch [110/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0039Epoch [110/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.4311Epoch [110/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0024Epoch [110/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0017Epoch [110/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1023Epoch [110/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0026Epoch [110/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0023Epoch [110/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0079Epoch [110/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0535Epoch [110/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0410Epoch [110/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0100Epoch [110/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0148Epoch [110/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0011Epoch [110/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0084Epoch [110/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0063Epoch [110/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0009Epoch [110/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0026Epoch [110/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0006Epoch [110/124], Batch [100/125] [################----] 80.0%, Loss: 0.0009Epoch [110/124], Batch [101/125] [################----] 80.8%, Loss: 0.0078Epoch [110/124], Batch [102/125] [################----] 81.6%, Loss: 0.0259Epoch [110/124], Batch [103/125] [################----] 82.4%, Loss: 0.0006Epoch [110/124], Batch [104/125] [################----] 83.2%, Loss: 0.0031Epoch [110/124], Batch [105/125] [################----] 84.0%, Loss: 0.0008Epoch [110/124], Batch [106/125] [################----] 84.8%, Loss: 0.0115Epoch [110/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0015Epoch [110/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0018Epoch [110/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0068Epoch [110/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0027Epoch [110/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0363Epoch [110/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0314Epoch [110/124], Batch [113/125] [##################--] 90.4%, Loss: 0.1018Epoch [110/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0011Epoch [110/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2536Epoch [110/124], Batch [116/125] [##################--] 92.8%, Loss: 0.3267Epoch [110/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0020Epoch [110/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0063Epoch [110/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0002Epoch [110/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0005Epoch [110/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0027Epoch [110/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0006Epoch [110/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0086Epoch [110/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0168Epoch [110/124], Batch [125/125] [####################] 100.0%, Loss: 0.0347
Epoch [110/124] finished. Average Loss: 0.0513
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 110 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [111/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0014Epoch [111/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.1002Epoch [111/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0018Epoch [111/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0032Epoch [111/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0083Epoch [111/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0203Epoch [111/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.1315Epoch [111/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0150Epoch [111/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0148Epoch [111/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0034Epoch [111/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0000Epoch [111/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0067Epoch [111/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0015Epoch [111/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.1896Epoch [111/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.6628Epoch [111/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0099Epoch [111/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0003Epoch [111/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0004Epoch [111/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0037Epoch [111/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0004Epoch [111/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0239Epoch [111/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0562Epoch [111/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0463Epoch [111/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0016Epoch [111/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0075Epoch [111/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0002Epoch [111/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0014Epoch [111/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0005Epoch [111/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0004Epoch [111/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0029Epoch [111/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0084Epoch [111/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0021Epoch [111/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0281Epoch [111/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0719Epoch [111/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0002Epoch [111/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0020Epoch [111/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0015Epoch [111/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0116Epoch [111/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0020Epoch [111/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0036Epoch [111/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0014Epoch [111/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0032Epoch [111/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0119Epoch [111/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0120Epoch [111/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.3589Epoch [111/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0019Epoch [111/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0508Epoch [111/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0174Epoch [111/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0097Epoch [111/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0928Epoch [111/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0146Epoch [111/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0001Epoch [111/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0059Epoch [111/124], Batch [54/125] [########------------] 43.2%, Loss: 0.8413Epoch [111/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0035Epoch [111/124], Batch [56/125] [########------------] 44.8%, Loss: 0.5723Epoch [111/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0009Epoch [111/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.1241Epoch [111/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0074Epoch [111/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0005Epoch [111/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0003Epoch [111/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0013Epoch [111/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0082Epoch [111/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0004Epoch [111/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0297Epoch [111/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0036Epoch [111/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.4332Epoch [111/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0058Epoch [111/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1668Epoch [111/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0014Epoch [111/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0012Epoch [111/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0080Epoch [111/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.1411Epoch [111/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0007Epoch [111/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0078Epoch [111/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0004Epoch [111/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0799Epoch [111/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0056Epoch [111/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0495Epoch [111/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0096Epoch [111/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0041Epoch [111/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0365Epoch [111/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0668Epoch [111/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0176Epoch [111/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0010Epoch [111/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0009Epoch [111/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0170Epoch [111/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0121Epoch [111/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0285Epoch [111/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0004Epoch [111/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0036Epoch [111/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2662Epoch [111/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0047Epoch [111/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0064Epoch [111/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.6602Epoch [111/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.3698Epoch [111/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0014Epoch [111/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0026Epoch [111/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0008Epoch [111/124], Batch [100/125] [################----] 80.0%, Loss: 0.0570Epoch [111/124], Batch [101/125] [################----] 80.8%, Loss: 0.0000Epoch [111/124], Batch [102/125] [################----] 81.6%, Loss: 0.0307Epoch [111/124], Batch [103/125] [################----] 82.4%, Loss: 0.0597Epoch [111/124], Batch [104/125] [################----] 83.2%, Loss: 0.0012Epoch [111/124], Batch [105/125] [################----] 84.0%, Loss: 0.1055Epoch [111/124], Batch [106/125] [################----] 84.8%, Loss: 0.7379Epoch [111/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0075Epoch [111/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0285Epoch [111/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0009Epoch [111/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0015Epoch [111/124], Batch [111/125] [#################---] 88.8%, Loss: 1.2506Epoch [111/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0004Epoch [111/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0363Epoch [111/124], Batch [114/125] [##################--] 91.2%, Loss: 0.9930Epoch [111/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0133Epoch [111/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0035Epoch [111/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0016Epoch [111/124], Batch [118/125] [##################--] 94.4%, Loss: 0.5434Epoch [111/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0566Epoch [111/124], Batch [120/125] [###################-] 96.0%, Loss: 0.8426Epoch [111/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0032Epoch [111/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0684Epoch [111/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0003Epoch [111/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0003Epoch [111/124], Batch [125/125] [####################] 100.0%, Loss: 0.2944
Epoch [111/124] finished. Average Loss: 0.0894
Training Accuracy: 98.60%
--- Saving checkpoint for epoch 111 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [112/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0010Epoch [112/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0013Epoch [112/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0018Epoch [112/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0029Epoch [112/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0003Epoch [112/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0109Epoch [112/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0102Epoch [112/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0055Epoch [112/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0103Epoch [112/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0062Epoch [112/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.2107Epoch [112/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0026Epoch [112/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0060Epoch [112/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0010Epoch [112/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0835Epoch [112/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0152Epoch [112/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0888Epoch [112/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.3773Epoch [112/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0292Epoch [112/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0037Epoch [112/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0064Epoch [112/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0008Epoch [112/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.4309Epoch [112/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0012Epoch [112/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0565Epoch [112/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0087Epoch [112/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.7613Epoch [112/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0060Epoch [112/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0861Epoch [112/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0692Epoch [112/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0883Epoch [112/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0250Epoch [112/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0021Epoch [112/124], Batch [34/125] [#####---------------] 27.2%, Loss: 2.2245Epoch [112/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0089Epoch [112/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.4306Epoch [112/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.4151Epoch [112/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0023Epoch [112/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0143Epoch [112/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0221Epoch [112/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0025Epoch [112/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1025Epoch [112/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0070Epoch [112/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.3234Epoch [112/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0003Epoch [112/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0029Epoch [112/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0557Epoch [112/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1506Epoch [112/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0065Epoch [112/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0268Epoch [112/124], Batch [51/125] [########------------] 40.8%, Loss: 1.2685Epoch [112/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0018Epoch [112/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0138Epoch [112/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0564Epoch [112/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0116Epoch [112/124], Batch [56/125] [########------------] 44.8%, Loss: 0.2165Epoch [112/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.2263Epoch [112/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0011Epoch [112/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0288Epoch [112/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0085Epoch [112/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0154Epoch [112/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0007Epoch [112/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0073Epoch [112/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0005Epoch [112/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.4666Epoch [112/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0016Epoch [112/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0056Epoch [112/124], Batch [68/125] [##########----------] 54.4%, Loss: 1.0331Epoch [112/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0013Epoch [112/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0054Epoch [112/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0004Epoch [112/124], Batch [72/125] [###########---------] 57.6%, Loss: 1.8958Epoch [112/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0481Epoch [112/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1870Epoch [112/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0011Epoch [112/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0374Epoch [112/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0821Epoch [112/124], Batch [78/125] [############--------] 62.4%, Loss: 1.5936Epoch [112/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0213Epoch [112/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0705Epoch [112/124], Batch [81/125] [############--------] 64.8%, Loss: 0.1308Epoch [112/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1343Epoch [112/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0046Epoch [112/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.5788Epoch [112/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.8269Epoch [112/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.5138Epoch [112/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.5945Epoch [112/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0364Epoch [112/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0237Epoch [112/124], Batch [90/125] [##############------] 72.0%, Loss: 0.2176Epoch [112/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0133Epoch [112/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0448Epoch [112/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1938Epoch [112/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.1373Epoch [112/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0030Epoch [112/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.5971Epoch [112/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.4366Epoch [112/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0141Epoch [112/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0522Epoch [112/124], Batch [100/125] [################----] 80.0%, Loss: 1.2832Epoch [112/124], Batch [101/125] [################----] 80.8%, Loss: 0.1087Epoch [112/124], Batch [102/125] [################----] 81.6%, Loss: 0.0200Epoch [112/124], Batch [103/125] [################----] 82.4%, Loss: 0.4856Epoch [112/124], Batch [104/125] [################----] 83.2%, Loss: 0.0051Epoch [112/124], Batch [105/125] [################----] 84.0%, Loss: 0.0076Epoch [112/124], Batch [106/125] [################----] 84.8%, Loss: 0.1682Epoch [112/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0765Epoch [112/124], Batch [108/125] [#################---] 86.4%, Loss: 0.2706Epoch [112/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0103Epoch [112/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0415Epoch [112/124], Batch [111/125] [#################---] 88.8%, Loss: 0.2406Epoch [112/124], Batch [112/125] [#################---] 89.6%, Loss: 0.2596Epoch [112/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0823Epoch [112/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0115Epoch [112/124], Batch [115/125] [##################--] 92.0%, Loss: 1.5861Epoch [112/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0053Epoch [112/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0881Epoch [112/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0052Epoch [112/124], Batch [119/125] [###################-] 95.2%, Loss: 0.1945Epoch [112/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0063Epoch [112/124], Batch [121/125] [###################-] 96.8%, Loss: 0.6994Epoch [112/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0243Epoch [112/124], Batch [123/125] [###################-] 98.4%, Loss: 0.5048Epoch [112/124], Batch [124/125] [###################-] 99.2%, Loss: 0.7515Epoch [112/124], Batch [125/125] [####################] 100.0%, Loss: 0.1648
Epoch [112/124] finished. Average Loss: 0.2014
Training Accuracy: 98.80%
--- Saving checkpoint for epoch 112 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [113/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0505Epoch [113/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0073Epoch [113/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0787Epoch [113/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.4985Epoch [113/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0014Epoch [113/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.2771Epoch [113/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0073Epoch [113/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0045Epoch [113/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0110Epoch [113/124], Batch [10/125] [#-------------------] 8.0%, Loss: 1.2117Epoch [113/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1097Epoch [113/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0253Epoch [113/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0005Epoch [113/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0070Epoch [113/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0568Epoch [113/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0289Epoch [113/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0072Epoch [113/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0177Epoch [113/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.9639Epoch [113/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1049Epoch [113/124], Batch [21/125] [###-----------------] 16.8%, Loss: 1.8725Epoch [113/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2706Epoch [113/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0117Epoch [113/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0022Epoch [113/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.3698Epoch [113/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0781Epoch [113/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0782Epoch [113/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0220Epoch [113/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.6323Epoch [113/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0006Epoch [113/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0184Epoch [113/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.3082Epoch [113/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1647Epoch [113/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.9476Epoch [113/124], Batch [35/125] [#####---------------] 28.0%, Loss: 1.3057Epoch [113/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0621Epoch [113/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0029Epoch [113/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0063Epoch [113/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0190Epoch [113/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0562Epoch [113/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0028Epoch [113/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0066Epoch [113/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.3393Epoch [113/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0226Epoch [113/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0028Epoch [113/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.2771Epoch [113/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0284Epoch [113/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0128Epoch [113/124], Batch [49/125] [#######-------------] 39.2%, Loss: 2.3629Epoch [113/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0021Epoch [113/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1618Epoch [113/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0035Epoch [113/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0388Epoch [113/124], Batch [54/125] [########------------] 43.2%, Loss: 0.9978Epoch [113/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0781Epoch [113/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0029Epoch [113/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0991Epoch [113/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0101Epoch [113/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0910Epoch [113/124], Batch [60/125] [#########-----------] 48.0%, Loss: 1.3514Epoch [113/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.5563Epoch [113/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0274Epoch [113/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.1838Epoch [113/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0027Epoch [113/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.4621Epoch [113/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0590Epoch [113/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0069Epoch [113/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.1651Epoch [113/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.1354Epoch [113/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0625Epoch [113/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0011Epoch [113/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.3076Epoch [113/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.2358Epoch [113/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0069Epoch [113/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0006Epoch [113/124], Batch [76/125] [############--------] 60.8%, Loss: 0.7339Epoch [113/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0177Epoch [113/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0134Epoch [113/124], Batch [79/125] [############--------] 63.2%, Loss: 0.2192Epoch [113/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0998Epoch [113/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0068Epoch [113/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.6121Epoch [113/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.4289Epoch [113/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0095Epoch [113/124], Batch [85/125] [#############-------] 68.0%, Loss: 1.0975Epoch [113/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.1056Epoch [113/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0554Epoch [113/124], Batch [88/125] [##############------] 70.4%, Loss: 0.6118Epoch [113/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0421Epoch [113/124], Batch [90/125] [##############------] 72.0%, Loss: 0.1956Epoch [113/124], Batch [91/125] [##############------] 72.8%, Loss: 0.9248Epoch [113/124], Batch [92/125] [##############------] 73.6%, Loss: 0.2301Epoch [113/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0014Epoch [113/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2382Epoch [113/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.3269Epoch [113/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.2713Epoch [113/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.3893Epoch [113/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.3823Epoch [113/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0045Epoch [113/124], Batch [100/125] [################----] 80.0%, Loss: 0.1485Epoch [113/124], Batch [101/125] [################----] 80.8%, Loss: 0.7121Epoch [113/124], Batch [102/125] [################----] 81.6%, Loss: 0.0040Epoch [113/124], Batch [103/125] [################----] 82.4%, Loss: 0.0031Epoch [113/124], Batch [104/125] [################----] 83.2%, Loss: 0.0143Epoch [113/124], Batch [105/125] [################----] 84.0%, Loss: 0.0026Epoch [113/124], Batch [106/125] [################----] 84.8%, Loss: 0.0339Epoch [113/124], Batch [107/125] [#################---] 85.6%, Loss: 0.2911Epoch [113/124], Batch [108/125] [#################---] 86.4%, Loss: 1.4798Epoch [113/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0104Epoch [113/124], Batch [110/125] [#################---] 88.0%, Loss: 0.4194Epoch [113/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0026Epoch [113/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0330Epoch [113/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0033Epoch [113/124], Batch [114/125] [##################--] 91.2%, Loss: 0.1751Epoch [113/124], Batch [115/125] [##################--] 92.0%, Loss: 0.3460Epoch [113/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0166Epoch [113/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0088Epoch [113/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0182Epoch [113/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0033Epoch [113/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0472Epoch [113/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0011Epoch [113/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0064Epoch [113/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1884Epoch [113/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0031Epoch [113/124], Batch [125/125] [####################] 100.0%, Loss: 0.0016
Epoch [113/124] finished. Average Loss: 0.2304
Training Accuracy: 99.00%
--- Saving checkpoint for epoch 113 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [114/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0085Epoch [114/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0007Epoch [114/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.9428Epoch [114/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0003Epoch [114/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0001Epoch [114/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.2623Epoch [114/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0132Epoch [114/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0387Epoch [114/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0264Epoch [114/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0620Epoch [114/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0009Epoch [114/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0011Epoch [114/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0003Epoch [114/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0167Epoch [114/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0711Epoch [114/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0644Epoch [114/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0206Epoch [114/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0150Epoch [114/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0011Epoch [114/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1336Epoch [114/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0052Epoch [114/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0998Epoch [114/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0019Epoch [114/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0431Epoch [114/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.2274Epoch [114/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0634Epoch [114/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.2380Epoch [114/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0609Epoch [114/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0081Epoch [114/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0110Epoch [114/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1396Epoch [114/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0021Epoch [114/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.1191Epoch [114/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0156Epoch [114/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.1987Epoch [114/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0056Epoch [114/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0682Epoch [114/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0329Epoch [114/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0025Epoch [114/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0598Epoch [114/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0151Epoch [114/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0288Epoch [114/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0026Epoch [114/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0004Epoch [114/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0010Epoch [114/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0146Epoch [114/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0076Epoch [114/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0686Epoch [114/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.7956Epoch [114/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0079Epoch [114/124], Batch [51/125] [########------------] 40.8%, Loss: 0.1406Epoch [114/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0948Epoch [114/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0091Epoch [114/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0011Epoch [114/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0013Epoch [114/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0034Epoch [114/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0009Epoch [114/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0197Epoch [114/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0012Epoch [114/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0009Epoch [114/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0054Epoch [114/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1964Epoch [114/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0095Epoch [114/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.2183Epoch [114/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.8041Epoch [114/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.1289Epoch [114/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0006Epoch [114/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0993Epoch [114/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0438Epoch [114/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0050Epoch [114/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.1087Epoch [114/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0036Epoch [114/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.1148Epoch [114/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0026Epoch [114/124], Batch [75/125] [############--------] 60.0%, Loss: 0.7113Epoch [114/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0239Epoch [114/124], Batch [77/125] [############--------] 61.6%, Loss: 0.4321Epoch [114/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1415Epoch [114/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0261Epoch [114/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0154Epoch [114/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0024Epoch [114/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0081Epoch [114/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0357Epoch [114/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0000Epoch [114/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.3071Epoch [114/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0029Epoch [114/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0204Epoch [114/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0118Epoch [114/124], Batch [89/125] [##############------] 71.2%, Loss: 0.2555Epoch [114/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0027Epoch [114/124], Batch [91/125] [##############------] 72.8%, Loss: 1.3648Epoch [114/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0001Epoch [114/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0262Epoch [114/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.4773Epoch [114/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.2665Epoch [114/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0784Epoch [114/124], Batch [97/125] [###############-----] 77.6%, Loss: 1.2514Epoch [114/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0034Epoch [114/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0169Epoch [114/124], Batch [100/125] [################----] 80.0%, Loss: 0.1811Epoch [114/124], Batch [101/125] [################----] 80.8%, Loss: 0.0430Epoch [114/124], Batch [102/125] [################----] 81.6%, Loss: 0.1857Epoch [114/124], Batch [103/125] [################----] 82.4%, Loss: 0.0021Epoch [114/124], Batch [104/125] [################----] 83.2%, Loss: 0.3273Epoch [114/124], Batch [105/125] [################----] 84.0%, Loss: 0.0766Epoch [114/124], Batch [106/125] [################----] 84.8%, Loss: 0.4941Epoch [114/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0066Epoch [114/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0467Epoch [114/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0261Epoch [114/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0028Epoch [114/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1960Epoch [114/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0148Epoch [114/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0008Epoch [114/124], Batch [114/125] [##################--] 91.2%, Loss: 0.3931Epoch [114/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0064Epoch [114/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0029Epoch [114/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0016Epoch [114/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0208Epoch [114/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0212Epoch [114/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0000Epoch [114/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0018Epoch [114/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0020Epoch [114/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2951Epoch [114/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0809Epoch [114/124], Batch [125/125] [####################] 100.0%, Loss: 0.0014
Epoch [114/124] finished. Average Loss: 0.1116
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 114 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [115/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0774Epoch [115/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.9808Epoch [115/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0029Epoch [115/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0013Epoch [115/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0487Epoch [115/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0832Epoch [115/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0065Epoch [115/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0038Epoch [115/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.2724Epoch [115/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0131Epoch [115/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0695Epoch [115/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0654Epoch [115/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.3602Epoch [115/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0113Epoch [115/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0154Epoch [115/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0448Epoch [115/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0005Epoch [115/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.1981Epoch [115/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0141Epoch [115/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.1339Epoch [115/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0005Epoch [115/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0010Epoch [115/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0049Epoch [115/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0003Epoch [115/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0090Epoch [115/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0125Epoch [115/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0013Epoch [115/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0005Epoch [115/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0360Epoch [115/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.1455Epoch [115/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0001Epoch [115/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.2172Epoch [115/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0211Epoch [115/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0031Epoch [115/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0164Epoch [115/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0051Epoch [115/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0116Epoch [115/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0561Epoch [115/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0001Epoch [115/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0945Epoch [115/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0631Epoch [115/124], Batch [42/125] [######--------------] 33.6%, Loss: 1.4602Epoch [115/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0346Epoch [115/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0309Epoch [115/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0130Epoch [115/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0010Epoch [115/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0011Epoch [115/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0013Epoch [115/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0191Epoch [115/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0140Epoch [115/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0656Epoch [115/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0000Epoch [115/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0065Epoch [115/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0004Epoch [115/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2254Epoch [115/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0074Epoch [115/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0869Epoch [115/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0001Epoch [115/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0015Epoch [115/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0007Epoch [115/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0059Epoch [115/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0293Epoch [115/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0026Epoch [115/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0003Epoch [115/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0035Epoch [115/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0079Epoch [115/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0005Epoch [115/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0035Epoch [115/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0854Epoch [115/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0037Epoch [115/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0169Epoch [115/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0035Epoch [115/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0000Epoch [115/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0509Epoch [115/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0150Epoch [115/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0080Epoch [115/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0034Epoch [115/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0089Epoch [115/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0030Epoch [115/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0003Epoch [115/124], Batch [81/125] [############--------] 64.8%, Loss: 0.6090Epoch [115/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1292Epoch [115/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0935Epoch [115/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0003Epoch [115/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0523Epoch [115/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0018Epoch [115/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.1094Epoch [115/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0136Epoch [115/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0003Epoch [115/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0036Epoch [115/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0026Epoch [115/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0008Epoch [115/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0000Epoch [115/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0019Epoch [115/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0013Epoch [115/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0206Epoch [115/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0019Epoch [115/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0032Epoch [115/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0026Epoch [115/124], Batch [100/125] [################----] 80.0%, Loss: 0.0025Epoch [115/124], Batch [101/125] [################----] 80.8%, Loss: 0.0039Epoch [115/124], Batch [102/125] [################----] 81.6%, Loss: 0.0319Epoch [115/124], Batch [103/125] [################----] 82.4%, Loss: 0.4617Epoch [115/124], Batch [104/125] [################----] 83.2%, Loss: 0.0138Epoch [115/124], Batch [105/125] [################----] 84.0%, Loss: 0.0102Epoch [115/124], Batch [106/125] [################----] 84.8%, Loss: 0.2456Epoch [115/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0006Epoch [115/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0140Epoch [115/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0014Epoch [115/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0056Epoch [115/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0001Epoch [115/124], Batch [112/125] [#################---] 89.6%, Loss: 0.1475Epoch [115/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0024Epoch [115/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0280Epoch [115/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0303Epoch [115/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0024Epoch [115/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0026Epoch [115/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0011Epoch [115/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0066Epoch [115/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0058Epoch [115/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0009Epoch [115/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0002Epoch [115/124], Batch [123/125] [###################-] 98.4%, Loss: 0.1422Epoch [115/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0008Epoch [115/124], Batch [125/125] [####################] 100.0%, Loss: 0.0001
Epoch [115/124] finished. Average Loss: 0.0603
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 115 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [116/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0003Epoch [116/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0009Epoch [116/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0018Epoch [116/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0006Epoch [116/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0002Epoch [116/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0001Epoch [116/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0108Epoch [116/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0086Epoch [116/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0843Epoch [116/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0061Epoch [116/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0018Epoch [116/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0084Epoch [116/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0005Epoch [116/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0043Epoch [116/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0037Epoch [116/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0003Epoch [116/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0117Epoch [116/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0002Epoch [116/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0028Epoch [116/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.6598Epoch [116/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0012Epoch [116/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0006Epoch [116/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0007Epoch [116/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0012Epoch [116/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0314Epoch [116/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0001Epoch [116/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0051Epoch [116/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0166Epoch [116/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2867Epoch [116/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0040Epoch [116/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.1194Epoch [116/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0002Epoch [116/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0007Epoch [116/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0197Epoch [116/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.6940Epoch [116/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0000Epoch [116/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0011Epoch [116/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0035Epoch [116/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0033Epoch [116/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1260Epoch [116/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0049Epoch [116/124], Batch [42/125] [######--------------] 33.6%, Loss: 1.2749Epoch [116/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1797Epoch [116/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0004Epoch [116/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0025Epoch [116/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0026Epoch [116/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0145Epoch [116/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0015Epoch [116/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0169Epoch [116/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0012Epoch [116/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0003Epoch [116/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0195Epoch [116/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0275Epoch [116/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0900Epoch [116/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0002Epoch [116/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0077Epoch [116/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0014Epoch [116/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0006Epoch [116/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0147Epoch [116/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0043Epoch [116/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0118Epoch [116/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0005Epoch [116/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0029Epoch [116/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0017Epoch [116/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.6870Epoch [116/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0010Epoch [116/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0012Epoch [116/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0077Epoch [116/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0003Epoch [116/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0003Epoch [116/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0650Epoch [116/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0004Epoch [116/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0084Epoch [116/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0005Epoch [116/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0008Epoch [116/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0030Epoch [116/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0352Epoch [116/124], Batch [78/125] [############--------] 62.4%, Loss: 0.1610Epoch [116/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0023Epoch [116/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0046Epoch [116/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0004Epoch [116/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0627Epoch [116/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0042Epoch [116/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0034Epoch [116/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1263Epoch [116/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0063Epoch [116/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0003Epoch [116/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0088Epoch [116/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0095Epoch [116/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0009Epoch [116/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0022Epoch [116/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0002Epoch [116/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0082Epoch [116/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0004Epoch [116/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0018Epoch [116/124], Batch [96/125] [###############-----] 76.8%, Loss: 1.6810Epoch [116/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0034Epoch [116/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0010Epoch [116/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0609Epoch [116/124], Batch [100/125] [################----] 80.0%, Loss: 0.0033Epoch [116/124], Batch [101/125] [################----] 80.8%, Loss: 0.0010Epoch [116/124], Batch [102/125] [################----] 81.6%, Loss: 0.0013Epoch [116/124], Batch [103/125] [################----] 82.4%, Loss: 0.0645Epoch [116/124], Batch [104/125] [################----] 83.2%, Loss: 0.0549Epoch [116/124], Batch [105/125] [################----] 84.0%, Loss: 0.1859Epoch [116/124], Batch [106/125] [################----] 84.8%, Loss: 0.0414Epoch [116/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0006Epoch [116/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0009Epoch [116/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0004Epoch [116/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0044Epoch [116/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0126Epoch [116/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0006Epoch [116/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0054Epoch [116/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0819Epoch [116/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0605Epoch [116/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0693Epoch [116/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0184Epoch [116/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0003Epoch [116/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0001Epoch [116/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0164Epoch [116/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0003Epoch [116/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0003Epoch [116/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0001Epoch [116/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0028Epoch [116/124], Batch [125/125] [####################] 100.0%, Loss: 0.0000
Epoch [116/124] finished. Average Loss: 0.0591
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 116 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [117/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0063Epoch [117/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0009Epoch [117/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0084Epoch [117/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0002Epoch [117/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0017Epoch [117/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0124Epoch [117/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0005Epoch [117/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0126Epoch [117/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0139Epoch [117/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0029Epoch [117/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0125Epoch [117/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0004Epoch [117/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.2987Epoch [117/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0053Epoch [117/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0010Epoch [117/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0002Epoch [117/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0003Epoch [117/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0016Epoch [117/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0010Epoch [117/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0001Epoch [117/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0219Epoch [117/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0003Epoch [117/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0017Epoch [117/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0007Epoch [117/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0314Epoch [117/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.2062Epoch [117/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0070Epoch [117/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0006Epoch [117/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0003Epoch [117/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0021Epoch [117/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0010Epoch [117/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0017Epoch [117/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0001Epoch [117/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0010Epoch [117/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0116Epoch [117/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0002Epoch [117/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0365Epoch [117/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0001Epoch [117/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0005Epoch [117/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0313Epoch [117/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0005Epoch [117/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0000Epoch [117/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0028Epoch [117/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0036Epoch [117/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0032Epoch [117/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0000Epoch [117/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0341Epoch [117/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0004Epoch [117/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0000Epoch [117/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0003Epoch [117/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0027Epoch [117/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0005Epoch [117/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0221Epoch [117/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0244Epoch [117/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0035Epoch [117/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0126Epoch [117/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0093Epoch [117/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0546Epoch [117/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0032Epoch [117/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0631Epoch [117/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0052Epoch [117/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0019Epoch [117/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0001Epoch [117/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0001Epoch [117/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0014Epoch [117/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0000Epoch [117/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0132Epoch [117/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0035Epoch [117/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0014Epoch [117/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0002Epoch [117/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0001Epoch [117/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0007Epoch [117/124], Batch [73/125] [###########---------] 58.4%, Loss: 1.3286Epoch [117/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0008Epoch [117/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0003Epoch [117/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0086Epoch [117/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0075Epoch [117/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0001Epoch [117/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0136Epoch [117/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0007Epoch [117/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0003Epoch [117/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0028Epoch [117/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0095Epoch [117/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0000Epoch [117/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0122Epoch [117/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0113Epoch [117/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0003Epoch [117/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0157Epoch [117/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0109Epoch [117/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0001Epoch [117/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0015Epoch [117/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0001Epoch [117/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0004Epoch [117/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0001Epoch [117/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0026Epoch [117/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0016Epoch [117/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.6335Epoch [117/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0000Epoch [117/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1191Epoch [117/124], Batch [100/125] [################----] 80.0%, Loss: 0.0004Epoch [117/124], Batch [101/125] [################----] 80.8%, Loss: 0.0011Epoch [117/124], Batch [102/125] [################----] 81.6%, Loss: 0.0000Epoch [117/124], Batch [103/125] [################----] 82.4%, Loss: 0.0000Epoch [117/124], Batch [104/125] [################----] 83.2%, Loss: 0.4203Epoch [117/124], Batch [105/125] [################----] 84.0%, Loss: 0.0007Epoch [117/124], Batch [106/125] [################----] 84.8%, Loss: 0.0016Epoch [117/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0007Epoch [117/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0019Epoch [117/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0003Epoch [117/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0001Epoch [117/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0131Epoch [117/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0001Epoch [117/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0034Epoch [117/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0072Epoch [117/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0004Epoch [117/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0001Epoch [117/124], Batch [117/125] [##################--] 93.6%, Loss: 0.1231Epoch [117/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0025Epoch [117/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0001Epoch [117/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0003Epoch [117/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0003Epoch [117/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0007Epoch [117/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0018Epoch [117/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0002Epoch [117/124], Batch [125/125] [####################] 100.0%, Loss: 0.0095
Epoch [117/124] finished. Average Loss: 0.0302
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 117 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [118/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0064Epoch [118/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0018Epoch [118/124], Batch [3/125] [--------------------] 2.4%, Loss: 1.0404Epoch [118/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.5736Epoch [118/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0004Epoch [118/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0146Epoch [118/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0011Epoch [118/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0004Epoch [118/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0002Epoch [118/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0016Epoch [118/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0034Epoch [118/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0110Epoch [118/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0000Epoch [118/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0969Epoch [118/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0020Epoch [118/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0002Epoch [118/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0447Epoch [118/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0199Epoch [118/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0153Epoch [118/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0003Epoch [118/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0008Epoch [118/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0149Epoch [118/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0110Epoch [118/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0025Epoch [118/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0057Epoch [118/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0023Epoch [118/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0188Epoch [118/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0004Epoch [118/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.2181Epoch [118/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0017Epoch [118/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0039Epoch [118/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0003Epoch [118/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0009Epoch [118/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0006Epoch [118/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0001Epoch [118/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.2665Epoch [118/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0009Epoch [118/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0049Epoch [118/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0012Epoch [118/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0083Epoch [118/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0004Epoch [118/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0232Epoch [118/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0030Epoch [118/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0016Epoch [118/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0652Epoch [118/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0026Epoch [118/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0039Epoch [118/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0014Epoch [118/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0056Epoch [118/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0100Epoch [118/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0921Epoch [118/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0010Epoch [118/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0004Epoch [118/124], Batch [54/125] [########------------] 43.2%, Loss: 0.1061Epoch [118/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0721Epoch [118/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0310Epoch [118/124], Batch [57/125] [#########-----------] 45.6%, Loss: 1.2263Epoch [118/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0092Epoch [118/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0013Epoch [118/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0078Epoch [118/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0076Epoch [118/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1328Epoch [118/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0312Epoch [118/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0017Epoch [118/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0009Epoch [118/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0005Epoch [118/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0012Epoch [118/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0398Epoch [118/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0014Epoch [118/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0011Epoch [118/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.3850Epoch [118/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.1426Epoch [118/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0049Epoch [118/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0008Epoch [118/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0124Epoch [118/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0082Epoch [118/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0021Epoch [118/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0176Epoch [118/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0001Epoch [118/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0043Epoch [118/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0173Epoch [118/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0272Epoch [118/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0001Epoch [118/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0215Epoch [118/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0751Epoch [118/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0203Epoch [118/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0012Epoch [118/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0003Epoch [118/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0003Epoch [118/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0183Epoch [118/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0002Epoch [118/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0002Epoch [118/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0096Epoch [118/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.8328Epoch [118/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0007Epoch [118/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0035Epoch [118/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0041Epoch [118/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0086Epoch [118/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0234Epoch [118/124], Batch [100/125] [################----] 80.0%, Loss: 0.0341Epoch [118/124], Batch [101/125] [################----] 80.8%, Loss: 0.0065Epoch [118/124], Batch [102/125] [################----] 81.6%, Loss: 0.0019Epoch [118/124], Batch [103/125] [################----] 82.4%, Loss: 0.0738Epoch [118/124], Batch [104/125] [################----] 83.2%, Loss: 0.0001Epoch [118/124], Batch [105/125] [################----] 84.0%, Loss: 0.0002Epoch [118/124], Batch [106/125] [################----] 84.8%, Loss: 0.0001Epoch [118/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0005Epoch [118/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0031Epoch [118/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0132Epoch [118/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0040Epoch [118/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0018Epoch [118/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0023Epoch [118/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0299Epoch [118/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0211Epoch [118/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0002Epoch [118/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0038Epoch [118/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0059Epoch [118/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0014Epoch [118/124], Batch [119/125] [###################-] 95.2%, Loss: 0.4138Epoch [118/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0012Epoch [118/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0408Epoch [118/124], Batch [122/125] [###################-] 97.6%, Loss: 0.2163Epoch [118/124], Batch [123/125] [###################-] 98.4%, Loss: 0.2299Epoch [118/124], Batch [124/125] [###################-] 99.2%, Loss: 0.3150Epoch [118/124], Batch [125/125] [####################] 100.0%, Loss: 0.0020
Epoch [118/124] finished. Average Loss: 0.0588
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 118 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [119/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0590Epoch [119/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.3765Epoch [119/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.3453Epoch [119/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0004Epoch [119/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0014Epoch [119/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0276Epoch [119/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0011Epoch [119/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0077Epoch [119/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0010Epoch [119/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0407Epoch [119/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.3451Epoch [119/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0001Epoch [119/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0017Epoch [119/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0010Epoch [119/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0548Epoch [119/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0004Epoch [119/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.3053Epoch [119/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0302Epoch [119/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0787Epoch [119/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0021Epoch [119/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0001Epoch [119/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0037Epoch [119/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0007Epoch [119/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.1725Epoch [119/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0010Epoch [119/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0015Epoch [119/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0233Epoch [119/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0262Epoch [119/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0076Epoch [119/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0021Epoch [119/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.2843Epoch [119/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0309Epoch [119/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0005Epoch [119/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0047Epoch [119/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0001Epoch [119/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0067Epoch [119/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0021Epoch [119/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0003Epoch [119/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0009Epoch [119/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0658Epoch [119/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0049Epoch [119/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.8508Epoch [119/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0114Epoch [119/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0713Epoch [119/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0013Epoch [119/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0008Epoch [119/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0000Epoch [119/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0000Epoch [119/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0016Epoch [119/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0124Epoch [119/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0032Epoch [119/124], Batch [52/125] [########------------] 41.6%, Loss: 0.1888Epoch [119/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0005Epoch [119/124], Batch [54/125] [########------------] 43.2%, Loss: 1.1682Epoch [119/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0277Epoch [119/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0015Epoch [119/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0002Epoch [119/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.2799Epoch [119/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0112Epoch [119/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.1481Epoch [119/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0059Epoch [119/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0007Epoch [119/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0070Epoch [119/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0003Epoch [119/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0210Epoch [119/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0001Epoch [119/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0029Epoch [119/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0000Epoch [119/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0079Epoch [119/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0005Epoch [119/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0004Epoch [119/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0005Epoch [119/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0001Epoch [119/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0022Epoch [119/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0001Epoch [119/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0772Epoch [119/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0267Epoch [119/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0037Epoch [119/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0576Epoch [119/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0265Epoch [119/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0016Epoch [119/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0030Epoch [119/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0086Epoch [119/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0079Epoch [119/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0115Epoch [119/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0286Epoch [119/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0724Epoch [119/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0499Epoch [119/124], Batch [89/125] [##############------] 71.2%, Loss: 0.6675Epoch [119/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0051Epoch [119/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0382Epoch [119/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0083Epoch [119/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0001Epoch [119/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0093Epoch [119/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.5207Epoch [119/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0029Epoch [119/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0033Epoch [119/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0154Epoch [119/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0439Epoch [119/124], Batch [100/125] [################----] 80.0%, Loss: 0.0000Epoch [119/124], Batch [101/125] [################----] 80.8%, Loss: 0.0002Epoch [119/124], Batch [102/125] [################----] 81.6%, Loss: 0.0001Epoch [119/124], Batch [103/125] [################----] 82.4%, Loss: 0.0003Epoch [119/124], Batch [104/125] [################----] 83.2%, Loss: 0.0013Epoch [119/124], Batch [105/125] [################----] 84.0%, Loss: 0.0021Epoch [119/124], Batch [106/125] [################----] 84.8%, Loss: 0.0001Epoch [119/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0002Epoch [119/124], Batch [108/125] [#################---] 86.4%, Loss: 0.6099Epoch [119/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0004Epoch [119/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0043Epoch [119/124], Batch [111/125] [#################---] 88.8%, Loss: 0.1168Epoch [119/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0043Epoch [119/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0016Epoch [119/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0006Epoch [119/124], Batch [115/125] [##################--] 92.0%, Loss: 0.2620Epoch [119/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0003Epoch [119/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0006Epoch [119/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0000Epoch [119/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0265Epoch [119/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0010Epoch [119/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0025Epoch [119/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0001Epoch [119/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0008Epoch [119/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0000Epoch [119/124], Batch [125/125] [####################] 100.0%, Loss: 0.4747
Epoch [119/124] finished. Average Loss: 0.0668
Training Accuracy: 99.80%
--- Saving checkpoint for epoch 119 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [120/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0000Epoch [120/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0001Epoch [120/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0037Epoch [120/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0232Epoch [120/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0004Epoch [120/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0001Epoch [120/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0002Epoch [120/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0002Epoch [120/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0065Epoch [120/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0008Epoch [120/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0114Epoch [120/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0088Epoch [120/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0000Epoch [120/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0550Epoch [120/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0000Epoch [120/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0096Epoch [120/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0000Epoch [120/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0053Epoch [120/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.3884Epoch [120/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0001Epoch [120/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0140Epoch [120/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0340Epoch [120/124], Batch [23/125] [###-----------------] 18.4%, Loss: 1.5359Epoch [120/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0498Epoch [120/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0031Epoch [120/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0141Epoch [120/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0001Epoch [120/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0001Epoch [120/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.5829Epoch [120/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0426Epoch [120/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0304Epoch [120/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0040Epoch [120/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0079Epoch [120/124], Batch [34/125] [#####---------------] 27.2%, Loss: 1.7965Epoch [120/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.1801Epoch [120/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0002Epoch [120/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0006Epoch [120/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0011Epoch [120/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0093Epoch [120/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.1169Epoch [120/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0360Epoch [120/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0268Epoch [120/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0416Epoch [120/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0035Epoch [120/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0017Epoch [120/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.1500Epoch [120/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.2114Epoch [120/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0172Epoch [120/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0028Epoch [120/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0235Epoch [120/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0037Epoch [120/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0086Epoch [120/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0084Epoch [120/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0054Epoch [120/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0369Epoch [120/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0151Epoch [120/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0041Epoch [120/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.2336Epoch [120/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.7551Epoch [120/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0047Epoch [120/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0010Epoch [120/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.1841Epoch [120/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0060Epoch [120/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0054Epoch [120/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0049Epoch [120/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0036Epoch [120/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.1528Epoch [120/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0032Epoch [120/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0001Epoch [120/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0018Epoch [120/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0016Epoch [120/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0980Epoch [120/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0063Epoch [120/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0070Epoch [120/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0012Epoch [120/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0364Epoch [120/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0007Epoch [120/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0001Epoch [120/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0030Epoch [120/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0018Epoch [120/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0064Epoch [120/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0100Epoch [120/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0003Epoch [120/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0116Epoch [120/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0016Epoch [120/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0001Epoch [120/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.2529Epoch [120/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0121Epoch [120/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0248Epoch [120/124], Batch [90/125] [##############------] 72.0%, Loss: 0.2518Epoch [120/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0001Epoch [120/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0159Epoch [120/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0027Epoch [120/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.2220Epoch [120/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.4957Epoch [120/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0036Epoch [120/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0034Epoch [120/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.2064Epoch [120/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0151Epoch [120/124], Batch [100/125] [################----] 80.0%, Loss: 0.0009Epoch [120/124], Batch [101/125] [################----] 80.8%, Loss: 0.6501Epoch [120/124], Batch [102/125] [################----] 81.6%, Loss: 0.7537Epoch [120/124], Batch [103/125] [################----] 82.4%, Loss: 0.0072Epoch [120/124], Batch [104/125] [################----] 83.2%, Loss: 0.0424Epoch [120/124], Batch [105/125] [################----] 84.0%, Loss: 0.1368Epoch [120/124], Batch [106/125] [################----] 84.8%, Loss: 2.5043Epoch [120/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0907Epoch [120/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0250Epoch [120/124], Batch [109/125] [#################---] 87.2%, Loss: 0.4925Epoch [120/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0013Epoch [120/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0042Epoch [120/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0248Epoch [120/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0409Epoch [120/124], Batch [114/125] [##################--] 91.2%, Loss: 0.4789Epoch [120/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0028Epoch [120/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0418Epoch [120/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0071Epoch [120/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0008Epoch [120/124], Batch [119/125] [###################-] 95.2%, Loss: 0.2167Epoch [120/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2895Epoch [120/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0043Epoch [120/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0266Epoch [120/124], Batch [123/125] [###################-] 98.4%, Loss: 0.9165Epoch [120/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0056Epoch [120/124], Batch [125/125] [####################] 100.0%, Loss: 0.0015
Epoch [120/124] finished. Average Loss: 0.1228
Training Accuracy: 98.20%
--- Saving checkpoint for epoch 120 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [121/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0034Epoch [121/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0580Epoch [121/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0405Epoch [121/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0671Epoch [121/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0016Epoch [121/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0033Epoch [121/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0169Epoch [121/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0005Epoch [121/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0008Epoch [121/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0060Epoch [121/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.1006Epoch [121/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0020Epoch [121/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0235Epoch [121/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0236Epoch [121/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0017Epoch [121/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0455Epoch [121/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0128Epoch [121/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0183Epoch [121/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0047Epoch [121/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0357Epoch [121/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0418Epoch [121/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.2359Epoch [121/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.1328Epoch [121/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0033Epoch [121/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0014Epoch [121/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0238Epoch [121/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.8184Epoch [121/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0205Epoch [121/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.7897Epoch [121/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.6345Epoch [121/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0037Epoch [121/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0265Epoch [121/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0028Epoch [121/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.2054Epoch [121/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0002Epoch [121/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0046Epoch [121/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.2121Epoch [121/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0596Epoch [121/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0576Epoch [121/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.2024Epoch [121/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0028Epoch [121/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0023Epoch [121/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0023Epoch [121/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0028Epoch [121/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0351Epoch [121/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0007Epoch [121/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0004Epoch [121/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.1581Epoch [121/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.2794Epoch [121/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0181Epoch [121/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0151Epoch [121/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0076Epoch [121/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0173Epoch [121/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0066Epoch [121/124], Batch [55/125] [########------------] 44.0%, Loss: 1.3263Epoch [121/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0074Epoch [121/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0004Epoch [121/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0002Epoch [121/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.2573Epoch [121/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0007Epoch [121/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0569Epoch [121/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0112Epoch [121/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0940Epoch [121/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0838Epoch [121/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1170Epoch [121/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0074Epoch [121/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0000Epoch [121/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.2889Epoch [121/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0124Epoch [121/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0016Epoch [121/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0051Epoch [121/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.4743Epoch [121/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0005Epoch [121/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.2234Epoch [121/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0007Epoch [121/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0251Epoch [121/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0085Epoch [121/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0055Epoch [121/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0267Epoch [121/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0099Epoch [121/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0051Epoch [121/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0181Epoch [121/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0055Epoch [121/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0214Epoch [121/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.1355Epoch [121/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.6878Epoch [121/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0017Epoch [121/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0060Epoch [121/124], Batch [89/125] [##############------] 71.2%, Loss: 1.4638Epoch [121/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0002Epoch [121/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0278Epoch [121/124], Batch [92/125] [##############------] 73.6%, Loss: 0.1035Epoch [121/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0112Epoch [121/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0046Epoch [121/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0262Epoch [121/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0014Epoch [121/124], Batch [97/125] [###############-----] 77.6%, Loss: 1.6915Epoch [121/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0077Epoch [121/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0232Epoch [121/124], Batch [100/125] [################----] 80.0%, Loss: 0.4076Epoch [121/124], Batch [101/125] [################----] 80.8%, Loss: 0.0012Epoch [121/124], Batch [102/125] [################----] 81.6%, Loss: 0.0038Epoch [121/124], Batch [103/125] [################----] 82.4%, Loss: 0.0016Epoch [121/124], Batch [104/125] [################----] 83.2%, Loss: 0.0093Epoch [121/124], Batch [105/125] [################----] 84.0%, Loss: 0.0012Epoch [121/124], Batch [106/125] [################----] 84.8%, Loss: 0.0003Epoch [121/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0012Epoch [121/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0739Epoch [121/124], Batch [109/125] [#################---] 87.2%, Loss: 0.2592Epoch [121/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0001Epoch [121/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0266Epoch [121/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0026Epoch [121/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0019Epoch [121/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0009Epoch [121/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0005Epoch [121/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0125Epoch [121/124], Batch [117/125] [##################--] 93.6%, Loss: 0.3788Epoch [121/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0253Epoch [121/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0156Epoch [121/124], Batch [120/125] [###################-] 96.0%, Loss: 0.5652Epoch [121/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0094Epoch [121/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0003Epoch [121/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0402Epoch [121/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0008Epoch [121/124], Batch [125/125] [####################] 100.0%, Loss: 0.0012
Epoch [121/124] finished. Average Loss: 0.1090
Training Accuracy: 99.20%
--- Saving checkpoint for epoch 121 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [122/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0006Epoch [122/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0320Epoch [122/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.1099Epoch [122/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.2024Epoch [122/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0008Epoch [122/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0003Epoch [122/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0660Epoch [122/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0238Epoch [122/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0667Epoch [122/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0002Epoch [122/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0111Epoch [122/124], Batch [12/125] [#-------------------] 9.6%, Loss: 1.0765Epoch [122/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0085Epoch [122/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0003Epoch [122/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0020Epoch [122/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0004Epoch [122/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0175Epoch [122/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0183Epoch [122/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0163Epoch [122/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0041Epoch [122/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0005Epoch [122/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0042Epoch [122/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0017Epoch [122/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.3523Epoch [122/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0016Epoch [122/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0046Epoch [122/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0176Epoch [122/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0341Epoch [122/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.5170Epoch [122/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0023Epoch [122/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0105Epoch [122/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.1563Epoch [122/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0001Epoch [122/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0035Epoch [122/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0022Epoch [122/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0649Epoch [122/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0076Epoch [122/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0079Epoch [122/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0039Epoch [122/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0017Epoch [122/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0131Epoch [122/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0918Epoch [122/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.1742Epoch [122/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0029Epoch [122/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0080Epoch [122/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0448Epoch [122/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0507Epoch [122/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0040Epoch [122/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0607Epoch [122/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0941Epoch [122/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0606Epoch [122/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0003Epoch [122/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0243Epoch [122/124], Batch [54/125] [########------------] 43.2%, Loss: 0.6348Epoch [122/124], Batch [55/125] [########------------] 44.0%, Loss: 0.2671Epoch [122/124], Batch [56/125] [########------------] 44.8%, Loss: 0.4943Epoch [122/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0003Epoch [122/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0012Epoch [122/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.3465Epoch [122/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0012Epoch [122/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0029Epoch [122/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0067Epoch [122/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0006Epoch [122/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0128Epoch [122/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.1295Epoch [122/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0272Epoch [122/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0940Epoch [122/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0080Epoch [122/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0122Epoch [122/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0547Epoch [122/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0016Epoch [122/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0232Epoch [122/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0029Epoch [122/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0171Epoch [122/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0096Epoch [122/124], Batch [76/125] [############--------] 60.8%, Loss: 0.4527Epoch [122/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0197Epoch [122/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0029Epoch [122/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0009Epoch [122/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0005Epoch [122/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0074Epoch [122/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.1194Epoch [122/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0263Epoch [122/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0023Epoch [122/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0005Epoch [122/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0188Epoch [122/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0371Epoch [122/124], Batch [88/125] [##############------] 70.4%, Loss: 0.1608Epoch [122/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0019Epoch [122/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0039Epoch [122/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0025Epoch [122/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0016Epoch [122/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0163Epoch [122/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0003Epoch [122/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0062Epoch [122/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0019Epoch [122/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0032Epoch [122/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0006Epoch [122/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.1857Epoch [122/124], Batch [100/125] [################----] 80.0%, Loss: 0.1169Epoch [122/124], Batch [101/125] [################----] 80.8%, Loss: 0.0002Epoch [122/124], Batch [102/125] [################----] 81.6%, Loss: 0.0099Epoch [122/124], Batch [103/125] [################----] 82.4%, Loss: 0.0137Epoch [122/124], Batch [104/125] [################----] 83.2%, Loss: 0.0295Epoch [122/124], Batch [105/125] [################----] 84.0%, Loss: 0.0010Epoch [122/124], Batch [106/125] [################----] 84.8%, Loss: 0.0012Epoch [122/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0039Epoch [122/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0163Epoch [122/124], Batch [109/125] [#################---] 87.2%, Loss: 0.1282Epoch [122/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0012Epoch [122/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0016Epoch [122/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0072Epoch [122/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0623Epoch [122/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0010Epoch [122/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0684Epoch [122/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0065Epoch [122/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0003Epoch [122/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0002Epoch [122/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0005Epoch [122/124], Batch [120/125] [###################-] 96.0%, Loss: 0.2634Epoch [122/124], Batch [121/125] [###################-] 96.8%, Loss: 0.1430Epoch [122/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0003Epoch [122/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0040Epoch [122/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0001Epoch [122/124], Batch [125/125] [####################] 100.0%, Loss: 0.0015
Epoch [122/124] finished. Average Loss: 0.0607
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 122 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [123/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0002Epoch [123/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0524Epoch [123/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0000Epoch [123/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0353Epoch [123/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0088Epoch [123/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0579Epoch [123/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0002Epoch [123/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0052Epoch [123/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0070Epoch [123/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.8130Epoch [123/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.0013Epoch [123/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0206Epoch [123/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0002Epoch [123/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0001Epoch [123/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0004Epoch [123/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.0011Epoch [123/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0143Epoch [123/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0131Epoch [123/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0135Epoch [123/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0007Epoch [123/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0002Epoch [123/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0000Epoch [123/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0133Epoch [123/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0311Epoch [123/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0047Epoch [123/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0002Epoch [123/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0011Epoch [123/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.9510Epoch [123/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0010Epoch [123/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0012Epoch [123/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0000Epoch [123/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0004Epoch [123/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0005Epoch [123/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0001Epoch [123/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0061Epoch [123/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0002Epoch [123/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0006Epoch [123/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0000Epoch [123/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0051Epoch [123/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.0064Epoch [123/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0017Epoch [123/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.0003Epoch [123/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0045Epoch [123/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0528Epoch [123/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0020Epoch [123/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0065Epoch [123/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0089Epoch [123/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0083Epoch [123/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0003Epoch [123/124], Batch [50/125] [########------------] 40.0%, Loss: 0.3511Epoch [123/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0240Epoch [123/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0000Epoch [123/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0120Epoch [123/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0002Epoch [123/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0001Epoch [123/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0002Epoch [123/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.2606Epoch [123/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0126Epoch [123/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0001Epoch [123/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0040Epoch [123/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0188Epoch [123/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0001Epoch [123/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0012Epoch [123/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0031Epoch [123/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0002Epoch [123/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.0101Epoch [123/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0025Epoch [123/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0013Epoch [123/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0074Epoch [123/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0010Epoch [123/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.0010Epoch [123/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0011Epoch [123/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0021Epoch [123/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.1735Epoch [123/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0049Epoch [123/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0004Epoch [123/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0165Epoch [123/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0012Epoch [123/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0003Epoch [123/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0001Epoch [123/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0001Epoch [123/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0051Epoch [123/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0101Epoch [123/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0028Epoch [123/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.0002Epoch [123/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0000Epoch [123/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0037Epoch [123/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0424Epoch [123/124], Batch [89/125] [##############------] 71.2%, Loss: 0.3402Epoch [123/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0305Epoch [123/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0079Epoch [123/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0839Epoch [123/124], Batch [93/125] [##############------] 74.4%, Loss: 0.0008Epoch [123/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0542Epoch [123/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0128Epoch [123/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0415Epoch [123/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0004Epoch [123/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.2551Epoch [123/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.0003Epoch [123/124], Batch [100/125] [################----] 80.0%, Loss: 0.0027Epoch [123/124], Batch [101/125] [################----] 80.8%, Loss: 0.0004Epoch [123/124], Batch [102/125] [################----] 81.6%, Loss: 0.0004Epoch [123/124], Batch [103/125] [################----] 82.4%, Loss: 0.0013Epoch [123/124], Batch [104/125] [################----] 83.2%, Loss: 0.0017Epoch [123/124], Batch [105/125] [################----] 84.0%, Loss: 0.0134Epoch [123/124], Batch [106/125] [################----] 84.8%, Loss: 0.0195Epoch [123/124], Batch [107/125] [#################---] 85.6%, Loss: 0.1655Epoch [123/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0241Epoch [123/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0046Epoch [123/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0004Epoch [123/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0047Epoch [123/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0037Epoch [123/124], Batch [113/125] [##################--] 90.4%, Loss: 0.0019Epoch [123/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0001Epoch [123/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0002Epoch [123/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0003Epoch [123/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0064Epoch [123/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0001Epoch [123/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0085Epoch [123/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0006Epoch [123/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0001Epoch [123/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0955Epoch [123/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0016Epoch [123/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0003Epoch [123/124], Batch [125/125] [####################] 100.0%, Loss: 0.0001
Epoch [123/124] finished. Average Loss: 0.0345
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 123 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
Epoch [124/124], Batch [1/125] [--------------------] 0.8%, Loss: 0.0000Epoch [124/124], Batch [2/125] [--------------------] 1.6%, Loss: 0.0002Epoch [124/124], Batch [3/125] [--------------------] 2.4%, Loss: 0.0008Epoch [124/124], Batch [4/125] [--------------------] 3.2%, Loss: 0.0001Epoch [124/124], Batch [5/125] [--------------------] 4.0%, Loss: 0.0002Epoch [124/124], Batch [6/125] [--------------------] 4.8%, Loss: 0.0814Epoch [124/124], Batch [7/125] [#-------------------] 5.6%, Loss: 0.0010Epoch [124/124], Batch [8/125] [#-------------------] 6.4%, Loss: 0.0001Epoch [124/124], Batch [9/125] [#-------------------] 7.2%, Loss: 0.0187Epoch [124/124], Batch [10/125] [#-------------------] 8.0%, Loss: 0.0005Epoch [124/124], Batch [11/125] [#-------------------] 8.8%, Loss: 0.3254Epoch [124/124], Batch [12/125] [#-------------------] 9.6%, Loss: 0.0001Epoch [124/124], Batch [13/125] [##------------------] 10.4%, Loss: 0.0161Epoch [124/124], Batch [14/125] [##------------------] 11.2%, Loss: 0.0000Epoch [124/124], Batch [15/125] [##------------------] 12.0%, Loss: 0.0012Epoch [124/124], Batch [16/125] [##------------------] 12.8%, Loss: 0.1663Epoch [124/124], Batch [17/125] [##------------------] 13.6%, Loss: 0.0020Epoch [124/124], Batch [18/125] [##------------------] 14.4%, Loss: 0.0004Epoch [124/124], Batch [19/125] [###-----------------] 15.2%, Loss: 0.0001Epoch [124/124], Batch [20/125] [###-----------------] 16.0%, Loss: 0.0002Epoch [124/124], Batch [21/125] [###-----------------] 16.8%, Loss: 0.0014Epoch [124/124], Batch [22/125] [###-----------------] 17.6%, Loss: 0.0006Epoch [124/124], Batch [23/125] [###-----------------] 18.4%, Loss: 0.0000Epoch [124/124], Batch [24/125] [###-----------------] 19.2%, Loss: 0.0402Epoch [124/124], Batch [25/125] [####----------------] 20.0%, Loss: 0.0014Epoch [124/124], Batch [26/125] [####----------------] 20.8%, Loss: 0.0004Epoch [124/124], Batch [27/125] [####----------------] 21.6%, Loss: 0.0159Epoch [124/124], Batch [28/125] [####----------------] 22.4%, Loss: 0.0107Epoch [124/124], Batch [29/125] [####----------------] 23.2%, Loss: 0.0038Epoch [124/124], Batch [30/125] [####----------------] 24.0%, Loss: 0.0015Epoch [124/124], Batch [31/125] [####----------------] 24.8%, Loss: 0.0025Epoch [124/124], Batch [32/125] [#####---------------] 25.6%, Loss: 0.0038Epoch [124/124], Batch [33/125] [#####---------------] 26.4%, Loss: 0.0005Epoch [124/124], Batch [34/125] [#####---------------] 27.2%, Loss: 0.0013Epoch [124/124], Batch [35/125] [#####---------------] 28.0%, Loss: 0.0070Epoch [124/124], Batch [36/125] [#####---------------] 28.8%, Loss: 0.0029Epoch [124/124], Batch [37/125] [#####---------------] 29.6%, Loss: 0.0003Epoch [124/124], Batch [38/125] [######--------------] 30.4%, Loss: 0.0058Epoch [124/124], Batch [39/125] [######--------------] 31.2%, Loss: 0.0002Epoch [124/124], Batch [40/125] [######--------------] 32.0%, Loss: 0.5783Epoch [124/124], Batch [41/125] [######--------------] 32.8%, Loss: 0.0021Epoch [124/124], Batch [42/125] [######--------------] 33.6%, Loss: 0.1565Epoch [124/124], Batch [43/125] [######--------------] 34.4%, Loss: 0.0013Epoch [124/124], Batch [44/125] [#######-------------] 35.2%, Loss: 0.0001Epoch [124/124], Batch [45/125] [#######-------------] 36.0%, Loss: 0.0006Epoch [124/124], Batch [46/125] [#######-------------] 36.8%, Loss: 0.0009Epoch [124/124], Batch [47/125] [#######-------------] 37.6%, Loss: 0.0000Epoch [124/124], Batch [48/125] [#######-------------] 38.4%, Loss: 0.0024Epoch [124/124], Batch [49/125] [#######-------------] 39.2%, Loss: 0.0012Epoch [124/124], Batch [50/125] [########------------] 40.0%, Loss: 0.0000Epoch [124/124], Batch [51/125] [########------------] 40.8%, Loss: 0.0025Epoch [124/124], Batch [52/125] [########------------] 41.6%, Loss: 0.0003Epoch [124/124], Batch [53/125] [########------------] 42.4%, Loss: 0.0019Epoch [124/124], Batch [54/125] [########------------] 43.2%, Loss: 0.0097Epoch [124/124], Batch [55/125] [########------------] 44.0%, Loss: 0.0011Epoch [124/124], Batch [56/125] [########------------] 44.8%, Loss: 0.0098Epoch [124/124], Batch [57/125] [#########-----------] 45.6%, Loss: 0.0000Epoch [124/124], Batch [58/125] [#########-----------] 46.4%, Loss: 0.0015Epoch [124/124], Batch [59/125] [#########-----------] 47.2%, Loss: 0.0396Epoch [124/124], Batch [60/125] [#########-----------] 48.0%, Loss: 0.0006Epoch [124/124], Batch [61/125] [#########-----------] 48.8%, Loss: 0.0045Epoch [124/124], Batch [62/125] [#########-----------] 49.6%, Loss: 0.0024Epoch [124/124], Batch [63/125] [##########----------] 50.4%, Loss: 0.0238Epoch [124/124], Batch [64/125] [##########----------] 51.2%, Loss: 0.0265Epoch [124/124], Batch [65/125] [##########----------] 52.0%, Loss: 0.0020Epoch [124/124], Batch [66/125] [##########----------] 52.8%, Loss: 0.2578Epoch [124/124], Batch [67/125] [##########----------] 53.6%, Loss: 0.0002Epoch [124/124], Batch [68/125] [##########----------] 54.4%, Loss: 0.0012Epoch [124/124], Batch [69/125] [###########---------] 55.2%, Loss: 0.0251Epoch [124/124], Batch [70/125] [###########---------] 56.0%, Loss: 0.0109Epoch [124/124], Batch [71/125] [###########---------] 56.8%, Loss: 0.2626Epoch [124/124], Batch [72/125] [###########---------] 57.6%, Loss: 0.0014Epoch [124/124], Batch [73/125] [###########---------] 58.4%, Loss: 0.0009Epoch [124/124], Batch [74/125] [###########---------] 59.2%, Loss: 0.0023Epoch [124/124], Batch [75/125] [############--------] 60.0%, Loss: 0.0005Epoch [124/124], Batch [76/125] [############--------] 60.8%, Loss: 0.0025Epoch [124/124], Batch [77/125] [############--------] 61.6%, Loss: 0.0008Epoch [124/124], Batch [78/125] [############--------] 62.4%, Loss: 0.0005Epoch [124/124], Batch [79/125] [############--------] 63.2%, Loss: 0.0224Epoch [124/124], Batch [80/125] [############--------] 64.0%, Loss: 0.0002Epoch [124/124], Batch [81/125] [############--------] 64.8%, Loss: 0.0001Epoch [124/124], Batch [82/125] [#############-------] 65.6%, Loss: 0.0148Epoch [124/124], Batch [83/125] [#############-------] 66.4%, Loss: 0.0096Epoch [124/124], Batch [84/125] [#############-------] 67.2%, Loss: 0.0000Epoch [124/124], Batch [85/125] [#############-------] 68.0%, Loss: 0.3167Epoch [124/124], Batch [86/125] [#############-------] 68.8%, Loss: 0.0001Epoch [124/124], Batch [87/125] [#############-------] 69.6%, Loss: 0.0018Epoch [124/124], Batch [88/125] [##############------] 70.4%, Loss: 0.0001Epoch [124/124], Batch [89/125] [##############------] 71.2%, Loss: 0.0005Epoch [124/124], Batch [90/125] [##############------] 72.0%, Loss: 0.0002Epoch [124/124], Batch [91/125] [##############------] 72.8%, Loss: 0.0001Epoch [124/124], Batch [92/125] [##############------] 73.6%, Loss: 0.0009Epoch [124/124], Batch [93/125] [##############------] 74.4%, Loss: 0.1511Epoch [124/124], Batch [94/125] [###############-----] 75.2%, Loss: 0.0012Epoch [124/124], Batch [95/125] [###############-----] 76.0%, Loss: 0.0000Epoch [124/124], Batch [96/125] [###############-----] 76.8%, Loss: 0.0001Epoch [124/124], Batch [97/125] [###############-----] 77.6%, Loss: 0.0002Epoch [124/124], Batch [98/125] [###############-----] 78.4%, Loss: 0.0000Epoch [124/124], Batch [99/125] [###############-----] 79.2%, Loss: 0.2503Epoch [124/124], Batch [100/125] [################----] 80.0%, Loss: 0.0020Epoch [124/124], Batch [101/125] [################----] 80.8%, Loss: 0.0102Epoch [124/124], Batch [102/125] [################----] 81.6%, Loss: 0.0000Epoch [124/124], Batch [103/125] [################----] 82.4%, Loss: 0.0007Epoch [124/124], Batch [104/125] [################----] 83.2%, Loss: 0.0003Epoch [124/124], Batch [105/125] [################----] 84.0%, Loss: 0.0001Epoch [124/124], Batch [106/125] [################----] 84.8%, Loss: 0.0004Epoch [124/124], Batch [107/125] [#################---] 85.6%, Loss: 0.0002Epoch [124/124], Batch [108/125] [#################---] 86.4%, Loss: 0.0132Epoch [124/124], Batch [109/125] [#################---] 87.2%, Loss: 0.0750Epoch [124/124], Batch [110/125] [#################---] 88.0%, Loss: 0.0001Epoch [124/124], Batch [111/125] [#################---] 88.8%, Loss: 0.0007Epoch [124/124], Batch [112/125] [#################---] 89.6%, Loss: 0.0098Epoch [124/124], Batch [113/125] [##################--] 90.4%, Loss: 0.9561Epoch [124/124], Batch [114/125] [##################--] 91.2%, Loss: 0.0001Epoch [124/124], Batch [115/125] [##################--] 92.0%, Loss: 0.0333Epoch [124/124], Batch [116/125] [##################--] 92.8%, Loss: 0.0037Epoch [124/124], Batch [117/125] [##################--] 93.6%, Loss: 0.0003Epoch [124/124], Batch [118/125] [##################--] 94.4%, Loss: 0.0005Epoch [124/124], Batch [119/125] [###################-] 95.2%, Loss: 0.0034Epoch [124/124], Batch [120/125] [###################-] 96.0%, Loss: 0.0003Epoch [124/124], Batch [121/125] [###################-] 96.8%, Loss: 0.0065Epoch [124/124], Batch [122/125] [###################-] 97.6%, Loss: 0.0008Epoch [124/124], Batch [123/125] [###################-] 98.4%, Loss: 0.0105Epoch [124/124], Batch [124/125] [###################-] 99.2%, Loss: 0.0064Epoch [124/124], Batch [125/125] [####################] 100.0%, Loss: 0.0046
Epoch [124/124] finished. Average Loss: 0.0325
Training Accuracy: 100.00%
--- Saving checkpoint for epoch 124 ---
Checkpoint saved to ./trained_models/efficientnet_checkpoint.pth
EfficientNet training finished.

--- Saving EfficientNet Model ---
EfficientNet model saved to ./trained_models/efficientnet_food_classifier.pth

--- Starting EfficientNet Inference Example ---
Inference on a random test image.
True label: clam_chowder
Predicted label: macaroni_and_cheese
EfficientNet inference example finished.

EfficientNet script finished.
